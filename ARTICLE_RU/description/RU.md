---
title: Как сделать своего ROS робота
short: Пошаговая инструкция как сделать простого робота работающего на Raspberry Pi 4, ROS и C++
date: 2021-04-07
author: Максим Данилин
all_tags:
 - Raspberry Pi 4
 - С++
 - ROS
 - 3Д-печать
 - Linux
 - Solidworks
 - RPLIDAR
 - Troyka Hat
 - 3D Печать
 - Двухканальный Н-мост
---

# Введение

Привет!

В этой статье мы на примере расскажем о том как создать настоящего робота работающего на OS ROS. Это будет наш первый простой робот со своей операционной системой. Далее мы постараемся пошагово и как можно подробней рассказать вам о процессе проектирования, конструирования и программирования робота а так же расскажем с каким трудностями и проблемами мы столкнулись.

Создание свеого робота это не сложная но и нетривиальная задача. Данная задача требует определенных хотя бы минимальных следующих навыков:

- Работа с OS Linux
- 3Д твердотельное моделирование
- Программирование на С++ или Python
- Навыки 3Д печати

Так же понадобится персональный компьютер под управлением OS Linux и OS Windows и локальная Wi-Fi сеть.

Все исходники как конструкторские CAD файлы так и код мы разместили в Github репозитории [https://github.com/gabbapeople/abot](https://github.com/gabbapeople/abot).

# Цель робота

Постройка робота начинается с идеи. Прежде чем лететь собирать робота вам нужно ответить для себя на следующие вопросы:

- Как должен выглядеть мой робот?
- Из каких частей/сегментов мой робот будет состоять?
- Что мой робот должен делать и как?

Все настоящие роботы создаются с какой либо целью. Человек стремится облегчить себе жизнь переложив часть своих задач на робота. Робот может выполнять тяжелую физическую работу, например сварочные роботы манипуляторы или транспортные роботы на автоматизированных складах-хранилищах. Или же робот может выполнять потенциально опасные для человека работы, например разминирование или работа в завалах или токсичных, ядовитых средах. Так же робот робот может избавить человека от рутинных задач для экономия времени - робот пылесос, автономный транспорт.

Цель создания робота практически полностью определяет его внешний вид, конструкцию и программу. Обычно робот созданный для работы в одной области не способен работать в какой либо другой. Цель создания нашего робота будет скорее обучающей и развлекательной нежели практической.

Мы попробуем создать робота "офисного питомца". Этакий робот который будет жить с нами в офисе и передвигаться туда куда мы ему скажем при этом робот должен будет самостоятельно ориентироваться в помещении. Кажется что навигация в помещении это легкая задача однако это совсем не так. В дальнейшем мы будем добавлять функционал нашему роботу но начнем именно с этой конкретной задачи.

Итак раз мы решили что робот не стационарный а мобильный то он должен каким то образом передвигаться.

# Привод робота

## Типы приводов

Рассмотрим разные типы приводов мобильных роботов, выясним какую механику эти привода используют, выделим их плюсы и минусы. Затем выберем привод для нашего робота.

Роботы могут передвигаться в 2D или 3D пространстве. Очевидно, роботы способные двигаться в трехмерном пространстве - летающие. Это чрезвычано сложные роботы, например летающие дроны способные ориентироваться в помещении или на местности используя трехмерные камеры глубины. Постойка такого робота требует сложнейшего железа и программного обеспечения поэтому летающего робота мы не рассматриваем.

Если робот передвигается только в двухмерном пространстве то все становится уже проще. Мы можем рассмотреть движение робота как движение материальной точки в плоскости (X, Y) в [прямоугольной или Декартовой системе координат](https://ru.wikipedia.org/wiki/Прямоугольная_система_координат) (X, Y, Z).

В этой плоскости движение робота может быть [голономным](https://ru.wikipedia.org/wiki/Голономная_система) (Holonomic) или [неголономным](https://ru.wikipedia.org/wiki/Неголономная_система) (Non-holonomic). Что это значит? При голономном движении, движение робота не имеет каких либо ограничений и он способен двигаться по любому верктору XY не меняя при этом своей ориентации. При неголономном движении, движение робота ограничено и он может передвигаться только в нескольких направлениях.

![part_1_ru_robot_drive_0_scheme_1.png](../media/part_1/drive_0/schemes/part_1_ru_robot_drive_0_scheme_1.png)

Например, обычный классический автомобиль не может из места переехать строго вправо или влево, значит его движение неголономно. С другой стороны если бы у автомобиля вместо обычных колес стояли [всенаправленные колеса](https://ru.wikipedia.org/wiki/Всенаправленное_колесо) то он смог бы двигаться голономно.

Вы наверное спрашиваете себя "Зачем мне все это нужно знать?". Понимание того каким именно образом двигается робот и понимание принципов получения проекций его скоростей в системе координат чрезвычано важно при создании программы контроллера движения робота. Чем больше направлений движения и вращения имеет робот тем сложнее сконструировать его механику и контролировать его движение.

Еще одиним важным фактором при выборе привода робота является сложность получения одометрии и ее точность.

[Одометрия](https://ru.wikipedia.org/wiki/Одометрия) это использование данных полученных с различных сенсоров и датчиков установленных на роботе для расчета его текущего положения и ориентации в пространстве. С некоторых приводов получить качественную одометрию очень легко, например с двухколесного дифференциального привода (2WD differential drive). Для этого достаточно парочки колесных энкодеров. С других же приводов получить точную одометрию невероятно трудно, например шагающие робо-собаки или роботы гуманоиды. Для одометрии подобных роботов понадобятся десятки различных 2D и 3D сенсоров и сложнейший софт.

Мы попробовали выделить как двигаются самые популярыне хобби роботы.

## Дифференциальный привод двумя ведущими колесами и пассивными колесами

[Двухколесный дифференциальный привод](https://en.wikipedia.org/wiki/Differential_wheeled_robot) это самый простой и распространенный тип привода робота в хобби робототехнике. Именно такой тип привода установлен на домашних роботах пылесосах.

Двухколесное дифференциально шасси состоит из двух ведущих колес установленных на противоположных сторонах корпуса робота и одного или нескольких всенаправленных (пассивных) колес или опор. Каждое ведущее колесо приводится в движение собственным мотором. Моторы управляются независимо друг от друга. Пассивные колеса устанавливаются на такое шасси для достжения равновесия всей платформы.

К слову такой тип привода имеет наша [Робоняша](prod://robonyasha-iskra-js) и [Драгстер](prod://dragster).

Движение двухколесного дифференциально привода неголономно. Движение робота задается линейной скоротью по оси Х (вперед или назад) и угловой скоростью вокруг оси Z (вращение на месте). Синтез этих двух скоротей заставляет робота поворачивать во время движения.

Вот основные типы движения такого робота:

![part_1_ru_robot_drive_1_scheme_1.png](../media/part_1/drive_1/schemes/part_1_ru_robot_drive_1_scheme_1.png)

![part_1_ru_robot_drive_1_scheme_2.png](../media/part_1/drive_1/schemes/part_1_ru_robot_drive_1_scheme_2.png)

![part_1_ru_robot_drive_1_scheme_3.png](../media/part_1/drive_1/schemes/part_1_ru_robot_drive_1_scheme_3.png)

![part_1_ru_robot_drive_1_scheme_4.png](../media/part_1/drive_1/schemes/part_1_ru_robot_drive_1_scheme_4.png)

Особенности шасси:

- Легко сконструировать.
- Легко программировать контроллер движения.
- Легко получить относительно качественную одометрию всего двумя датчиками вращения колес.
- Шасси не предназначено для движения по бездорожью. Любая значительная преграда на пути может вывести двухколесную платформу из равновесия. Чаще всего это шасси используется в помещении и для движения по ровной поверхности.

![part_1_robot_drive_1_showcase_1.jpg](../media/part_1/drive_1/showcase/part_1_robot_drive_1_showcase_1.jpg)

Turtlebot3 от Robotis

![part_1_robot_drive_1_showcase_2.jpg](../media/part_1/drive_1/showcase/part_1_robot_drive_1_showcase_2.jpg)

PAL Robotics

![part_1_robot_drive_1_showcase_3.jpg](../media/part_1/drive_1/showcase/part_1_robot_drive_1_showcase_3.jpg)

Мобильный робот MP-500 от Neobotix

![part_1_robot_drive_1_showcase_4.jpg](../media/part_1/drive_1/showcase/part_1_robot_drive_1_showcase_4.jpg)

The Innok Robotics

## Дифференциальный привод Skid-steer

Привод skid-steer это расширенная версия простого двухколсеного дифференциальный привода. В этом приводе состояние равновесия платформы достигается не пассивными колесами как в двухколесном приводе а дополнительными ведущими. На каждой стороне робота может быть четыре, пять, шесть и более колес. Все колеса на одной стороне робота управляются общим мотором через передачи и вращаются с одинаковой скоростью. Обычно, в этом шасси, так же как и в двухколесном, используются два мотора, но бывают плафтормы где каждое колесо управлятся собственным мотором.
  
Движение привода skid-steer неголономно. Принцип движения такой же как и у двухколесного дифференциального привода.

Пример задания скоростей робота:

![part_1_ru_robot_drive_2_scheme_1.png](../media/part_1/drive_2/schemes/part_1_ru_robot_drive_2_scheme_1.png)

Особенности шасси:

- В сравенении с двухколесной платформой skid-steer обладает большей проходимостью. Это достигается благодаря множеству колес и отсутствии пассивных колес и опор. Робот с большими колесами может быть очень эффективен на пересеченой местности.
- Одометрию так же легко получить используя датчики вращения колес. Однако каждое колесо шасси skid-steer нуждается в собственном сенсоре. Точность одометрии, в сравенении с двухколесной платформой, заметно ниже. При поворотах робота, колеса шасси проскальзывают. При движении такого шасси по ровной местности, моменты заноса и скольжения можно определить и исправить программно. Для получения одометрии при движении skid-steer робота по пересеченной местности одних только датчиков вращения колес может быть уже не достаточно.

![part_1_robot_drive_2_showcase_1.jpg](../media/part_1/drive_2/showcase/part_1_robot_drive_2_showcase_1.jpg)

Husky robot

![part_1_robot_drive_2_showcase_2.jpg](../media/part_1/drive_2/showcase/part_1_robot_drive_2_showcase_2.jpg)

Wild Thumper 6WD by DAGU Electronics

![part_1_robot_drive_2_showcase_3.jpg](../media/part_1/drive_2/showcase/part_1_robot_drive_2_showcase_3.jpg)

The Innok Robotics

## Дифференциальный привод с гусеницами

Дифференциальный привод с гусеницами (танковое шасси) это версия привода skid-steer только с гусеницами вместо дополнительный колес. Как и ранее, каждая гусеница и сторона робота контролируется одним мотором.
Можно интерпретировать этот привод как двухколесный дифференциальный привод где колесо имеет не круглую форму и большую длину окружности. Или как привод skid-steer с бесконечным количеством колес на определенной длине.

Движение привода с гусеницами неголономно. Принцип движения такой же как и у skid-steer привода. В этом случае для расчета скоростей робота используются не угловые скорости колес а скорости гусениц.

Особенности шасси:

- Танковое шасси обладает самыми высокими эксплуатационными характеристиками на пересеченной местности благодаря форме гусениц и сцеплению с землей.
- Усложненная механика. В конструкции танкового шасси множество не простых деталей: части трака, натяжители, опорные колеса и.т.д.
- Получить одометрию еще сложнее, чем при использовании skid-steer привода. Как и при использовании skid-steer привода, при движении танкового шасси происходят проскальзывания гусениц и заносы (особенно это заметно, когда робот танк вращается на месте на ровной поверхности). Однако ввиду наличия всего двух датчиков вращения программно компенсировать ошибки одометрии очень тяжело. Использование датчиков вращения при движении по пересеченой местности практически бесполезно и для одометрии нужны другие источники. При движении по ровной поверхности, одометрия с датчиков вращения не точная.

![part_1_robot_drive_3_showcase_1.jpg](../media/part_1/drive_3/showcase/part_1_robot_drive_3_showcase_1.jpg)

Robodyne MAXXII

![part_1_robot_drive_3_showcase_2.jpg](../media/part_1/drive_3/showcase/part_1_robot_drive_3_showcase_2.jpg)

Tank chassis

![part_1_robot_drive_3_showcase_3.jpg](../media/part_1/drive_3/showcase/part_1_robot_drive_3_showcase_3.jpg)

Dragon Runner Bomb Disposal Robot

## Рулевой привод Аккермана

[Ackermann steering](https://en.wikipedia.org/wiki/Ackermann_steering_geometry) привод - самый распространенный в мире, так как используется в каждом автомобиле. Привод Аккермана состоит из двух ведущих колес и двух рулевых колес. Ведущая пара колес отвечает за движение робота. Рулевые колеса отвечают за поворот робота. Чтобы избежать заноса и скольжения, рулевое управление Аккермана спроектировано таким образом, что при повороте внутреннее колесо поворачивается на больший угол, чем внешнее. Для каждого колеса угол поворота рассчитывается на основе желаемого диапазона углов поворота робота.

Рулевой привод Аккермана имеет неголономное движение. Этот привод управляется линейной скоростью вдоль оси X и угловой скоростью по оси Z. Но в отличие от дифференциальных приводов, при ненулевой угловой скоростью вокруг оси Z, линейная скорость по X не может быть равна нулю. Робот, как и автомобиль не может развернуться стоя на месте.

![part_1_ru_robot_drive_4_scheme_1.png](../media/part_1/drive_4/schemes/part_1_ru_robot_drive_4_scheme_1.png)

Особенности шасси:

- Рулевое управление Аккермана обычно используется на ровной поверхности для быстро движущихся роботов, которые нуждаются в большом дорожном просвете и сцеплении с землей.
- Наличие рулевых вращающихся колес усложняет конструкцию робота и требует дополнительных двигателей и приводов.
- Отличный пример использования этого привода в робототехнике это настоящие беспилотные автомобили. Кроме того, этот привод используется в хобби-робототехнике, если робот построен на базе радиоуправляемой игрушечной машинке.

![part_1_robot_drive_4_showcase_1.jpg](../media/part_1/drive_4/showcase/part_1_robot_drive_4_showcase_1.jpg)

VolksBots

![part_1_robot_drive_4_showcase_2.jpg](../media/part_1/drive_4/showcase/part_1_robot_drive_4_showcase_2.jpg)

RB-CAR by Robotnik

## Привод с Omni колесами

Этот тип привода использует вместо обычных [Omni колеса](https://en.wikipedia.org/wiki/Omni_wheel). Omni колесо - это колесо с небольшими роликами по расположенными по окружности. Оси роликов перпендикулярны оси вращения колеса. С помощью этих колес, контролируя их скорость и направление вращения, вы можете заставить робота двигаться в любом направлении, другими словами, сделать движение робота голономным.

Обычно привод с Omni колесами шасси имеет 3 или 4 колеса.

Шасси с тремя колесами обеспечивает большую тягу, поскольку любая реактивная сила распределяется только через три точки, и робот хорошо сбалансирован даже на неровной местности. Omni колеса имеют высокую стоимость, поэтому шасси с тремя колесами дешевле, чем с четырьмя.

В различных конструкциях трехколесных шасси колеса могут устанавливаться под разными углами. Чаще всего шасси имеет колеса установленные под углом 120° друг к другу. Иногда два колеса параллельны друг другу, а третье колесо перпендикулярно первым двум. Последняя конструкция может быть более эффективной, потому что, когда колеса расположены под углом 120°, только одно колесо является ведущим, а два других по сути тормозят его, заставляя двигаться с меньшей скоростью.

Поскольку колеса на таком шасси не выровнены по осям, каждое колесо требуют индивидуального расчета скорости.

Пример определения векторов скоростей колес для трехколесного шасси:

![part_1_ru_robot_drive_5_scheme_1.png](../media/part_1/drive_5/schemes/part_1_ru_robot_drive_5_scheme_1.png)

Конструкция четырехколсеного шасси имеет четыре ведущих колеса, расположенные под углом 90° друг к другу. Эта конструкция более удобна для расчета скоростей колес, так как два колеса параллельны друг другу, а два других колеса перпендикулярны первым двум. Как и в трехколсеном шасси, КПД всех колес также не используется на 100%. Но в отличие от трехколсеного шасси, здесь есть два ведущих колеса и два свободных. Таким образом, с двумя ведущими колесами четырехколесное шасси движется быстрее, чем трехколесное. Четвертое колесо добавляет шасси еще одну точку опоры, и на неровной местности одно из колес робота может оказаться в воздухе.

Пример определения скорости вращения колес для четырехколесного шасси:

![part_1_ru_robot_drive_5_scheme_2.png](../media/part_1/drive_5/schemes/part_1_ru_robot_drive_5_scheme_2.png)

Особенности шасси:

- Поскольку колеса Omni представляют собой комбинацию из множества роликов, возникает сопротивление вращению, что приводит к более высокому трению и более значительным потерям энергии.
- Не все колеса являются ведущими, в каждый момент времени эффективно работает лишь одно или два Omni колеса.
- С помощью Omni колес достигается голономное движение робота.
- Работа Omni колес изначально строится на принципах проскальзывания. Невозможно поставить датчик вращения на каждый ролик Omni колеса, поэтому полученная одометрия не точная.
- Чаще всего роботы с таким шасси используются внутри помещений и ровных и гладких поверхностях.

![part_1_robot_drive_5_showcase_1.jpg](../media/part_1/drive_5/showcase/part_1_robot_drive_5_showcase_1.jpg)

3WD Omni wheel chassis by NEXUS robot

![part_1_robot_drive_5_showcase_2.jpg](../media/part_1/drive_5/showcase/part_1_robot_drive_5_showcase_2.jpg)

Soccer robots by RoboFEI Team

![part_1_robot_drive_5_showcase_3.jpg](../media/part_1/drive_5/showcase/part_1_robot_drive_5_showcase_3.jpg)

King Kong 4WD Omni Wheel chassis

## Привод с Mecanum колесами

Этот тип привода использует вместо обычных [Mecanum колеса](https://en.wikipedia.org/wiki/Mecanum_wheel). Колесо Mecanum - это разновидность Omni колеса. Mecanum колеса предназначены для грузоподьемных и проходимых роботов. Как и на Omni колесе, на колесе Mecanum ролики расположены по всей окружности обода, но здесь ролики имеют ось вращения под углом 45° к плоскости колеса и 45° к оси вращения колеса.

Поворот оси ролика позволяет использовать колеса Mecanum в приводах skid-steer. Эта комбинация использует преимущества skid-steer привода и привода с всенаправленными колесами. Колеса Mecanum заменяют обычные колеса для достижения голономного движения робота. Чаще всего этот тип привода имеет 4 Mecanum колеса, но иногда шасси может иметь и шесть колес.

При вращении Mecanum колеса к его вращению прилагается сила под углом 45°. Направление вращения определяет направление приложенной силы. Комбинации сил от всех колес позволяют роботу двигаться в разных направлениях.

Вгляните на схемы получения скоростей робота:

![part_1_ru_robot_drive_6_scheme_1.png](../media/part_1/drive_6/schemes/part_1_ru_robot_drive_6_scheme_1.png)

![part_1_ru_robot_drive_6_scheme_2.png](../media/part_1/drive_6/schemes/part_1_ru_robot_drive_6_scheme_2.png)

![part_1_ru_robot_drive_6_scheme_3.png](../media/part_1/drive_6/schemes/part_1_ru_robot_drive_6_scheme_3.png)

![part_1_ru_robot_drive_6_scheme_4.png](../media/part_1/drive_6/schemes/part_1_ru_robot_drive_6_scheme_4.png)

Особенности шасси:

- Привод с Mecanum колесами используется если робот должен обладать голономным движением и высокой грузоподьемностью.
- Чаще всего роботы с эти типом шасси это грузовые роботы, которые работают на ровной и гладкой поверхности. При использовании такого шасси на бездорожье, управление движением и получение качественной колесной одометрии с датчиков вращения может крайне труднено.

![part_1_robot_drive_6_showcase_1.jpg](../media/part_1/drive_6/showcase/part_1_robot_drive_6_showcase_1.jpg)

Kuka robot

![part_1_robot_drive_6_showcase_2.jpg](../media/part_1/drive_6/showcase/part_1_robot_drive_6_showcase_2.jpg)

Mobile Robot MPO-500 by Neobotix

![part_1_robot_drive_6_showcase_3.jpg](../media/part_1/drive_6/showcase/part_1_robot_drive_6_showcase_3.jpg)

SUMMIT-XL STEEL by Robotnik

## Скелетные роботы

Эти роботы используют конечности или ноги, чтобы двигаться. Движение таких роботов имитирует естественное движение живого организма.

Роботы на конечностях обладают голономным движением, также как и живые организмы, кинематику которых они повторяют. Например, робот-гексапод может идти в любом направлении, не меняя ориентацию своего тела.

Подобные роботы являюстя самыми мобильными но и самыми сложными в конструировании. Скелет конечности должен обладать множеством стенепенй свободы. Для этого требуется множество двигателей, приводов а так же сложные системы управления движеним. Из за большого количества приводов, скелетные роботы потребляют больше всего энергии. Для получение одометрии с шагающего шасси используется синтез данных с множества различных сенсоров (энкодеры приводов, IMU сенсоры, 3D лидары, 3D RGB камеры глубины, контактные датчики давления и.т.д) а так же машинное обучение.

![part_1_robot_drive_7_showcase_1.jpg](../media/part_1/drive_7/showcase/part_1_robot_drive_7_showcase_1.jpg)

Agility Robotics

![part_1_robot_drive_7_showcase_2.jpg](../media/part_1/drive_7/showcase/part_1_robot_drive_7_showcase_2.jpg)

Spot by Boston Dynamics

## Другие типы приводов

В действительности, в хобби-робототехнике, существует великое множество различных уникальных приводов движения. Все они используются крайне редко. Вот лишь некоторые из не упомянутых выше:

- Segway drive - дифференциальный двухколесный привод без пассивных колес. Равновесное состояние робота достигается с помощью датчиков и контроллеров. Пример - автономный сегвей.
- Forklift steering drive - разновидность рулевого привода Аккермана но с задней парой рулевых колес и передней парой ведущих.
- Independent drive - это привод, в котором все колеса являются ведущими и рулевыми одновременно. Колес может быть четыре, шесть и более. Пример - марсоход.
- Articulated drive - разновидность рулевого привода Аккермана. Для того чтобы повернуть роботом в движении Articulated drive не поворачивает рулевые колеса а деформирует всю рулевую часть рамы или шасси.
- Ball drive - привод при котором, робот балансирует и перемещась на сфере.
- Ползучие червеобразные и змееподобные роботы движение которых основано на трении тела робота с поверхностью.

# Выбор шасси

Шасси робота напрямую зависит от выбранного типа привода. Мы выбрали двухколесный дифференциальный привод с пассивными колесами. Такой же привод используется в домашних роботах-пылесосах, а они как никто лучше справляются с задачей ориентации в помещении. Кроме того, это самое бюджетное шасси и самое простое в программировании.

При выборе типа привода мы руководствовались эффективностью колесной одометрии. Самая простая одометрия робота, которую вы можете получить - это датчики вращения, установленные на колесах. Обычно, такие датчики скорости представляют собой энкодеры, установленные на валах колес, валах двигателей или валах коробок передач.

Сперва мы попробовали танковое шасси [Rover 5](prod://rover-5-chassis) с резиновыми гусеницами. Установили дополнительные двигатели и энкодеы на колеса. Но, как оказалось, получить качественную одометрию только с помощью энкодеров довольно сложно. Когда робот вращается на месте и на высоких скоростях, гусеницы регулярно проскальзывают, и результирующая одометрия отличается от фактического положения робота. Поэтому мы решили начать с более простого шасси.

Вы можете сначала выбрать тип привода, который вам нравится, а затем самостоятельно построить шасси робота для этого типа. Или наоборот, купить готового шасси для робота и написать программу контроллер под него.

Чтобы самостоятельно собрать качественное робо-шасси, нужно обладать некоторыми навыками проектирования машин, разбираться в материалах, комплектующих и умело работать руками. Собранное своими руками шасси дает вам полное знание всех его деталей, узлов, ключевых моментов и слабых мест. Чем сложнее тип привода и шасси, тем больше вероятность, что вам придется собирать его самостоятельно.

С другой стороны, многие производители предоставляют высококачественные шасси для хобби робототехники. Если вы приобретете готовое шасси, то сможете сэкономить много времени на механической составляющей робота и потратить это время на электронную и программную часть.

**Это важно!** При покупке готового шасси выбирайте наиболее документированное, с маркировкой деталей, информацией о двигателях и полными чертежами основных деталей и компонентов в САПР.

## Шасси Turtle

В нашем роботе мы решили использовать двухколесный диффернциальный привод и робо-платформу [Turtle](prod://turtle-chassis) от DFRobot.

![part_2_prod_chassis_1.jpg](../media/part_2/prod/part_2_prod_chassis_1.jpg)

Это шасси для небольшого робота. Рама изготовлена из металла и состоит из 2 согнутых листовых металлических пластин. Обе пластины имеют перфорацию и вырезы для установки электроники. Шасси поставляется с двумя [Мотор-редукторами типа TT с двухсторонним валом (160 об / мин 6 В L-образной формы)](https://www.dfrobot.com/product-100.html), два пластиковых колеса диаметром 65 мм и [15-миллиметровое стальное шариковое колесо](https://www.dfrobot.com/product-225.html). Этот комплект шасси также содержит много других деталей и креплений, но они нам не нужны. Нам нужна только рама шасси.

![part_2_prod_chassis_2.jpg](../media/part_2/prod/part_2_prod_chassis_2.jpg)

Это не дорогое шасси, но и не самого лучшего качества:

- Данное шасси слабо документировано. Мы не нашли чертежи шасси в открытом доступе.
- Покрышки колес, которые идут в комплекте, пластиковые и бесполезные, потому что у них почти нет сцепления с землей. Мы сразу же заменили их резиновыми шинами от того же производителя - [Резиновое колесо для 4WD и 2WD (пара)](https://www.dfrobot.com/product-352.html).
- 1:120 Коробки передач моторов типа TT имеют пластиковые шестерни. Было бы лучше, если бы коробка передач была сделана из металла.
- Двигатели постоянного тока работают без обвязки и генерируют значительное количество электромагнитных наводок. На полной скорости эти двигатели существенно влияют на работу близлежащих аналоговых и цифровых электронных устройств.

Подводя итог, можно сказать, что это шасси не предел мечтаний, но оно доступно и популярно в хобби-робототехнике. Выбирая не дорогое шасси, будьте готовы приобрести ответственные детали и комплектующие или изготовить их самостоятельно.

## Энкодеры

Для колесной одометрии нам понадобятся датчики угла поворота или [энкодеры](https://en.wikipedia.org/wiki/Rotary_encoder). Часто готовые шасси уже имеют энкодеры, но эта платформа поставляется без них. По типу отдаваемых данных энкодеры могут быть [абсолютными](https://en.wikipedia.org/wiki/Rotary_encoder#Absolute_encoder) или [инкрементный](https://en.wikipedia.org/wiki/Incremental_encoder).

Абсолютный энкодер выдает сигнал, который однозначно соответствует углу поворота вала. Энкодеры этого типа не требуют привязки системы отсчета к какому-либо нулевому положению.

Инкрементный энкодер генерирует импульсы на выходе. Контроллер подсчитывает количество импульсов с помощью счетчика и определяет текущее положение вала. Сразу после включения контроллера положение вала неизвестно. Существует специальная нулевая отметка, через которую вал должен пройти после включения. Эта метка используется для привязки системы отсчета к нулевой позиции. Основным недостатком энкодеров такого типа является невозможность определить пропуск импульса, вызванный какой-либо причиной. Пропуски импульсов накапливают погрешность в угле поворота вала до тех пор, пока не будет пройдена нулевая отметка. Инкрементный кодер может быть без нулевой отметки. В этом случае отсчет импульсов, полученный в начале накопления, является началом системы отсчета.

По типу действия энкодеры могут быть оптическими, магнитными и механическими. Оптический энкодер использует свет, падающий на фотодиод через щели в металлическом или стеклянном диске, установленном на вращающемся валу. Механический энкодер также имеет вращающийся диск, но здесь угол считывают механические переключатели или контакты. Магнитные энкодеры имеют магнит, установленный на вращающемся валу. Эти энкодеры используют датчики Холла для считывания вращения вала с магнитом.

В основном в хобби-робототехнике используются оптические и магнитные инкрементные энкодеры или магнитные абсолютные энкодеры. Не имеет значения, какой тип энкодера использовать. При выборе энкодера основными параметрами являются количество каналов передачи данных, количество импульсов на оборот (PPR) и максимально допустимая скорость вращения вала.

Наиболее популярны квадратурные энкодеры с двумя каналами А и В. Редко у энкодеров хобби есть канал с нулевой отметкой - Z. Чем выше значение PPR, тем меньше угол поворота вала, который может зафиксировать датчик. Чем точнее энкодер, тем точнее одометрия робота, поэтому не пренебрегайте высококачественными энкодерами и не используйте энкодеры с низким значением PPR. Максимальная скорость вращения может быть любой, так как большинство энкодеров способно работать на очень высоких скоростях. Скорее всего, скорость вращения, которую вы будете измернять, будет в несколько раз меньше максимальной. Даже если вы планируете использовать высокоскоростные BLDC двигатели с высоким значением kv, то существуют энкодеры работающие с максимальными скоростями 28000 об/мин, 60000 об/мин или даже больше.

Если вы используете двигатель с коробкой передач, установите поворотный энкодер на вал двигателя, а не на вал колеса или коробки передач. Это важно. Эта настройка уменьшает минимальный читаемый угол поворота колеса и делает вашу одометрию более точной. Энкодеры могут устанавливаться и на оси передач и редукторов но обычно это делается в приводах скелетных роботов.

Мы обзавелись двумя такими двигателями с энкодерами - [Мотор-редуктор TT с энкодером (6V 160RPM 120:1 L Shape)](https://www.dfrobot.com/product-1458.html)

![part_2_prod_chassis_3.jpg](../media/part_2/prod/part_2_prod_chassis_3.jpg)

Почему мы выбрали именно эти моторы?

- Во-первых, их конструкция специально разработана для нашего Turtle шасси, и нам не придется придумывать крепление.
- Во-вторых, производитель исправил существенные недостатки, заменил пластиковые шестерни металлическими и добавил схему двигателя обвязку.
- Эта сборка имеет квадратурный магнитный энкодер с разрешением 16 PPR. Энкодер установлен на валу двигателя. Передаточное отношение 120:1 дает полное разрешение в 1920 импульсов на оборот колеса с минимальным измеряемым шагом в 0°11'15". Для поставленной нам задачи такой точности более чем достаточно.

Заменив моторы и убрав все лишнее, мы получил вот такое шасси:

![part_2_irl_chassis_1.jpg](../media/part_2/irl/part_2_irl_chassis_1.jpg)

![part_2_irl_chassis_2.jpg](../media/part_2/irl/part_2_irl_chassis_2.jpg)

![part_2_irl_chassis_3.jpg](../media/part_2/irl/part_2_irl_chassis_3.jpg)

![part_2_irl_chassis_4.jpg](../media/part_2/irl/part_2_irl_chassis_4.jpg)

# ROS

Мы разобрались с шасси. Давайте начнем разбираться в программном обеспечении. Для настоящих роботов классические программы микроконтроллеров нам не подходят. Вместо этого мы используем ROS.

[ROS(Robot Operation System)](https://www.ros.org) - это [операционная система](https://en.wikipedia.org/wiki/Operating_system) для роботов. ROS обеспечивает весь необходимый функционал для распределенной работы всех узлов робота. На самом деле ROS-это библиотека, надстройка поверх компьютерной операционной системы. ROS предоставляет стандартные услуги операционной системы, такие как аппаратная абстракция, низкоуровневое управление устройствами, реализация часто используемых функций, передача сообщений между процессами и управление пакетами.

ROS имеет графовую архитектуру, где обработка данных происходит в узлах - нодах (`nodes`), которые могут принимать и передавать сообщения между собой. ROS состоит из двух частей. Первая, это ядро - `roscore`. Ядро отвечает за работу системы и взаимодействие всех пакетов. Вторая часть - это пользовательские пакеты (`packages`) или наборы этих пакетов, организованных в стек.

Пакетов очень и очень много. Поскольку ROS-это проект с открытым исходным кодом, благодаря сообществу уже написало большинство пакетов, реализующих стандартные функции роботов.

Вот почему мы используем ROS. Из-за наличия готовых пакетов. Тем не менее, некоторые ноды нам придется написать самостоятельно, например низкоуровневые драйверы, но большая часть программного обеспечения уже сделана. Нам лишь нужно только собрать все это вместе.

Сам ROS и большинство его пакетов очень хорошо документированы. Вы можете найти ответы практически на любые вопросы в [ROS wiki](http://wiki.ros.org). Для ознакомления с разработкой под ROS настоятельно рекомендуем вам ознакомиться с ROS wiki.

ROS содержит множество пакетов для создания виртуального робота и моделирования его поведения, например стек пакетов [`gazebo_ros_pkgs`](http://wiki.ros.org/gazebo_ros_pkgs).

Изначально ROS предназначен для постройки сложных роботов, которые могут стоить тысячи долларов. Поэтому, прежде чем тратить финансы на какие - либо реальные дорогостоящие физические детали и узлы робота, ROS предлагает - сначала смоделировать робота в виртуальной среде и только потом реализовать его в реальном мире.

Мы сделаем все наоборот. Мы сделаем робота из дешевых деталей, которые у нас уже есть. Не будем использовать симуляцию, но настроим ROS для моего конкретного робота.

Чтобы использовать программное обеспечение ROS эффективно и для мониторинга, лучше установить его на две разные машины. Первая машина с ROS - это ваш настольный компьютер под управлением ОС Linux. Вторая машина - это бортовой компьютер, установленный на роботе, также работающем под управлением Linux. Позже мы свяжем эти две машины, и ROS будет работать в сети.

Предположим, что у вас уже есть настольный компьютер. Теперь вам нужно рзобраться с бортовым.

# Бортовой компьютер

## Выбор железа

Итак, робот работает на ROS, ROS работает на Linux. Давайте выберем для робота бортовой компьютер работающий на OS Linux.

Большие мобильные роботы способные нести большую нагрузку имеют на борту большие и мощные компьютеры. Если не стоит вопрос в размере боротвого компьютера то чаше всего на робота устанавливают мощный бортовой ноутбук. Наш робот маленький. На нем нет места для кучи оборудования и нечем это оборудование питать. Поэтому мы и используем [одноплатный компьютер](https://en.wikipedia.org/wiki/Single-board_computer). Сегодня существует множество одноплатных компьютеров. Самые популярные это:

- [Raspberry Pi Zero, 3, 4](https://www.raspberrypi.org) - это самые популярные платы. Изначально Raspberry Pi предназначен для обучения программированию и Linux. Эти платы самые дешевые. Семейство Raspberry Pi имеет множество реплик и копий платы оригинала дополненного различными периферийными интерфейсами и устройствами для любой задачи - Orange Pi, Rock Pi, Banana Pi.
- [NVIDIA Jetson Nano Developer Kit](https://www.nvidia.com/ru-ru/autonomous-machines/embedded-systems/jetson-nano/) - это самая многофункциональная плата. Она может быть использована для настольного ПК, но изначально предназначена для разработки мобильного искусственного интеллекта и машинного обучения. Эта плата использует мощный графический процессор из множдества ядер NVIDIA для вычислений.
- [Coral Dev Board](https://coral.ai/products/dev-board/) - это лучшая плата машинного обучения с использованием фреймворка Tensorflow. Плата специально разработана для работы с нейронной сетью TensorFlow Lite для микроконтроллеров.
- [ODYSSEY X86J4105800](https://www.seeedstudio.com/ODYSSEY-X86J4105800-p-4445.html) - самый большой и мощный одноплатник. Он способная работать под полноценной Windows 10 и имеет все функции настольного ПК.
- [Rock Pi N10](https://wiki.radxa.com/RockpiN10) - лучшая плата для машинного обучения. Эта плата имеет вычислительную мощность до 3,0 Терафлопс.

Вы можете выбрать любой одноплатник для робота. Тщательно выясните особенности каждой конкретной платы и определите ту, которая подходит вам лучше всего.

Мы не планируюем заниматься машинным обучением или выполнять массивные вычисления, а это означает, что почти любой негабаритный одноплатник подходит для нашего робота.

Мы выбрали [Raspberry Pi 4 Model B на 4 ГБ](prod://raspberry-pi-4-model-b-4-gb). Плата Raspberry Pi 4 может сильно нагреваться, так что мы установили на нее [пару алюминиевых радиаторов](prod://heatsink-passive-raspberry-pi) для пассивного охлаждения.

![part_3_irl_mcu_1.jpg](../media/part_3/irl/part_3_irl_mcu_1.jpg)

Подключите любую клавиатуру и мышь к USB-портам платы. Подключите любой дисплей или монитор с помощью кабеля micro-HDMI. 

![part_3_irl_mcu_2.jpg](../media/part_3/irl/part_3_irl_mcu_2.jpg)

Все это нам нужно для установки программного обеспечения и отладки программ в первый раз. Позже мы не будем использовать мышь, клавиатуру или дисплей, так как будем работать с Raspberry Pi по сети с помощью SSH.

Производитель одноплатника рекомендует использовать источник питания 3 А и более. Когда мы установим Raspberry Pi на робота, мы обеспечим плату достаточным напряжением и током, но в первый раз мы можем запитать плату от любого источника питания USB через кабель USB Type-C, например от [импульсного блока питания Ginzzu GA-3311UW](prod://usb-power-plug-3a)

***Важно*** Помните! Плату Raspberry Pi 4 с установленной в нее картой памяти не следует выключать просто отключив ее от питания. Выключайте плату правильно, средствами операционной системы.

## Выбор и установка дистрибутива Linux

Прежде чем выбрать ОС для установки, вам нужно выбрать, какую версию ROS использовать. ROS [выпускает дистрибутивы](http://wiki.ros.org/Distributions) для различных операционных систем и архитектур - Ubuntu, Debian, Windows, других ОС Linux. Глобальные обновления ROS основаны на глобальных обновлениях ОС Ubuntu. Вскоре после выходна новой версии Ubuntu появляется и новая версия ROS. Предыдущие версии ROS продолжают поддерживаться до тех пор, пока поддерживается дистрибутивы Ubuntu, для которого они были созданы ([EOL](https://en.wikipedia.org/wiki/End-of-life_(продукт))). На момент написания этого руководства нам доступны два поддерживаемых дистрибутива ROS:

- [ROS Melodic Morenia](http://wiki.ros.org/melodic) нацеленная на [Ubuntu 18.04 (Bionic)](https://releases.ubuntu.com/bionic/). Поддерживает Ubuntu 17.10 (Artful). Дата релиза - 23 мая 2018. Дата конца поддержки - май 2023 (Bionic).
- [ROS Noetic Ninjemys](http://wiki.ros.org/noetic) нацеленная на [Ubuntu 20.04 (Focal)](https://releases.ubuntu.com/focal/). Дата релиза - 23 мая 2020. Дата конца поддержки - май 2025 (Focal).

Официальная документация [рекомендует](https://www.ros.org/install/) установку последней версии ROS - Noetic для последней версии Ubuntu ОС - Focal. ROS живет благодаря сообществу. Если ядро обновляется всегда вовремя то обноваление и поддержка различных пакетов может запаздывать. Обратите внимание, что некоторые интересные пакеты все еще не обновлены для новой версии Noetic, и вам, возможно, придется собирать их вручную.

Перейдем в раздел установки ROS Noetic и взглянем, какие OS и какие [архитектуры](https://en.wikipedia.org/wiki/Comparison_of_instruction_set_architectures) мы можем использовать:

- Ubuntu Focal на `amd64`, `armhf`, `arm64`.
- Debian Buster на `amd64`, `arm64`.
- Windows 10 на `amd64`.
- Не гарантировано, любой дистрибутив Linux на `amd64`, `i686`, `arm`, `armv6h`, `armv7h`, `aarch64`.

Raspberry Pi 4 B имеет набор инструкций ARMv8-A и поддерживает 32-разрядные и 64-разрядные вычисления. Обычно пользователи устанавливают 32-разрядную ОС на Raspberry. Однако у нашей малины 4 ГБ оперативной памяти, (и, кстати, может быть и 8 ГБ). С таким объемом оперативной памяти вы можете попробовать 64-разрядную ОС. С определенными задачами 64-разрядная версия ОС будет справляться быстрее.

Для ROS Noetic мы устанавливаем на одноплатник Ubuntu Server 20.04.2 arm64. Для хранения ОС вам понадобится флэш-накопитель microSD. Чем больше емкость карты, и ее класс тем лучше. Мы использовали [microSD карточку на 16 ГБ](prod://microsd-16gb).

Скачайте образ ОС. Перейдите на официальный сайт [Ubuntu](https://ubuntu.com). Затем перейдите в раздел **Downloads → Ubuntu for IOT → [Raspberry Pi 2, 3 or 4](https://ubuntu.com/download/raspberry-pi)**. Загрузите образ 64-разрядной ОС Ubuntu Server для `arm`.

Установите программу для создания загрузочных флэш-дисков. Мы используем официальную программу от Raspberry - Raspberry Pi Imager. Перейдите на официальный сайт [Raspberry website](http://www.raspberrypi.org). Затем перейдите в раздел **Downloads → Raspberry Pi Imager**. Загрузите и установите [Raspberry Pi Imager](https://www.raspberrypi.org/software/) для вашей ОС.

Вставьте SD-карту в компьютер и отформатируйте ее.

Запустите Raspberry Pi Imager. Затем войдите в меню **Operating system** menu and select **Use custom**.

![part_4_linux_install_1.png](../media/part_4/part_4_linux_install_1.png)

Укажите путь к скаченному образу Ubuntu, затем путь к вашей флеш карте и нажмите кнопку **Write**.

![part_4_linux_install_2.png](../media/part_4/part_4_linux_install_2.png)

![part_4_linux_install_3.png](../media/part_4/part_4_linux_install_3.png)

Когда запись ОС завершена вставьте microSD флешку в Raspberry Pi и включите плату подав на нее питание.

## Первый запуск

Убедимся, что Linux работает. При первой загрузке Ubuntu логин - `ubuntu`, пароль - `ubuntu`. При первом входе, ОС просит нас изменить стандартный пароль. Установите новый. Обратите внимание: пароль не может быть палиндромом; это одна из стандартных настроек ОС Ubuntu Server. 

```bash
Ubuntu 20.04.2 LTS ubnutu tty1

ubuntu login: ubuntu
Password:
You are requested to change your password immediately (root enforced)
Changing password for ubuntu.
(current) UNIX password:
Enter new UNIX password:
Retype new UNIX password:
Welcome to Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-1015-raspi aarch64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Wed Apr 1 17:25:35 UTC 2020

  System load:  0.27                Swap usage:  0%          Users logged in: 0
  Usage of /:   12.8% of 14.03GB    Temperature: 46.7 C 
  Memory usage: 6%                  Processes:   134

0 packages can be updated.
0 updates are security updates.

The programs included with the Ubuntu system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by
applicable law.

To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.

ubuntu@ubuntu:~$
```

Пароль для `root` не установлен в Ubuntu по умолчанию, и вход в систему пользователя `root` отключен. Включим учетную запись `root` и установим для нее пароль. Затем переключимся на `root`: 

```bash
sudo passwd root
su root
```

При желании вы можете переименовать стандартное имя текущего хоста в более привлекательное. Мы назовем бортовой компютер `robot`.

Отредактируем файл `/etc/hostname` и заменим `ubuntu` на `robot`:

```bash
nano /etc/hostname
```

Затем перезагрузимся и снова войдите в систему под `root`: 

```bash
reboot now
```

## Настройка Wi-Fi и графической оболочки

Теперь нам нужно подключиться к Интернету через Wi-fi адаптер на Raspberry. Предполагается, что у вас уже есть точка доступа Wi-Fi. 

Первый шаг - определить имя вашего беспроводного сетевого интерфейса. Имя интерфейса беспроводной сети может быть разное но обычно это `wlan0`: 

```bash
ls /sys/class/net/
```

Затем перейдем в каталог `/etc/netplan` и найдем соответствующие файлы конфигурации Netplan. Файл конфигурации имеет имя типа `50-cloud-init.yaml`: 

```bash
ls /etc/netplan/
```
Отредактируем файл конфигурации Netplan: 

```bash
nano /etc/netplan/50-cloud-init.yaml
```

Весь файл конфигурации должен выглядеть примерно так, как показано ниже. Убедитесь, что все блоки кода выровнены. Для выравнивания используйте пробелы вместо табуляции. Замените строки `SSID` и `PASSWORD` на имя и пароль вашей сети Wi-Fi.

```bash
# This file is generated from information provided by the datasource.  Changes
# to it will not persist across an instance reboot.  To disable cloud-init's
# network configuration capabilities, write a file
# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:
# network: {config: disabled}
network:
    ethernets:
        eth0:
            dhcp4: true
            optional: true
    version: 2
    wifis:
        wlan0:
            optional: true
            access-points:
                "SSID":
                    password: "PASSWORD"
            dhcp4: true
```

Запустим службу, перезагрузимся и войдем в систему:

```bash
systemctl start wpa_supplicant
reboot now
```

Применим изменения Netplan и подключимся к беспроводной сети: 

```bash
sudo netplan generate
sudo netplan apply
```

Еще раз перезагрузимся и снова войдем в систему. Теперь наша Raspberry в сети Wi-Fi, и мы можем пропинговать наш сетевой шлюз: 

```bash
ip addr show
ping 192.168.88.1
```

Следующим шагом будет установка графического интерфейса для удобства работы с OS. Обновим список пакетов из репозитория, обновим пакеты их и установим любую понравившуюся графическую оболочку. Например, мы выбрали [XFce](https://en.wikipedia.org/wiki/Xfce): 

```bash
sudo apt-get update && apt-get upgrade
sudo apt-get install xubuntu-desktop
```

Установка графической оболочки может занять некоторое время. После установки перезагрузимся и войдите в систему под `ubuntu`. 

# Установка и настройка ROS

Мы установим ROS на две машины, на Raspberry Pi и на десктопный компьютер. Затем мы обьединим ROS на этих компьютерах в единую сеть.

Зачем нужно два компьютера с ROS? Разработка программного обеспечения для робота тесно связана с ресурсоемкой визуализацией. Работа с графикой, трехмерными обьектами и визуализация на Raspberry существенно тормозит разработку ПО.

Кроме этого некоторые поставленные нами задачи, например навигация в помещении, очень сложные и требуют большие вычислительные мощности. Выполнение подобных задач на  Raspberry может быть очень медленно а то и вовсе невыполнимо.

Если бы вместо Raspberry Pi на нашем роботе стоял мощный ноутбук, то мы смогли бы вести весь проект от начала и до конца на одной ROS машине. В нашем случае, ROS на роботе будет оперировать простыми вычислениями и поддерживать работу драйверов низкого уровня а десктопный компьютер с ROS будет осуществлять трудоемкие вычисления и визуализацию. 

## Установка ROS на Raspberry

Установим ROS Noetic на Raspberry так как рекомендуется в [installation guide for ROS Noetic](http://wiki.ros.org/noetic/Installation/Ubuntu). Откроем новый терминал и продолжим под юзером `ubuntu`.

Настроим Raspberry на прием программного обеспечения из репозитория [packages.ros.org](http://packages.ros.org/):

```bash
sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
```

Настраиваем ключи:

```bash
sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654
```

Обновим список пакетов:

```bash
sudo apt-get update
```

Установим полную версию ROS используя стек пакетов `ros-noetic-desktop-full`:

```bash
sudo apt install ros-noetic-desktop-full
```

Настраиваем переменные окружения ROS и автоматически добавляем их в bash сеанс при каждом новом запуске Ubuntu:

```bash
echo "source /opt/ros/noetic/setup.bash" >> ~/.bashrc
source ~/.bashrc
```

Установим пакет `rosdep`. `rosdep` позволяет вам легко устанавливать системные зависимости для исходного кода, который вы хотите скомпилировать, и необходим для запуска некоторых основных компонентов в ROS:

```bash
sudo apt-get install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wsstool build-essential
```

Инициализируем `rosdep`:

```bash
sudo rosdep init
rosdep update
```

Убедимся, что ROS на Raspberry работает. Откроем новый терминал и запустим ядро ROS:

```bash
roscore
```

![part_5_rpi_side_screen_1.png](../media/part_5/rpi_side/part_5_rpi_side_screen_1.png)

## Установка ROS на десктопный компьютер

Установка ROS на десктопном компьютере ничем не отличается от установки ROS на Raspberry. Установка версии ROS по-прежнему зависит от операционной версии системы Linux, установленной у вас на десктопном компьютере.

Наш десктопный компьютер работает под Ubuntu 20.04.1 LTS Focal поэтому на него мы так же устанавливаем ROS Noetic.

## Создание рабочего пространства ROS

Прежде чем создавать рабочее пространство, мы настоятельно рекомендуюем вам прочитать [уроки ROS для начинающих](http://wiki.ros.org/ROS/Tutorials). Это отличная документация. В первый раз документация может показаться сложной и непонятной. Со временем, когда вы привыкнете к ROS, официальная документация ответит вам на все возникающие вопросы. Ознакомьтесь с документаций и, для начала, попытайтесь понять некоторые основные принципы ROS:

- Что такое переменные среды ROS?
- Как выглядит файловая система ROS и какова структура пакета ROS?
- Что такое ноды или узлы (`nodes`), темы (`topics`), сервисы (`sevices`), сообщения (`messages`), издатели (`publishers`), подписчики (`subscribers`)?
- Каким образом все описанные выше обьекты взаимодействуют друг с другом?

Создадим новое рабочее пространство ROS. Рабочее пространство ROS - это место, где вы храните все программное обеспечение робота или проекта: пакеты с нодами, исполняемые файлы, файлы конфигурации, файлы описаний и прочее. На самом деле рабочее пространство - это просто папка в файловой системе Linux. 

Мы назвали наше рабочее пространство `ros`. Пакеты с исходным кодом должны находиться в подкаталоге `src`.

```bash
mkdir -p ~/ros/src
cd ~/ros/
```

Рабочее пространство в настоящее время пусто, давайте соберем его с помощью [catkin](http://wiki.ros.org/catkin). Это удобный инструмент для компиляции исходного кода C++ или Python, создания исполняемых файлов, связывания пакетов, и этот инструмент регулярно используется при работе с ROS.

```bash
catkin_make
```

Взгляните в каталог рабочего пространства. Теперь там появились папки `build` и `devel`. В папке `build` хранятся исполняемые файлы, бинарные файлы и файлы сборки. Папка `devel` содержит множество сгенерированных файлов setup.*sh, которые используются для наложения рабочей области ROS поверх среды Linux.

## Процесс разработки

Поскольку мы используем ROS на двух компьютерах то и рабочее пространство нужно создать на обоих машинах. И там и там нужно держать одинаковые и актуальные файлы вашего проекта. Да, звучит не очень удобно, но такова цена за использование двух машин вместо одной. 

Добиться актуализации данных и синхронизировать рабочие пространсва на декстопном компьютере и Raspberry можно используя `git` или различные утилиты типа `rsync`.

Далее, если мы производим какие нибудь изменения в рабочем пространсве `ros` то подразумевается что эти изменения выполнены как на Raspberry так и на десктопном компьютере. Наш проект будет храниться в одинаковом виде в двух местах. Но, на разных машинах, мы будем запускать разные части нашего проекта.

## Настойка локальной сети и сети ROS

Настроим общение по сети между десктопным копьютером и Raspberry а так же обьединим ROS на обоих в компьютерах в сеть. В [вики ROS](http://wiki.ros.org) есть подробная статья о настройки [ROS на нескольких машинах](http://wiki.ros.org/ROS/Tutorials/MultipleMachines).

Узнаем IP адреса Raspberry и IP адрес дектопного компьютера в локальной сети. У нас десктопный компютер имеет адрес в сети `192.168.88.24` а Raspberry `192.168.88.82`. IP адрес можно узнать утилитами `ip addr` или `ifconfig`

Десктопный компьютер имеет имя `robot-user` а Raspberry имя `robot`. Имена можно посмотреть в файле `/etc/hostname`.

Отредактируем `etc/hosts` на обоих машинах:

```bash
sudo nano /etc/hosts
```
Добавим в этот файл несколько строк:

```bash
192.168.88.24 robot-user
192.168.88.82 robot
```

В сети ROS может быть запущено только одно ядро `roscore`. Именно машина с запущенным ядром отвечает за работу всей системы. Такая машина в сети ROS будет являться `master` а остальные машины `slave`. Мы в качестве `master` выбираем десктопный компьютер `robot-user`. Для всех ROS в сети нужно указать какая именно машина является мастером. 

Добавим новые сетевые переменные окружения ROS в автозапуск. Сперва на десктопном компьютере:

```bash
echo "ROS_MASTER_URI=http://robot-user:11311" >> ~/.bashrc
echo "ROS_HOSTNAME=robot-user" >> ~/.bashrc
echo "ROS_IP=192.168.88.24" >> ~/.bashrc
```

А затем на raspberry:

```bash
echo "ROS_MASTER_URI=http://robot-user:11311" >> ~/.bashrc
echo "ROS_HOSTNAME=robot" >> ~/.bashrc
echo "ROS_IP=192.168.88.82" >> ~/.bashrc
```

Перезагрузим обе машины и протестируем сеть ROS.

Запустим ядро на десктопной машине:

```bash
roscore
```

![part_5_desk_side_screen_1.png](../media/part_5/desk_side/part_5_desk_side_screen_1.png)

Как мы видим из лога ядро ROS запустилось на машине которая имеет в сети имя `robot-user`. А значит мы уже можем увидеть ядро в сети. На Raspbery проверим появились ли какие либо топики ROS:

```bash
rostopic list
```

У нас появились два системных топика ROS. Это значит что ROS на Raspberry видит наш мастер. 

![part_5_rpi_side_screen_1.png](../media/part_5/rpi_side/part_5_rpi_side_screen_2.png)

SSH!!! TODO

# Описание робота (Robot Description)

Пришло время дать нашему роботу имя. Мы решили назвать нашего робота - `abot`, акроним от Amberka Bot.

Имя робота очень важно так как имя является своего рода пространством имен (`namespace`) при работе с программным обеспечением.

Человек, работающий с роботом, может физически взаимодействовать с ним. В любой момент вы можете потрогать робота, взглянуть на части из которых он состоит, взвесить его или снять размеры с его деталей. То есть у вас есть к нему доступ.

Программное обеспечение для робота также должно иметь полный доступ к роботу в любой момент времени. Для этого программе необходимо предоставить полное описание реального робота.

## Формат URDF

Для описания роботов существют различные форматы. ROS использует формат [URDF (Unified Robot Description Format)](http://wiki.ros.org/urdf). Этот формат является специализацией формата [XML](https://en.wikipedia.org/wiki/XML). 

С помощью URDF можно описать каждую часть реального робота. Чем лучше описание робота, тем больше программных функций можно использовать, например, для физического моделирования. Детали робота - сегменты (links), сочленения (joints), датчики (sensors) организованы в виде дерева. Описание URDF может различается в зависимости от реализации, но есть несколько основных элементов: 

- `<link>` - описывает кинематические и динамические свойства жесткой инерционной детали робота (абслолютно твердого тела). Элемент также может включать визуальные составляющию и свойства коллизий (collisions).
- `<visual>` - описывает визуальные свойства `<link>`. Этот элемент определяет геометрическую форму объекта детали робота (`куб, цилиндр, сфера) или 3D-модель визуализации.
- `<collision>` - описывает упрощенную геометрию части робота. Элемент используется для задания хитбоксов и областей, используемых в физических расчетах во время моделирования.
- `<inertial>` - описывает инерционные свойства части робота. Элемент определяет массу детали робота, центр масс и [тензор инерции](https://ru.wikipedia.org/wiki/Тензор_инерции) детали в виде матрицы 3х3.
- `<joint>` описывает шарнир, сочленение, соединение двух жестких частей (`<link>`). Этот элемент определяет кинематику и динамику соединения, пределы безопасного движения, физическое демпфирование и параметры трения.
- `<transmission>` описывает взаимосвязь между приводом и `<joint>`. 

Описание робота с множеством частей и соединений может занимать тысячи строк и быть неудобным для чтения. Решением является язык макросов [xacro](http://wiki.ros.org/xacro). С помощью `xacro` вы можете создавать более короткие и удобочитаемые XML-файлы, используя макросы. 

Для описание нашего abot'a мы использем `urdf` и `xacro`. Вы можете просмотреть примеры описаний роботов в [URDF уроках](http://wiki.ros.org/urdf/Tutorials).

Вы можете написать описание вашего робота в формате URDF вручную. Создайте новый пустой файл и описывайте элемент за элементом. Однако, это трудоемкий процесс, требующий внимания, потому что можно наделать много ошибок. Процесс создания файла URDF можно автоматизировать с помощью специального программного обеспечения, которое экспортирует 3D-модель робота в URDF. А для этого вам понадобится 3D модель робота в [САПР (Системе автоматизированного проектирования)](https://ru.wikipedia.org/wiki/Система_автоматизированного_проектирования). 

## 3D модель робота в САПР

В теории, 3D-модель робота можно создать в любом 3D редакторе, но лучше использовать твердотельное моделирование. 

Мы используюем [SolidWorks 2017](https://www.solidworks.com) на настольном компьютере под управлением ОС Windows. Мы выбрали SolidWorks, потому что в нем есть отличный плагин для экспорта проекта в формат URDF. 

Старайтесь не описывать сразу всего робота. Добавляйте различные части к модели постепенно. Это поможет вам освоить процесс описания. Мы начал с деталирования шасси робота.

Все наше шасси пришлось детализировать вручную. Вот почему так важны чертежи от производителя. Вот что у нас получилось:

![part_6_cad_drawing_1](../media/part_6/cad/part_6_cad_drawing_1.png)

На данный момент наша модель состоит из четырех сегментов:

- `abot_base`
- `abot_left_wheel`
- `abot_right_wheel`
- `abot_caster_wheel`

И трех сочленений (joints):

- `left_wheel_to_base`
- `right_wheel_to_base`
- `caster_wheel_to_base`

Для правильного экспорта нужно выполнить несколько действий.

Добавьте системы координат. Определите системы координат для всех сегментов. Лучше всего указывать системы координат от исходных точек деталей модели. Лучше использовать центр симметрии детали, точку на оси симметрии или центр масс в качестве начала системы координат.

ROS и URDF требуют правосторонних систем координат ([Правило правой руки](https://ru.wikipedia.org/wiki/Правило_буравчика)). Определите, где находится передняя, задняя и верхняя части вашего робота. Ось X должна указывать вперед, ось Y - влево, а ось Z - вверх. По умолчанию стандартные виды Solidworks и система координат повернуты на 90 градусов вокруг осей X и Z. Для удобства правильного размещения осей в Solidworks можно разместить направляющие линии.

Каждый сегмент модели имеет свою систему координат: 

- `CS_BASE`
- `CS_RIGHT_WHEEL`
- `CS_LEFT_WHEEL`
- `CS_CASTER_WHEEL`

Система координат `CS_BASE` условно расположена в центре нашего робота. `CS_LEFT_WHEEL` и `CS_RIGHT_WHEEL` находятся в центрах колес. `CS_CASTER_WHEEL` находится в центре сферы всенаправленного опорного колеса.

![part_6_cad_drawing_2](../media/part_6/cad/part_6_cad_drawing_2.png)

Добавьте оси вращения для подвижных соединений, сочленений (joints). У нас есть три подвижных соединения - два вращающихся на осях колеса и одно всенаправленное колесо которое вращается во все стороны. Всенаправленное колесо не нуждается в оси. Для колес мы поместили оси `AXIS_LEFT_WHEEL` и `AXIS_RIGHT_WHEEL`.

![part_6_cad_drawing_3](../media/part_6/cad/part_6_cad_drawing_3.png)

Если вы планируете использовать описание вашего робота в симуляциях, вам необходимо так же задать реальные материалы для всех деталей модели. Вы можете подобрать материалы приблизительно, из стандартной библиотеки материалов SolidWorks. Экспортер использует материалы деталей для моделирования и расчета инерционных параметров сегментов - массы, координаты центра масс а так же тензора инерции.

## Экспорт в URDF

Чтобы экспортировать модель, мы установили специальный плагин [`solidworks_urdf_exporter`](https://github.com/ros/solidworks_urdf_exporter). Последовательность установки хорошо описана в [документации на плагин](http://wiki.ros.org/sw_urdf_exporter).

После установки включите этот плагин в SolidWorks. Для этого перейдите в меню **Tools → Add-Ins** и установите флажок рядом с плагином `SW2URDF`. Чтобы начать экспорт, перейдите в раздел **Tools - Export as UPDF** или в **Files - Export as UPDF**. Откроется меню экспорта. В этом меню необходимо указать все сегменты, используемые в модели.

Сначала мы указываем сегмент `abot_base`. Это базовый сегмент и родительский сегмент. В качестве базового сегмента для робота лучше выбрать что-то массивное, например каркас корпуса робота.

Затем мы определем три дочерних сегмента для `abot_base` и систему координат `CS_BASE`. Для задания геометрии этого сегмента мы выбираем все части 3D-модели, кроме боковых колес и всенаправленного колеса. При экспорте выбранные нами детали преобразуются в mesh-модели формата STL необходимые для визуализации.

![part_6_cad_drawing_4](../media/part_6/cad/part_6_cad_drawing_4.png)

Следующий шаг - описать сегменты боковых колес. Эти сегменты являются сегментами потомками `abot_base`. Мы установили имена соединений `abot_left_wheel` и `abot_right_wheel`. В качестве систем координат мы выбираем соответствующие `CS_LEFT_WHEEL` и `CS_RIGHT_WHEEL`. Оси вращения колес - `AXIS_LEFT_WHEEL` и `AXIS_RIGHT_WHEEL`. В качестве геометрии мы выбираем детали колес нашей 3D-модели. Для обычного колеса тип соединения (joint) является `continuous`. Так же задаем имена для сочленений колес - `left_wheel_to_base` и `right_wheel_to_base`.

![part_6_cad_drawing_5](../media/part_6/cad/part_6_cad_drawing_5.png)

Добавляем последний сегмент `abot_caster_wheel` и сочленение `caster_wheel_to_base` для всенаправленного колеса. Здесь тип соединения должен быть `continuous`, а система координат - `CS_CASTER_WHEEL`. Тип соединения `fixed` означает что мы не будем 

![part_6_cad_drawing_6](../media/part_6/cad/part_6_cad_drawing_6.png)

**Важно** Для двухколесного дифференциального привода, последнее, всенаправленное колесо никак не влияет на алгоритм задания скоростей движения робота. Мы не можем управлять этим колесом, задавать скорость его вращения и контролировать его. То есть, в теории, нет необходимости описывать его в модели и можно "слить" сегмент всенаправленного колеса с базовым сегментом всего робота. Однако это не так. Описывать желательно все подвижные части вашего робота. Если что то в роботе двигается - значит для этого нужно сочленение (joint) даже если вы не планируете его использовать. Особенно это важно если вы планируте использовать симуляции. Например, мы можем не описывать всенаправленное колесо, тогда оно останется в описании робота твердой опорой и частью другого сегмента. В этом случае при симуляции поведения движения робота описанного таким образом, программа не будет знать что это колесо. Программа расценит колесо как твердый обьект который роботу приходится "тащить" по полу и который создает силы трения и препятствует движению. Таким образом движение робота в симуляции и в реальной жизни будет координально отличаться.

Когда вы опишите все сегменты и сочленения, нажмите кнопку **Preview and Export.. button**.

Проверьте параметры сочленений и нажмите кнопку **Next**.

![part_6_cad_drawing_7](../media/part_6/cad/part_6_cad_drawing_7.png)

Проверьте параметры сегментов.

![part_6_cad_drawing_8](../media/part_6/cad/part_6_cad_drawing_8.png)

Обратите внимание, если вы укажете материал деталей, то программа экспортер сама вычислит массу сегментов, их центры массс и тензор инерции. Это крайне важные параметры если вы планируете симулировть робота!

Завершите экспорт, нажав на кнопку **Export URDF and Meshes..**. Укажите имя папки для экспорта. Мы назвали нашу папку `abot`. Экспортер создаст в этой папке готовый пакет ROS со многими файлами, которые вам в действительности не нужны. Вам нужны 3D-файлы формата *.STL из папки `meshes` и файл описания `abot.urdf` из папки `urdf`.

Отложим эти файлы на некоторое время в сторону.

## Пакет Robot_description

Вернемся на Linux и перейдем в наше рабочее пространство `ros` настольном компьютере.

Cоздадим наш первый пакет проекта робота. Это пакет который содержит описание робота. Традиционно этот пакет называют `robot_description`. Чтобы избежать путаницы с именем, мы назовем его `abot_description`. В директории `ros/src`, в терминали вводим:

```bash
catkin_create_pkg abot_description tf rviz urdf xacro
```

С помощью этой команды вы можете создать пустой пакет ROS, а именно файлы `CMakelists.txt` и `package.xml`. В команде после имени пакета указываются ппакеты зависимости. Для пакета `abot_description` мы установливаем пакеты зависимостей `tf`, `urdf`, `xacro` и `rviz`.

Для каждого пакета ROS не забывайте указывать необходимые пакеты зависимости а так отредактировать файлы `CMakelists.txt` и `package.xml` при добавлении новых функций. Подробнее о процессе создания пакета читайте в [учебной статье](http://wiki.ros.org/ROS/Tutorials/CreatingPackage).

Внутри пакета мы создаем четыре папки с именами `urdf`, `meshes`, `rviz`, and `launch`.

```bash
mkdir abot_description/urdf abot_description/meshes abot_description/rviz abot_description/launch
```

В папку `abot_description/meshes` нужно поместить 3D STL файлы сгенерированные ранее при экспорте нашей модели в URDF. В папку `abot_description/urdf` поместите файл `abot.urdf` так же сгенерированный при экспорте. 

## Приводим в порядок URDF файл описания робота

Экспортер генерирует описание URDF в одном большом файле. Это не всегда удобно. Откройте файл `abot.urdf` и посмотрите, как выглядит описание робота.

В будущем мы будем постоянно совершенствовать нашего робота и расширять его описание, поэтому для удобства давайте разделим файл `abot.urdf` на несколько частей с помощью макросов `xacro` и исправим некоторые сгенерированные ошибки.

Мы решил разделить описание на несколько частей:

- `abot.xacro` - основная информация о роботе, о его базовых сегментах.
- `abot_left_wheel.xacro` - описание сегмента левого колеса и сочленения левого колеса с базой робота.
- `abot_right_wheel.xacro` - описание сегмента правого колеса и сочленения правого колеса с базой робота.
- `abot_caster_wheel.xacro` - описание сегмента всенаправленного колеса и сочленения всенаправленного колеса с базой робота.
- `abot_materials.xacro` - описание цветов для визуализации.

Давайте разбираться. Начнем с простого. Создадим цвета для визуализации. В папке `urdf` cоздадим файл `abot_materials.xacro` и заполните его несколькими элементами описывающими цвета:

```xml
<?xml version="1.0"?>
<robot
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<material name="Green">
		<color rgba="0.0 1.0 0.0 1.0"/>
	</material>
	<material name="Blue">
		<color rgba="0.0 0.0 1.0 1.0"/>
	</material>
	<material name="Red">
		<color rgba="1.0 0.0 0.0 1.0"/>
	</material>
	<material name="White">
		<color rgba="1.0 1.0 1.0 1.0"/>
	</material>
	<material name="Yellow">
		<color rgba="1.0 1.0 0.0 1.0"/>
	</material>
</robot>
```

Теперь создадим файл `abot.xacro` и заполним его информацией о сегменте `abot_base`.

Изменим путь до трехмерных файлов с  `package://abot/meshes/abot_base.STL` на `package://abot_description/meshes/abot_base.STL`.

Включим `abot.xacro` файл с нашими цветами `abot_materials.xacro` и замените все экспортированные теги `material` на новые. Пусть сегмент `abot_base` визуализируется белым цветом. 

Вот какое получилось содержание файла `abot.xacro`.

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- Matherials -->
	<xacro:include filename="$(find abot_description)/urdf/abot_matherials.xacro" />
	<!-- abot_base -->
	<link name="abot_base">
		<inertial>
			<origin xyz="-0.024498 1.0952E-13 0.022295" rpy="0 0 0"/>
			<mass value="0.27459"/>
			<inertia ixx="0.00032396" ixy="-1.1142E-12" ixz="-9.1302E-06" iyy="0.00030091" iyz="-3.3253E-10" izz="0.00056103"/>
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_base.STL" />
			</geometry>
			<material name="White" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_base.STL" />
			</geometry>
		</collision>
	</link>
</robot>
```

Еще одна фундаментальная деталь. Согласно конвенции, описание URDF для ROS должно иметь сегмент с именем `base_link`. Именно этот сегмент служит отправной точкой для дерева описания робота. Вы можете добавить этот сегмент в дерево описания с любой простой геометрией, например, со сферой радиусом 1 мм. 

Мы добавляем в описание `base_link` и "прикрепляем" его к сегменту `abot_base` с помощью соединения `fixed`. Добавляем следующие строки в файл `abot.xacro`:

```xml
<!-- base_link -->
<link name="base_link">
	<visual>
		<origin xyz="0 0 0" rpy="0 0 0" />
		<geometry>
			<sphere radius="0.001" />
		</geometry>
	</visual>
</link>
<joint name="base_link_to_abot_base" type="fixed">
	<origin xyz="0 0 0" rpy="0 0 0" />
	<parent link="base_link" />
	<child link="abot_base" />
</joint>
```

Заполним файлы для правого колеса (`abot_right_wheel.xacro`), для левого колеса (`abot_left_wheel.xacro`) и всенаправлленого колеса (`abot_caster_wheel.xacro`) подобным образом. Отредактируем все экспортированные данные, и разделим их по файлам. Пусть все колеса будут зелеными.

Файл описания левого колеса:

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- left_wheel -->
	<link name="abot_left_wheel">
		<inertial>
			<origin xyz="1.9255E-10 0.00056576 -1.0414E-10" rpy="0 0 0"/>
			<mass value="0.050464"/>
			<inertia ixx="2.0701E-05" ixy="-3.8089E-14" ixz="1.3584E-15" iyy="3.5827E-05" iyz="2.1838E-15" izz="2.0701E-05"/>
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_left_wheel.STL" />
			</geometry>
			<material name="Green" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_left_wheel.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="left_wheel_to_base" type="continuous">
		<origin xyz="0 0.068 0.0145" rpy="0 0 0" />
		<parent link="abot_base" />
		<child link="abot_left_wheel" />
		<axis xyz="0 1 0" />
	</joint>
</robot>
```

Файл описания правого колеса:

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- right_wheel -->
	<link name="abot_right_wheel">
		<inertial>
			<origin xyz="1.9255E-10 -0.00056576 1.0414E-10" rpy="0 0 0"/>
			<mass value="0.050464"/>
			<inertia ixx="2.0701E-05" ixy="3.8089E-14" ixz="-1.3584E-15" iyy="3.5827E-05" iyz="2.1838E-15" izz="2.0701E-05"/>
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_right_wheel.STL" />
			</geometry>
			<material name="Green" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_right_wheel.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="right_wheel_to_base" type="continuous">
		<origin xyz="0 -0.068 0.0145" rpy="0 0 0" />
		<parent link="abot_base" />
		<child link="abot_right_wheel" />
		<axis xyz="0 1 0" />
	</joint>
</robot>
```

Файл описания всенаправленного колеса:

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- caster_wheel -->
	<link name="abot_caster_wheel">
		<inertial>
			<origin xyz="0 1.6073E-19 0" rpy="0 0 0"/>
			<mass value="0.011207"/>
			<inertia ixx="2.1965E-07" ixy="-1.5533E-55" ixz="-1.9776E-56" iyy="2.1965E-07" iyz="-2.2674E-40" izz="2.1965E-07"/>
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_caster_wheel.STL" />
			</geometry>
			<material name="Green" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_caster_wheel.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="caster_wheel_to_base" type="continuous">
		<origin xyz="-0.078 0 -0.011" rpy="0 0 0" />
		<parent link="abot_base" />
		<child link="abot_caster_wheel" />
		<axis xyz="0 1 0" />
	</joint>
</robot>
```

Включим все новые файл описания колес в конец главного файла `abot.xacro`.

```xml
<!-- Wheels -->
<xacro:include filename="$(find abot_description)/urdf/abot_left_wheel.xacro" />
<xacro:include filename="$(find abot_description)/urdf/abot_right_wheel.xacro" />
<xacro:include filename="$(find abot_description)/urdf/abot_caster_wheel.xacro" />
```

## Визуализация URDF модели

Давайте визуализируем нашего робота в ROS на десктопном компьютере машине и посмотрим что получается.

Для визуализации используем мощный инструмент `rviz`. Вы можете прочитать больше о `rviz` в [документации на вики](http://wiki.ros.org/rviz).

Если вы установили полную версию ROS (`ros-desktop-full`), то у вас уже есть все необходимые пакеты ROS для визуализации. Однако так же нужно установить дополнительный пакет `joint-state-publisher-gui` для ручного управления сочленениями. Для нашей ROS Noetic устанавливаем:

```bash
sudo apt-get install ros-noetic-joint-state-publisher-gui
```

Создадим новый файл запуска нод ROS. В ROS эти файлы имеют разрешение *.launch.

В нашем пакете `abot_description` в папке `launch` создаем файл `display_model.launch`. Заполним файл следующими строками:

```xml
<launch>
	<!-- Args -->
	<arg name="gui" default="true" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<!-- Params -->
	<param name="use_gui" value="$(arg gui)" />
	<!-- Robot Description from URDF -->
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="joint_state_publisher_gui" pkg="joint_state_publisher_gui" type="joint_state_publisher_gui" />
	<node name="robot_state_publisher" pkg="robot_state_publisher" type="robot_state_publisher" />
	<!-- Rviz -->
	<node name="rviz" pkg="rviz" type="rviz" required="false"/>
</launch>
```

Что делает этот файл? При запуске данный файл загрузит необходимые для визуализации ноды ROS а так же загрузит URDF описание нашего робота на сервер параметров ROS. 

Перейдем в наше рабочее пространство `ros` и соберем его с нашим новым пакетом `abot_description`.

```bash
cd ~/ros
catkin_make
```

Загрузим переменные окружения нашего рабочего пространства и запустим `display_model.launch`.

```bash
source devel/setup.bash
roslaunch abot_description display_model.launch
```

Если вы все сделали верно то появится оконо `rviz` и окно `joint_state_publisher_gui`.

![part_6_rviz_screen_1](../media/part_6/rviz/part_6_rviz_screen_1.png)

В окне `rviz`, в меню **Displays → Global Options** устанавливаем значение параметра `Fixed Frame` в `base_link`. 

Нажимаем кнопку **Add** в левой нижней части экрана и добавляем две визуализцаии `RobotModel` и `TF`. 

![part_6_rviz_screen_2](../media/part_6/rviz/part_6_rviz_screen_2.png)

На экране появится модель робота созданная по нашему URDF описанию и дерево транформаций.

![part_6_rviz_screen_3](../media/part_6/rviz/part_6_rviz_screen_3.png)

Выглядит не очень понятно. Это потому что сейчас `rviz` имеет стандартные настройки. Вы можете настроить отображение всех данных под себя и сохранить файл настроек. Файл настроек имеет разрешение *.rviz.

Например, мы сохраняем настройки `rviz` для отображения модели в виде файла `abot_model.rviz` в папке `abot_description/rviz` и добавляем соответствующий аргумент в файл запуска `display_model.launch`.

Теперь наш файл запуска `display_model.launch` выглядит таким образом:

```xml
<launch>
	<!-- Args -->
	<arg name="gui" default="true" />
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_model.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<!-- Params -->
	<param name="use_gui" value="$(arg gui)" />
	<!-- Robot Description from URDF -->
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="joint_state_publisher_gui" pkg="joint_state_publisher_gui" type="joint_state_publisher_gui" />
	<node name="robot_state_publisher" pkg="robot_state_publisher" type="robot_state_publisher" />
	<!-- Rviz -->
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

А отображение модели стало намного более приятным и понятным:

![part_6_rviz_screen_4](../media/part_6/rviz/part_6_rviz_screen_4.png)

Можно отключить видимость 3д моделей и проверьть все дерево элементов вашего описания а так же направление осей систем координат.

![part_6_rviz_screen_5](../media/part_6/rviz/part_6_rviz_screen_5.png)

Не забудьте что у нас открыто и второе окно `joint_state_publisher_gui`.

![part_6_rviz_screen_6](../media/part_6/rviz/part_6_rviz_screen_6.png)

Используя слайдеры в этом окне вы можете вручную поуправлять всеми сочленениями модели вашего робота. В нашем случае, перемещая слайдер мы вращаем колеса.

## Footprint робота

Сейчас, при визуализации, наш робот находится в точке (0, 0, 0) на плоскости `grid` которая выступает в роли пола а фиксированный кадр `Fixed Frame` в котором отображается наш робот является глобальным (`Global Frame`). На самом деле робот не должен находится в этой точке, ведь он стоит на своих колесах а не замурован где-то в полу.

Нам необходимо "поднять" робота над полом а так же указать его проекцию на пол - его `footprint`. В соответствии конвенцией в ROS, для этого используется сегмент `base_footprint`. Нам нужно ввести в описание нашего робота этот новый сегмент и связать его с базовым сегментом `base_link`. Так же нужно указать геометрические размеры проекции робота на пол и клиренс.

Добавим новые данные в основной файл описания робота `abot.xacro`. Добавим параметр `clearance` в начало файла. Это будет расстояние в метрах от пола до исходных точкек сегментов `base_link` и `abot_base`. Поместим следующую строку в начало файла `abot.xacro`:

```xml
<xacro:property name="clearance" value="0.018" />
```

В качестве проекции робота на пол можно указать простую геометрическую фигуру. Например, наш робот условно круглый и в качестве проекции мы можем указать блин высотой в 1мм и радиусом 100мм. Пусть на визуализации цвет проекции будет синим.

Добавляем в `abot.xacro` новый сегмент и связываем его с имеющимися.

```xml
<!-- base_footprint -->
<link name="base_footprint">
	<visual>
		<origin xyz="0 0 0" rpy="0 0 0" />
		<geometry>
			<cylinder length="0.001" radius="0.010" />
		</geometry>
		<material name="Blue" />
	</visual>
</link>
<joint name="base_footprint_to_base_link" type="fixed">
	<origin xyz="0 0 ${clearance}" rpy="0 0 0" />
	<parent link="base_footprint" />
	<child link="base_link" />
</joint>
```

Давайте опять запустим визуализацию `rviz`, но в качестве фиксированного кадра визуализации (`Fixed Frame`) укажем `base_footprint`.

Теперь наш робот стоит на земле со своими колесами:

![part_6_rviz_screen_7](../media/part_6/rviz/part_6_rviz_screen_7.png)

Сейчас дерево сегментов и связей нашего робота выглдит так:

![part_6_rqt_screen_1](../media/part_6/rqt/part_6_rqt_screen_1.png)

# Raspberry Pi Hat и крепление электроники

Следующим нашим шагом будет подключение двигатели и энкодеров к роботу. Одноплатник Raspberry в этом плане - отличный выбор, так как дает прямой доступ к контактам GPIO.

Однако не всегда удобно подключать электронику к плате Raspberry напрямую. Лучше использовать специальные платы расширения и адаптеры.

Для нашего робота мы используем универсальный хаб для Raspberry [Troyka HAT](prod://raspberry-pi-troyka-hat).

![part_7_prod_electronics_1.jpg](../media/part_7/prod/part_7_prod_electronics_1.jpg)

Этот адаптер легко вставляется в гребенку пинов Raspberry. Установим Troyka HAT на Raspberry:

![part_7_irl_electronics_1.jpg](../media/part_7/irl/part_7_irl_electronics_1.jpg)

Troyka HAT также имеет дополнительный контроллер-расширитель GPIO портов. Этот контроллер обеспечивает восемь дополнительных портов ввода-вывода с аппаратной поддержкой 12-битного АЦП и 16-битной ШИМ. Позже мы обязательно воспользуемся этой собенностью.

Так выглядит распиновка платы Troyka HAT:

![part_7_schemes_1.png](../media/part_7/schemes/part_7_schemes_1.png)

Пришло время прикрепить наш бортовой компьютер в шасси робота. Можно не заморачиваться с крепежом и прикрепить Raspberry хоть на двухсторонний скотч. Однако если вы хотите сделать качественного робота, все следует делать по уму.

Для крепления электроники мы спроектировали и напечатали на 3Д принтере новую деталь для робота в виде панели или диска. На этой детали мы сделали отверстия для крепежа Raspberry и прочих электронных компонентов. Деталь напечатали на [Prusa i3 MK3S](prod://3d-printer-prusa-i3-mk3s) из [серого PLA-пластика ESUN](prod://3d-printer-filament-esun-pla-plus-grey). 

Вот так выглядит панель:

![part_7_irl_electronics_2.jpg](../media/part_7/irl/part_7_irl_electronics_2.jpg)

Крепим на напечатанную панель Raspberry винтами M2,5x10, гайками M2,5 и контрим гроверными шайбами M2,5. 

![part_7_irl_electronics_3.jpg](../media/part_7/irl/part_7_irl_electronics_3.jpg)

## Бортовое питание

Для бортового питания нашего робота мы будем использовать [Li-ion аккумуляторы](https://ru.wikipedia.org/wiki/Литий-ионный_аккумулятор). Энергии нужно много, одна только Raspberry Pi 4 нуждается в 3 А тока а ведь помимо нее на борту робота будут и другие потребители. Так что нужны аккумуляторы с большой токоотдачей и емкостью. Можно использовать [Li-po аккумуляторы](https://ru.wikipedia.org/wiki/Литий-полимерный_аккумулятор) которые обычно применяются в радиоуправляемых моделях и способны отдавать токи величиной в 2С и более. Однако слишком уж большие токи нам не к чему и мы решили использовать именно Li-ion аккумуляторы в формате 18650.

Мы выбрали аккумуляторы [Li-Ion 18650 Ansmann 3.6 В 2600 мА·ч](battery-li-ion-18650-rechargeable-fourfold-protection).

![part_7_irl_electronics_4.jpg](../media/part_7/irl/part_7_irl_electronics_4.jpg)

Один такой аккумулятор это одна Li-ion "банка" 3.6 В с максимальной отдачей тока в 5 А. Всего мы будем использовать четыре аккумулятора соединенных попарно паралеленно. В сумме это даст нам батарею 7.2 В и 5200 мА·ч. Это не так уж и много для мобильного робота, но на первое время нам хватит. Еще один существенный плюс этих аккумуляторов это наличие схемы защиты от грубокого разряда и короткого замыкания.

7.2 В с батареи мы можем подать на DC-разъём платы Troyka HAT и на ее понижающий DC-DC преобразователь. Этими же 7.2 В мы можем управлять двумя 6-вольтовыми DC моторами в нашем шассии.

Аккумуляторы поместим в два [батарейных отсека 2x18650](https://www.chipdip.ru/product1/8007250932).

![part_7_irl_electronics_5.jpg](../media/part_7/irl/part_7_irl_electronics_5.jpg)

Батарейные отсеки крепим на панели робота винтами М2х6, гайками М2, контрим гроверными шайбами М2.

![part_7_irl_electronics_6.jpg](../media/part_7/irl/part_7_irl_electronics_6.jpg)

Примерим собранную панель на шасси:

![part_7_irl_electronics_7.jpg](../media/part_7/irl/part_7_irl_electronics_7.jpg)

## Актуализация модели робота

С добавлением новой напечатанной детали наш робот внешне немного изменился. А это значит что изменилась его 3д модель. И мы должны отредактировать его URDF описание.

Всегда регистрируйте любые изменения реального робота как в САПР документации так и в URDF описании. Это действие не является обязательным но оно прививает привычку контролировать документацию и поможет вам быстрее находить ошибки программах и что еще важнее причины ошибок.

Обновляем 3Д модель:

![part_7_cad_1.png](../media/part_7/cad/part_7_cad_1.png)

Также обновляем URDF описание робота. Делаем все через экспортер, так же как в прошлый раз. На этот раз не будем описывать процесс экспорта так же подробно. В этот раз у нас изменился только сегмент `abot_base`. А именно его `<visual>` составляющая, STL файл а так же инерционные свойства. 

![part_7_rviz_1.png](../media/part_7/rviz/part_7_rviz_1.png)

# Низкоуровневые драйверы робота

Давайте начнем драйверы для железа нашего робота.

Создадим в рабочем пространстве `ros` новый ROS пакет который будет отвечать за драйверы. Назовем пакет `abot_driver`. Не забываем оформлять файлы `CMakelists.txt` и `package.xml` для каждого нового пакета. В качестве пакетов зависимостей устанавливаем [`roscpp`](http://wiki.ros.org/roscpp) и [`std_msgs`](http://wiki.ros.org/std_msgs). Внутри пакета создаем папку `src`. В папка с этим названием в ROS конвенционально хранятся исходные файлы программ. 

ROS ноды которые мы напишем для этого пакета будут запускаться только на Raspberry (не на десктопном компьютере).

## Библиотека WiringPi

Чтобы использовать контакты Raspberry GPIO, вам нужна библиотека. Существует множество библиотек для управления GPIO Raspberry, они различаются по языку и по глубине использования функций. Существуют библиотеки для C, С++, C#, Python, JavaScript, Perl, Java и Ruby. Вы можете просмотреть [полный список существующих библиотек](https://docs.google.com/spreadsheets/d/1sFCJuPZ9k5GN0A6j7gHRckvbwIdnwzPH1sTCuPNFNRQ/edit#gid=0), который мы наши. Мы будем использовать библиотеку для C++ [WiringPi](http://wiringpi.com/) потому что писать наши ноды ROS мы так же будем на C++.

WiringPi это не сложная и известная библиотека. Однако она уже долгое время не поддерживается, потому что ее [разработка была прекращена](http://wiringpi.com/wiringpi-deprecated/). В ней и сейчас есть нереализованные функции и программные ошибки. Последняя официальная версия библиотеки - [2.52 для Raspberry Pi 4B](http://wiringpi.com/wiringpi-updated-to-2-52-for-the-raspberry-pi-4b/), и она собрана для архитектуры `armhf` а унас архетектура ``

На просторах Github мы нашли хороший форк библиотеки - [https://github.com/WiringPi/WiringPi](https://github.com/WiringPi/WiringPi). Мы будем использем эту версию библиотеки WiringPi и cоберем ее под нашу версию Linux.

В терминале на Raspberry Pi вводим:

```bash
git clone https://github.com/WiringPi/WiringPi.git
cd WiringPi
./build
```

Убедимся, что библиотека собралась и установилась правильно:

```bash
gpio -v
```

![part_8_rpi_side_screen_1.png](../media/part_8/rpi_side/part_8_rpi_side_screen_1.png)

Чтобы просмотреть назначение всех контактов Raspberry Pi 4B а так же их GPIO/Broadcom/WiringPi маппинг, используйте команду:

```bash
gpio readall
```

![part_8_rpi_side_screen_2.png](../media/part_8/rpi_side/part_8_rpi_side_screen_2.png)

## Драйвер моторов

Первый наш драйвер это драйвер для управления двумя DC моторами установленными на шассии.

### Подключение моторов 

Моторы нужно подключить к Raspberry. Но мы не можем напрямую подключить двигатели постоянно тока к плате Raspberry и управлять ими. Нам нужен специльный модуль - плата которая будет управлять моторами. 

Наши DC моторы, не потребляют больших токов и не нуждаются в большом напряжении поэтому в качестве платы управления мы можем использовать небольшой H-мост.


 - . 
Подключите двигатели к малине. Вы не можете напрямую подключить двигатели постоянного тока к Raspberry Pi. Вам нужна плата модуля драйвера. Мои двигатели постоянного тока не потребляют много тока, и я могу использовать простую плату драйвера двигателя постоянного тока.

Connect the motors to the Raspberry. You cant connect DC motors to the Raspberry Pi directly. You need a driver module board. My DC motors do not consume much current, and I can use a simple DC motor driver board.

I use a two-channel H-bridge shield from Amperka in the form of a Troyka module. This Module is designed for two DC motors with a current of up to 1,2A.

![../media/H_BRIDGE_800.jpg](../media/H_BRIDGE_800.jpg)

I also use a convenient Troyka adapter. With this adapter, it is easier to attach the Troyka module to the robot frame parts and wire it.

![../media/TROYKA_PAD_800.jpg](../media/TROYKA_PAD_800.jpg)

Two pins, D and E, control one motor channel. The E pin (Enable) awaits the PWM signal and is responsible for the motor's rotation speed. The D pin (Direction) uses a logical (HIGH or LOW) signal to set the rotation direction. In total, you need four pins to control two DC motors.

The Raspberry Pi 4B can generate a hardware PWM signal only on two channels `PWM0` and `PWM1`. These are the channels I use. Also, Raspberry can generate a software PWM on any of its pins, but it takes up almost all computing power. The `PWM0` channel can be assigned to the Broadcom pin `BCM 12` (WiringPi pin 26) or `BCM 18` (WiringPi pin 1). The `PWM1` channel can be assigned to the Broadcom pin `BCM 13` (WiringPi pin 23) or `BCM 19` (WiringPi pin 24). The direction H-bridge pins can be connected to any Raspberry pins.

I connected the left motor channel to WiringPi pins 7 and 1 and the right channel to pins 12 and 13:

![../media/1.png](../media/1.png)

The motors are powered by a voltage of 4,5V - 7,5V. The power should be applied to the P screw terminals of the Troyka H-bridge. I power the motors from a 2S 7,2V Lithium battery.

### DCMotor class

Let's write a С++ class to control the DC motor on a Raspberry through the H bridge. I create a C++ `dc_motor_wiring_pi.hpp` header file and place it in the `abot_driver/src` folder.

The motor can move `cw` (clockwise), move `ccw` (counterclockwise) or `stop`. The Raspberry PWM resolution is 10 bit (`1023`).

```cpp
#ifndef DC_MOTOR_WIRING_PI_HPP_
#define DC_MOTOR_WIRING_PI_HPP_

#include <ros/ros.h>
#include <wiringPi.h>

#define RPI_MAX_PWM_VALUE 1023

class DCMotorWiringPi {
public:
    DCMotorWiringPi(int8_t direction_pin, int8_t enable_pin);
    void cw(uint16_t val);
    void ccw(uint16_t val);
    void stop();
private:
    int8_t _direction_pin;
    int8_t _enable_pin;
    uint16_t protectOutput(uint16_t val);
};

DCMotorWiringPi::DCMotorWiringPi(int8_t direction_pin, int8_t enable_pin) {
    _direction_pin = direction_pin;
    _enable_pin = enable_pin;
    if (wiringPiSetupGpio() < 0) {
        ROS_ERROR("DCMotor wiringPi error: GPIO setup error");
        throw std::runtime_error("");
    }
    ROS_INFO("DCMotor wiringPi: GPIO setup");
    pinMode(_direction_pin, OUTPUT);
    pinMode(_enable_pin, PWM_OUTPUT);
    stop();
    ROS_INFO("DCMotor wiringPi: Motor setup");
}

void DCMotorWiringPi::stop() {
    pwmWrite(_enable_pin, 0);
    digitalWrite(_direction_pin, 0);
}

void DCMotorWiringPi::cw(uint16_t val) {
    pwmWrite(_enable_pin, protectOutput(val));
    digitalWrite(_direction_pin, 1);
}

void DCMotorWiringPi::ccw(uint16_t val) {
    pwmWrite(_enable_pin, protectOutput(val));
    digitalWrite(_direction_pin, 0);
}

uint16_t DCMotorWiringPi::protectOutput(uint16_t val) {
    return val > RPI_MAX_PWM_VALUE ? RPI_MAX_PWM_VALUE : val;
}

#endif // DC_MOTOR_WIRING_PI_HPP_
```

### Friction Test

Let's write a simple test for debugging the motors. We need this to ensure that the robot's motors are working and determine the minimum PWM signal to overcome the ground friction.

The fact is that only at a certain voltage on the motor, the wheel begins to rotate. If you specify that the robot wheel should rotate, for example, at an angular velocity of 0.5rad/s, it should rotate at this speed, and you should not wait for the PWM value to grow. 

Creating a new file `motors_friction_test.cpp` and place it in the `abot_driver/src/test` directory. To control the speed of motors, I use the topics `/left_motor` and `/right_motor` and values in the range from [-1,1], where 0 corresponds to the zero PWM, -1 and 1 to the maximum PWM.

```cpp
#include "../dc_motor_wiring_pi.hpp"
#include "std_msgs/Float32.h"

#define MOTOR_1_PIN_D 4     // Wiring pi 7 = BCM 4
#define MOTOR_1_PIN_E 18    // Wiring pi 1 = BCM 18
#define MOTOR_2_PIN_D 12    // Wiring pi 26 = BCM 12
#define MOTOR_2_PIN_E 13    // Wiring pi 23 = BCM 13

DCMotorWiringPi left_dc_motor(MOTOR_1_PIN_D, MOTOR_1_PIN_E);
DCMotorWiringPi right_dc_motor(MOTOR_2_PIN_D, MOTOR_2_PIN_E);

double mapSpeed(double angluar_wheel_speed, double max_angluar_wheel_speed, double min_pwm, double max_pwm) {
    return angluar_wheel_speed * (max_pwm - min_pwm) / (max_angluar_wheel_speed - 0) + min_pwm;
}

void leftMotorCallback(const std_msgs::Float32& msg) {
    double spd = msg.data;
    uint16_t pwm = mapSpeed(std::abs(spd), 1.0, 0.0, RPI_MAX_PWM_VALUE);
    ROS_INFO("LEFT MOTOR PWM: %d", pwm);
    if (spd > 0) {
        left_dc_motor.ccw(pwm);
    } else if (spd < 0) {
        left_dc_motor.cw(pwm);
    } else if (spd == 0) {
        left_dc_motor.stop();
    }
}

void rightMotorCallback(const std_msgs::Float32& msg) {
    double spd = msg.data;
    uint16_t pwm = mapSpeed(std::abs(spd), 1.0, 0.0, RPI_MAX_PWM_VALUE);
    ROS_INFO("RIGHT MOTOR PWM: %d", pwm);
    if (spd > 0) {
        right_dc_motor.cw(pwm);
    } else if (spd < 0) {
        right_dc_motor.ccw(pwm);
    } else if (spd == 0) {
        right_dc_motor.stop();
    }
}

int main(int argc, char **argv) {
    ros::init(argc, argv, "motors_friction_test");
    ros::NodeHandle node;
    ros::Subscriber left_motor_sub = node.subscribe("left_motor", 1, &leftMotorCallback);
    ros::Subscriber right_motor_sub = node.subscribe("right_motor", 1, &rightMotorCallback);
    ros::spin();
    return 0;
}
```

Edit the `CMakelists.txt` file to specify the compile flags to the Wiringpi library:

```makefile
add_executable(motors_friction_test src/test/motors_friction_test.cpp)
target_link_libraries(motors_friction_test ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

Build the workspace and launch ROS core:

```bash
cd ~/ros
catkin_make
```

The WiringPi reqires root permissions. In a new terminal run the test: 

```bash
sudo -s
cd ros
source devel/setup.bash
rosrun abot_driver motors_friction_test
```

![../media/motors_friction_test.png](../media/motors_friction_test.png)

Open a new terminal and check whether the necessary topics `/left_motor` and `/right_motor` have appeared.

```bash
rostopic list
```

![../media/rostopic_friction.png](../media/rostopic_friction.png)

To publish values to the topics manually, use the `rqt` ROS utility and the *Topics* → *MessagePublisher* `rqt` plugin.

![../media/rqt_friction_test.png](../media/rqt_friction_test.png)

Set the robot chassis on the ground. Gradually increase values in the topics `/left_motor` and `/right_motor` while observing the PWM values in the terminal with the running test. Determine at what PWM values the wheels overcomes the friction force and begins to rotate.

I got these values: 143 PWM for the left motor and 153 PWM for the right motor.

ВИДЕО! СПЛИТСКРИН, РОБОТ НА ПОЛУ + ПАБЛИШЕР, ПОСТЕПЕННО УВЕЛИЧИВАЕМ СКОРОСТЬ.

### Motors Node

Now we can write the final ROS node for motors - `dc_motors.cpp`. Put the `dc_motors.cpp` into the `abot_driver/src` folder in the workspace.

How does it work? The `dc_motors` node subscribe to two topics `/abot/left_wheel_velocity` and `/abot/right_wheel_velocity`. Through these topics, the node receives the `double` values of the angular velocities in rad/s with which the wheels should rotate. Then these angular velocities are mapped to PWM signals. 

For correct mapping, you need to set the minimum value of the PWM to overcome friction (`MOTOR_LEFT_PWM_THRESHOLD`, `MOTOR_RIGHT_PWM_THRESHOLD`), and the maximum value of each wheel's angular velocity in rad/s (`MAX_ANGLUAR_LEFT_WHEEL_SPEED`, `MAX_ANGLUAR_RIGHT_WHEEL_SPEED`). We will get the last values when we write a test for encoders.

```cpp
#include "dc_motor_wiring_pi.hpp"
#include "std_msgs/Float32.h"

#define MOTOR_1_PIN_D 4     // Wiring pi 7 = BCM 4
#define MOTOR_1_PIN_E 18    // Wiring pi 1 = BCM 18
#define MOTOR_2_PIN_D 12    // Wiring pi 26 = BCM 12
#define MOTOR_2_PIN_E 13    // Wiring pi 23 = BCM 13

#define MOTOR_LEFT_PWM_THRESHOLD 143
#define MOTOR_RIGHT_PWM_THRESHOLD 153

#define MAX_ANGLUAR_LEFT_WHEEL_SPEED 0.0
#define MAX_ANGLUAR_RIGHT_WHEEL_SPEED 0.0

DCMotorWiringPi left_dc_motor(MOTOR_1_PIN_D, MOTOR_1_PIN_E);
DCMotorWiringPi right_dc_motor(MOTOR_2_PIN_D, MOTOR_2_PIN_E);

double mapSpeed(double angluar_wheel_speed, double max_angluar_wheel_speed, double min_pwm, double max_pwm) {
    return angluar_wheel_speed * (max_pwm - min_pwm) / (max_angluar_wheel_speed - 0) + min_pwm;
}

void leftMotorCallback(const std_msgs::Float32& msg) {
    double motor_spd = msg.data;
    uint16_t motor_pwm = mapSpeed(std::abs(motor_spd), MAX_ANGLUAR_LEFT_WHEEL_SPEED, MOTOR_LEFT_PWM_THRESHOLD, RPI_MAX_PWM_VALUE);
    if (motor_spd > 0) {
        left_dc_motor.ccw(motor_pwm);
    } else if (motor_spd < 0) {
        left_dc_motor.cw(motor_pwm);
    } else if (motor_spd == 0) {
        left_dc_motor.stop();
    }      
}

void rightMotorCallback(const std_msgs::Float32& msg) {
    double motor_spd = msg.data;
    uint16_t motor_pwm = mapSpeed(std::abs(motor_spd), MAX_ANGLUAR_RIGHT_WHEEL_SPEED, MOTOR_RIGHT_PWM_THRESHOLD, RPI_MAX_PWM_VALUE);
    if (motor_spd > 0) {
        right_dc_motor.ccw(motor_pwm);
    } else if (motor_spd < 0) {
        right_dc_motor.cw(motor_pwm);
    } else if (motor_spd == 0) {
        right_dc_motor.stop();
    }
}

int main(int argc, char **argv) {
    ros::init(argc, argv, "dc_motors");
    ros::NodeHandle node;
    ros::Subscriber left_motor_sub = node.subscribe("abot/left_wheel_velocity", 1, &leftMotorCallback);
    ros::Subscriber right_motor_sub = node.subscribe("abot/right_wheel_velocity", 1, &rightMotorCallback);
    ros::spin();
    return 0;
}
```

Add the executable to the `CMakelists.txt` file in the `abot_driver` pakage:

```makefile
add_executable(dc_motors src/dc_motors.cpp)
target_link_libraries(dc_motors ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

## Encoder Driver

The second driver is for the motors encoders. 

### Wiring

The quadrature encoder has two channels, A and B, and communicates via two wires. The encoder generates simple logic signals on these two channels. If the motor shaft rotates quickly, it is better to use hardware interrupts to read signals. Raspberry allows interrupts on all pins, and you can connect the encoder to any unused pins.

I wired the left motor encoder to the Broadcom pins `BCM 17` (WiringPi pin 0) and `BCM 27` (WiringPi pin 2). Right side encoder to pins `BCM 24` (WiringPi pin 5) and `BCM 25` (WiringPi pin 6). 

Encoders are powered from 5V. 5V can be taken from Troyka Hat pads.

![../media/2.png](../media/2.png)

### Encoder class

Write a С++ class to decode a quadrature encoder on a Raspberry using interrupts. I create a C++ `encoder_wiring_pi.hpp` header file and place it in the `abot_driver/src` folder.

Using interrupts in WiringPi can be tricky. To use interrupts, I created two global functions `encoderISR1` and `encoderISR2`. The raw tick values are contained in the `long` variables `encoderPosition1` and `encoderPosition2`. I haven't written an overflow check yet. 

Set the PPR (Pulses per revolution) value of your encoder in the code. For my encoders the `PULSES_PER_REVOLUTION` value is `1920`.

```cpp
#ifndef ENCODER_WIRING_PI_HPP_
#define ENCODER_WIRING_PI_HPP_

#include <ros/ros.h>
#include <wiringPi.h>

#define ENCODER_1_PIN_A 17  // Wiring pi 0 = BCM 17
#define ENCODER_1_PIN_B 27  // Wiring pi 2 = BCM 27
#define ENCODER_2_PIN_A 24  // Wiring pi 5 = BCM 24
#define ENCODER_2_PIN_B 25  // Wiring pi 6 = BCM 25

#define PULSES_PER_REVOLUTION 1920

namespace EncoderWiringPiISR {

    volatile long encoderPosition1;
    volatile long encoderPosition2;
    volatile uint8_t encoderState1;
    volatile uint8_t encoderState2;

    void encoderISR(const int pinA, const int pinB, volatile long &encoderPosition, volatile uint8_t &encoderState) {
        uint8_t valA = digitalRead(pinA);
        uint8_t valB = digitalRead(pinB);
        uint8_t s = encoderState & 3;
        if (valA) s |= 4;
        if (valB) s |= 8; 
        encoderState = (s >> 2);
        switch (s) {
            case 1: case 7: case 8: case 14:
                encoderPosition++;
                return;
            case 2: case 4: case 11: case 13:
                encoderPosition--;
                return;
            case 3: case 12:
                encoderPosition += 2;
                return;
            case 6: case 9:
                encoderPosition -= 2;
                return;
        }
    }

    void encoderISR1(void) {
        encoderISR(ENCODER_1_PIN_A, ENCODER_1_PIN_B, encoderPosition1, encoderState1);
    }

    void encoderISR2(void) {
        encoderISR(ENCODER_2_PIN_A, ENCODER_2_PIN_B, encoderPosition2, encoderState2);
    }
}

class EncoderWiringPi {
public:
    EncoderWiringPi(const int &pinA, const int &pinB, void (*isrFunction)(void), volatile long* encoderPosition);
    double getAngle();
private:
    int _pinA;
    int _pinB;
    volatile long* _encoderPosition;
    double _initial_angle;
    double ticks2Angle(long position);
};

EncoderWiringPi::EncoderWiringPi(const int &pinA, const int &pinB, void (*isrFunction)(void), volatile long* encoderPosition) {
    _encoderPosition = encoderPosition;

    if (wiringPiSetupSys() < 0) {
        ROS_ERROR("Encoder wiringPi error: GPIO setup error");
        throw std::runtime_error("");
    }
    ROS_INFO("Encoder wiringPi: GPIO setup");

    _pinA = pinA;
    _pinB = pinB;
    pinMode(_pinA, INPUT);
    pinMode(_pinB, INPUT);
    pullUpDnControl(_pinA, PUD_UP);
    pullUpDnControl(_pinB, PUD_UP);

    if (wiringPiISR(_pinA, INT_EDGE_BOTH, isrFunction) < 0) {
        ROS_ERROR("Encoder wiringPi error: ISR pinA error");
        throw std::runtime_error("");
    }

    if (wiringPiISR(_pinB, INT_EDGE_BOTH, isrFunction) < 0) {
        ROS_ERROR("Encoder wiringPi error: ISR pinB error");
        throw std::runtime_error("");
    }

    _initial_angle = ticks2Angle(*_encoderPosition);
    ROS_INFO("Encoder wiringPi: ISR setup");
}

double EncoderWiringPi::getAngle() {
    double current_angle = ticks2Angle(*_encoderPosition);
    return current_angle - _initial_angle;
}

double EncoderWiringPi::ticks2Angle(long position) {
	return position * ((double)2 * M_PI / PULSES_PER_REVOLUTION / 2);
}

#endif // ENCODER_WIRING_PI_HPP_
```

### Encoders Node

Let's write a node for encoders - `encoders.cpp`. Put the `encoders.cpp` into the `abot_driver/src` folder in the workspace.

This node use current left and right wheel angles from encoders and publish them into topics `/abot/left_wheel_angle` and `/abot/right_wheel_angle`. Angle values are published to topics on timer `encoders_timer;`, 100 times per second `EncodersPair encoders_pair(0.01);`.

```cpp
#include "encoder_wiring_pi.hpp"
#include "std_msgs/Float32.h"

class EncodersPair {
public:
    EncodersPair(double update_rate);
private:
    ros::NodeHandle node;
    ros::Publisher left_wheel_angle_pub;
    ros::Publisher right_wheel_angle_pub;

    ros::Timer encoders_timer;

    std_msgs::Float32 left_wheel_angle_msg;
    std_msgs::Float32 right_wheel_angle_msg;

    EncoderWiringPi encoder_left;
    EncoderWiringPi encoder_right;

    double left_wheel_angle;
    double right_wheel_angle;

    void encodersCallback(const ros::TimerEvent& event);
};

EncodersPair::EncodersPair(double update_rate) :
    encoder_left(ENCODER_1_PIN_A, ENCODER_1_PIN_B, &EncoderWiringPiISR::encoderISR1, &EncoderWiringPiISR::encoderPosition1),
    encoder_right(ENCODER_2_PIN_A, ENCODER_2_PIN_B, &EncoderWiringPiISR::encoderISR2, &EncoderWiringPiISR::encoderPosition2) {
    left_wheel_angle_pub = node.advertise<std_msgs::Float32>("/abot/left_wheel_angle", 1);
    right_wheel_angle_pub = node.advertise<std_msgs::Float32>("/abot/right_wheel_angle", 1);
    encoders_timer = node.createTimer(ros::Duration(update_rate), &EncodersPair::encodersCallback, this);
}

void EncodersPair::encodersCallback(const ros::TimerEvent& event) {
    left_wheel_angle = -1 * encoder_left.getAngle();
    right_wheel_angle = 1 * encoder_right.getAngle();

    left_wheel_angle_msg.data = left_wheel_angle;
    right_wheel_angle_msg.data = right_wheel_angle;

    left_wheel_angle_pub.publish(left_wheel_angle_msg);
    right_wheel_angle_pub.publish(right_wheel_angle_msg);
}

int main(int argc, char** argv) {
    ros::init(argc, argv, "encoders");
    EncodersPair encoders_pair(0.01);
    ros::spin();
    return 0;
}
```

Add the executable to the `CMakelists.txt` file in the `abot_driver` pakage:

```makefile
add_executable(encoders src/encoders.cpp)
target_link_libraries(encoders ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

Build the new nodes:

```bash
cd ~/ros
catkin_make
```

Let's check that everything works. Run the core in a new terminal:

```bash
roscore
```

Run the `encoders` node in a new terminal under `root`:

```bash
cd ~/ros
sudo -s
source devel/setup.bash
rosrun abot_driver encoders
```

![../media/encoders.png](../media/encoders.png)

Launch the topic monitor, for example, for the right wheel. Manually rotate the robot wheel and watch for changes in the current angle. In a new terminal:

```bash
rostopic list
rostopic echo /abot/right_wheel_angle
```

I turned the wheel about 1 turn, which is `2*PI`:

![../media/rostopic_encoders.png](../media/rostopic_encoders.png)

ВИДЕО! СПЛИТ СКРИН 1 ОБОРОТ КОЛЕСА + ТЕРМИНАЛ.

### Encoders Velocity Test

Now, when you are sure that encoders work, you need to find out the maximum angular wheel speed at maximum PWM. I write another test - `encoders_velocity_test.cpp` and put it in the `abot_driver/src/test` folder. 

Speed is easy to measure - divide the distance traveled by time. I publish velocities in topics `/left_wheel_encoder_velocity` and `/right_wheel_encoder_velocity`.

```cpp
#include "../encoder_wiring_pi.hpp"
#include "std_msgs/Float32.h"
#include <chrono>

typedef boost::chrono::steady_clock time_source;

class EncodersPair {
public:
    EncodersPair(double update_rate);
private:
    ros::NodeHandle node;

    ros::Publisher left_wheel_velocity_pub;
    ros::Publisher right_wheel_velocity_pub;

    ros::Timer timer;

    std_msgs::Float32 left_wheel_velocity_msg;
    std_msgs::Float32 right_wheel_velocity_msg;

    EncoderWiringPi encoder_left;
    EncoderWiringPi encoder_right;

    double left_wheel_angle;
    double right_wheel_angle;
    double left_wheel_velocity;
    double right_wheel_velocity;
    double left_wheel_position;
    double right_wheel_position;

    time_source::time_point last_time;

    void encodersCallback(const ros::TimerEvent& event);
};

EncodersPair::EncodersPair(double update_rate) :
    encoder_left(ENCODER_1_PIN_A, ENCODER_1_PIN_B, &EncoderWiringPiISR::encoderISR1, &EncoderWiringPiISR::encoderPosition1),
    encoder_right(ENCODER_2_PIN_A, ENCODER_2_PIN_B, &EncoderWiringPiISR::encoderISR2, &EncoderWiringPiISR::encoderPosition2) {
    
    left_wheel_velocity_pub = node.advertise<std_msgs::Float32>("/left_wheel_encoder_velocity", 1);
    right_wheel_velocity_pub = node.advertise<std_msgs::Float32>("/right_wheel_encoder_velocity", 1);

    timer = node.createTimer(ros::Duration(update_rate), &EncodersPair::encodersCallback, this);
    last_time = time_source::now();
}

void EncodersPair::encodersCallback(const ros::TimerEvent& event) {
    time_source::time_point this_time = time_source::now();
    boost::chrono::duration<double> elapsed_duration = this_time - last_time;
    ros::Duration elapsed(elapsed_duration.count());
    last_time = this_time;

    left_wheel_angle = -1 * encoder_left.getAngle();
    right_wheel_angle = 1 * encoder_right.getAngle();

    double delta_left_wheel = left_wheel_angle - left_wheel_position;
    double delta_right_wheel = right_wheel_angle - right_wheel_position;

    left_wheel_position += delta_left_wheel;
    left_wheel_velocity = delta_left_wheel / elapsed.toSec();

    right_wheel_position += delta_right_wheel;
    right_wheel_velocity = delta_right_wheel / elapsed.toSec();
 
    left_wheel_velocity_msg.data = left_wheel_velocity;
    right_wheel_velocity_msg.data = right_wheel_velocity;

    left_wheel_velocity_pub.publish(left_wheel_velocity_msg);
    right_wheel_velocity_pub.publish(right_wheel_velocity_msg);
}

int main(int argc, char** argv) {
    ros::init(argc, argv, "encoders_velocity_test");
    EncodersPair encoders_pair(0.01);
    ros::spin();
    return 0;
}
```

Add the executable to the `CMakelists.txt` file in the `abot_driver` pakage:

```makefile
add_executable(encoders_velocity_test src/test/encoders_velocity_test.cpp)
target_link_libraries(encoders_velocity_test ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

Build the workspace with the new test:

```bash
cd ~/ros
catkin_make
```

Run the core in a new terminal:

```bash
roscore
```

Run the `encoders_velocity_test` node in a new terminal under `root`:

```bash
cd ~/ros
sudo -s
source devel/setup.bash
rosrun abot_driver encoders_velocity_test
```

Run the `friction_test` to manually set the maximum PWM value:

```bash
cd ~/ros
sudo -s
source devel/setup.bash
rosrun abot_driver friction_test
```

Set the maximum PWM value (1023) for both motors using the `rqt` utility, as we did in previous chapters.
Open the topic monitor for each wheel and find out its maximum rotation velocity.

For the right wheel:

```bash
rostopic echo /right_wheel_encoder_velocity
```

![../media/wheel_speed_right.png](../media/wheel_speed_right.png)

For the left wheel:

```bash
rostopic echo /left_wheel_encoder_velocity
```

![../media/wheel_speed_left.png](../media/wheel_speed_left.png)

I got that the left wheel rotates at a maximum speed of about `16.4` Rad/s and the right wheel at a speed of `15.1` Rad/s. You need to define these values in the `dc_motors` node:

```cpp
#define MAX_ANGLUAR_LEFT_WHEEL_SPEED 16.4
#define MAX_ANGLUAR_RIGHT_WHEEL_SPEED 15.1
```

## Drivers Launcher

Excellent, two main drivers are ready. Let's create the new launch file so that you don't have to run these drivers separately each time.

In the `abot_driver` package, create the `launch` folder and put the following `abot_drivers.launch` file into it.

```xml
<launch>
    <node name="encoders" pkg="abot_driver" type="encoders" output="screen" />
    <node name="dc_motors" pkg="abot_driver" type="dc_motors" output="screen" />
</launch>
```

Open a new terminal, build the workspace, and run drivers.

```bash
cd ~/ros
catkin_make
sudo -s
source devel/setup.bash
roslaunch abot_driver abot_drivers.launch
```

Make sure that both drivers are running, monitore active ROS topics:

```bash
rostopic list
```

![../media/terminal_4.png](../media/terminal_4.png)

# Movement Control

Now I can control the robot's wheels separately, but this is entirely useless. You need to create a controller that will handle the robot's movement. 

## Abot_control Package

The chassis of my robot is a type of 2WD differential drive with a caster wheel. The ROS has many ready-made controllers - `[ros_controllers](http://wiki.ros.org/ros_controllers?distro=noetic)`. For my kind of drive, there is also a ready-made controller - `[diff_drive_controller](http://wiki.ros.org/diff_drive_controller)`. It means that I don't have to write the differential engine algorithm myself but use a ready-made solution.

I create a new `abot_control` package in the `ros` workspace with the following package dependencies: `[controller_manager](http://wiki.ros.org/controller_manager)`, `[hardware_interface](http://wiki.ros.org/hardware_interface?distro=noetic)`, `[trajectory_msgs](http://wiki.ros.org/trajectory_msgs)`, `[ros_controllers](http://wiki.ros.org/ros_controllers)`, `[joint_state_controller](http://wiki.ros.org/joint_state_controller)`, `[robot_state_publisher](http://wiki.ros.org/robot_state_publisher)`.

### Controllers Config

In the `abot_control` package, create the `config` folder and place the `abot_controllers.yaml` file with the description of the robot's controllers. I use two controllers.

The first one is type `joint_state_controller/JointStateController`. I called it `joint_state_controller`. This controller is responsible for updating all robot joints positions on the parametric server. The `publish_rate` parameter sets the frequency of updating the joints positions. I set the rate to `100` times per second.

```yaml
joint_state_controller:
  type: joint_state_controller/JointStateController
  publish_rate: 100
```

The second controller is of the `diff_drive_controller/DiffDriveController` type. I named it `mobile_abot`. This is the controller directly responsible for the robot's movement. I set the contoller rate to `100` times per second.

In ROS, a robot's movement is carried out through topics that communicate type `geometry_msgs/Twist` messages. A message of this type consists of two vectors `geometry_msgs/Vector3 linear` and
`geometry_msgs/Vector3 angular`. The `geometry_msgs/Vector3 linear` vector describes a robot's linear velocities along the X Y Z axes in the global coordinate system. The `geometry_msgs/Vector3 angular` vector represents the rotation velocity of a robot along these axes. 

The differential 2WD drive is non-holomonic and it is controlled only by linear speed along the X axis and angular velocity around the Z axis.

Here is the controller priciple. You pass the robot velocity vectors to the `/cmd_vel` topic. The controller analyzes the received vectors, calculates the required rotation speeds of the right and left wheels, and sends calculated values to the left and right wheel motor topic. Simultaneously, the controller reads the current angles of the wheels and calculates the robot's path and Odometry. The Odometry messages are of the `nav_msgs/Odometry type` and are published in the `/odom` topic.

The controller is set by many parameters, but you can adjust just the main ones. You need to specify the names of the right and left wheel joints - `left_wheel` and `right_wheel`, the base robot link - `base_frame_id`, the maximum linear speed and acceleration of the robot along the X axis, and the maximum angular speed and acceleration of the robot around the Z axis. The minimum value can be omitted, by default it is equal to the maximum with the opposite sign. Set up the controllers working frequency - `publish_rate`. The `twist_covariance_diagonal` and `pose_covariance_diagonal` matrices for the Odometry can be left default.

```yaml
mobile_abot:
  type : "diff_drive_controller/DiffDriveController"
  left_wheel: 'left_wheel_to_base'
  right_wheel: 'right_wheel_to_base'
  publish_rate: 100.0
  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  wheel_separation_multiplier: 1.0 # default: 1.0
  wheel_radius_multiplier    : 1.0 # default: 1.0
  cmd_vel_timeout: 0.1
  base_frame_id: base_footprint
  linear:
    x:
      has_velocity_limits : true
      max_velocity : 0.6642 # m/s
      has_acceleration_limits: true
      max_acceleration : 6.1152 # m/s^2
  angular:
    z:
      has_velocity_limits : true
      max_velocity : 5.0 # rad/s
      has_acceleration_limits: true
      max_acceleration : 10.0 # rad/s^2  
  enable_odom_tf: true
```

Where do I get the robot's speed values? The robot's maximum linear speed can be calculated from the robot's wheels' maximum rotational speeds. However, it is better to set all speeds and accelerations to 0 and gradually increase them while debugging the robot. I took these values empirically. 

### Adjust the Robot Description

For the correct calculation of speeds and odometry, the controller needs two more important parameters - `wheel_radius` and `wheel_separation`. By default, the controller searches for these parameters in the `robot_description`. 

Furthermore, you need to make some changes to the `robot description`. In the controller settings, you specify the names of the robot wheel joints. The controller expects that the child links attached to these joints are circular wheels.

But, in my model, wheels are stored as mesh, *.STL files. The circular part stored in the *.STL file is not actually circular but is an approximation of a circle and consists of many polygons. The controller needs wheels to be described mathematically.

To do this, I create two more links in the `abot_description` URDF model, `left_wheel`, and `right_wheel`. In these links, the visual component is described by the `geometry` tag, not a Mesh. Now the `left_wheel_to_base` and `right_wheel_to_base` joints should lead to the new links `left_wheel` and `right_wheel`. The old links `abot_left_wheel` and `abot_right_wheel` can be attached fixed to the new ones with new fixed joints. I define the robot wheels as cylinders with a height of 26mm and a diameter of 65mm

Add new params to the `abot.xacro`:

```xml
<xacro:property name="wheel_radius" value="0.0325"/>
<xacro:property name="wheel_separation" value="0.128"/>
<xacro:property name="wheel_width" value="0.026"/>
<xacro:property name="PI" value="3.1415926"/>
```

Adjust the left wheel description:

```xml
<link name="left_wheel">
	<visual>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
		<material name="Green" />
	</visual>
	<collision>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
	</collision>
</link>
<joint name="left_wheel_to_abot_left_wheel" type="fixed">
	<origin xyz="0 0 0" rpy="0 0 0" />
	<parent link="left_wheel" />
	<child link="abot_left_wheel" />
</joint>
<joint name="left_wheel_to_base" type="continuous">
	<origin xyz="0 0.068 0.0145" rpy="0 0 0" />
	<parent link="abot_base" />
	<child link="left_wheel" />
	<axis xyz="0 1 0" />
</joint>	
```

And the right wheel description:

```xml
<link name="right_wheel">
	<visual>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
		<material name="Green" />
	</visual>
	<collision>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
	</collision>
</link>
<joint name="right_wheel_to_abot_right_wheel" type="fixed">
	<origin xyz="0 0 0" rpy="0 0 0" />
	<parent link="right_wheel" />
	<child link="abot_right_wheel" />
</joint>
<joint name="right_wheel_to_base" type="continuous">
	<origin xyz="0 -0.068 0.0145" rpy="0 0 0" />
	<parent link="abot_base" />
	<child link="right_wheel" />
	<axis xyz="0 1 0" />
</joint>
```

### Controllers Launcher

Create a launch file for both controllers. In package `abot_control`, create folder `launch` with file `abot_control.launch`:

```xml
<launch>
	<rosparam file="$(find abot_control)/config/abot_controllers.yaml" command="load"/>
	<node name="controller_spawner" pkg="controller_manager" type="spawner" respawn="false" output="screen"
		args="joint_state_controller mobile_abot"></node>
</launch>
```

## Abot_base Package

The controllers themselves that we have described are universal. By now, they have been configured, but they don't know with what they should work. We need to link controllers to our specific hardware, i.e., create a ROS [hardware interface](http://wiki.ros.org/hardware_interface). For this, in ROS, there is a conventional robot `base` node. I called mine `abot_base`.

I create a new `abot_base` package. Set the dependency packages: `controller_manager`, `hardware_interface`, `trajectory_msgs`, `[roscpp](http://wiki.ros.org/roscpp)`, `diff_drive_controller`.

In this package, you need to create a specific C++ class, a descendant of the ROS `hardware_interface::RobotHW` C++ class, which registers all the described controllers and communicates with drivers topics. My class subscribes to driver topics `abot/left_wheel_angle` and `abot/right_wheel_angle` and publishes to driver topics `/abot/left_wheel_velocity` and `/abot/right_wheel_velocity`. 

The `updateJointsFromHardware` method processes the current wheel angles, calculates the current wheels velocities and push them to the `mobile_abot` controller. On the other hand, the `writeCommandsToHardware` method sends to the driver the desired wheel speeds calculated by the `mobile_abot` controller.

Сreate the `src` folder in the `abot_base` package and place the `abot_hardware_interface.h` header file in it.

```cpp
#ifndef ABOT_HARDWARE_INTERFACE_HPP_
#define ABOT_HARDWARE_INTERFACE_HPP_

#include <boost/assign/list_of.hpp>
#include <sstream>
#include <std_msgs/Float32.h>
#include <std_srvs/Empty.h>

#include <controller_manager/controller_manager.h>
#include <hardware_interface/joint_command_interface.h>
#include <hardware_interface/joint_state_interface.h>
#include <hardware_interface/robot_hw.h>
#include <ros/ros.h>
#include <ros/console.h>

class AbotHardwareInterface : public hardware_interface::RobotHW {
public:
    AbotHardwareInterface(ros::NodeHandle node, ros::NodeHandle private_node, double target_max_wheel_angular_speed);

    void updateJointsFromHardware(const ros::Duration& period);
    void writeCommandsToHardware();
private:
    ros::NodeHandle _node;
    ros::NodeHandle _private_node;

    hardware_interface::JointStateInterface _joint_state_interface;
    hardware_interface::VelocityJointInterface _velocity_joint_interface;

    ros::Subscriber _left_wheel_angle_sub;
    ros::Subscriber _right_wheel_angle_sub;
    ros::Publisher _left_wheel_vel_pub;
    ros::Publisher _right_wheel_vel_pub;

    struct Joint {
        double position;
        double position_offset;
        double velocity;
        double effort;
        double velocity_command;

        Joint()
            : position(0)
            , velocity(0)
            , effort(0)
            , velocity_command(0) {}
    } _joints[2];

    double _left_wheel_angle;
    double _right_wheel_angle;
    double _max_wheel_angular_speed;

    void registerControlInterfaces();
    void leftWheelAngleCallback(const std_msgs::Float32& msg);
    void rightWheelAngleCallback(const std_msgs::Float32& msg);
    void limitDifferentialSpeed(double& diff_speed_left_side, double& diff_speed_right_side);
};

AbotHardwareInterface::AbotHardwareInterface(ros::NodeHandle node, ros::NodeHandle private_node, double target_max_wheel_angular_speed)
    : _node(node)
    , _private_node(private_node)
    , _max_wheel_angular_speed(target_max_wheel_angular_speed) {

    registerControlInterfaces();

    _left_wheel_vel_pub = _node.advertise<std_msgs::Float32>("/abot/left_wheel_velocity", 1);
    _right_wheel_vel_pub = _node.advertise<std_msgs::Float32>("/abot/right_wheel_velocity", 1);
    _left_wheel_angle_sub = _node.subscribe("abot/left_wheel_angle", 1, &AbotHardwareInterface::leftWheelAngleCallback, this);
    _right_wheel_angle_sub = _node.subscribe("abot/right_wheel_angle", 1, &AbotHardwareInterface::rightWheelAngleCallback, this);
}

void AbotHardwareInterface::writeCommandsToHardware() {
    double diff_angle_speed_left = _joints[0].velocity_command;
    double diff_angle_speed_right = _joints[1].velocity_command;

    limitDifferentialSpeed(diff_angle_speed_left, diff_angle_speed_right);

    std_msgs::Float32 left_wheel_vel_msg;
    std_msgs::Float32 right_wheel_vel_msg;

    left_wheel_vel_msg.data = diff_angle_speed_left;
    right_wheel_vel_msg.data = diff_angle_speed_right;

    _left_wheel_vel_pub.publish(left_wheel_vel_msg);
    _right_wheel_vel_pub.publish(right_wheel_vel_msg);
}

void AbotHardwareInterface::updateJointsFromHardware(const ros::Duration& period) {
    double delta_left_wheel = _left_wheel_angle - _joints[0].position - _joints[0].position_offset;
    double delta_right_wheel = _right_wheel_angle - _joints[1].position - _joints[1].position_offset;

    if (std::abs(delta_left_wheel) < 1) {
        _joints[0].position += delta_left_wheel;
        _joints[0].velocity = delta_left_wheel / period.toSec();
    } else {
        _joints[0].position_offset += delta_left_wheel;
    }

    if (std::abs(delta_right_wheel) < 1) {
        _joints[1].position += delta_right_wheel;
        _joints[1].velocity = delta_right_wheel / period.toSec();
    } else {
        _joints[1].position_offset += delta_right_wheel;
    }
}

void AbotHardwareInterface::registerControlInterfaces() {
    ros::V_string joint_names = boost::assign::list_of("left_wheel_to_base")("right_wheel_to_base");

    for (unsigned int i = 0; i < joint_names.size(); i++) {
        hardware_interface::JointStateHandle joint_state_handle(joint_names[i], &_joints[i].position, &_joints[i].velocity, &_joints[i].effort);
        _joint_state_interface.registerHandle(joint_state_handle);

        hardware_interface::JointHandle joint_handle(joint_state_handle, &_joints[i].velocity_command);
        _velocity_joint_interface.registerHandle(joint_handle);
    }
    registerInterface(&_joint_state_interface);
    registerInterface(&_velocity_joint_interface);
}

void AbotHardwareInterface::leftWheelAngleCallback(const std_msgs::Float32& msg) {
    _left_wheel_angle = msg.data;
}

void AbotHardwareInterface::rightWheelAngleCallback(const std_msgs::Float32& msg) {
    _right_wheel_angle = msg.data;
}

void AbotHardwareInterface::limitDifferentialSpeed(double& diff_speed_left_side, double& diff_speed_right_side) {
    double large_speed = std::max(std::abs(diff_speed_left_side), std::abs(diff_speed_right_side));
    if (large_speed >  _max_wheel_angular_speed) {
        diff_speed_left_side *=  _max_wheel_angular_speed / large_speed;
        diff_speed_right_side *=  _max_wheel_angular_speed / large_speed;
    }
}

#endif // ABOT_HARDWARE_INTERFACE_HPP_
```

This whole process can be described by classical [Control theory](https://en.wikipedia.org/wiki/Control_theory). We have a [closed-loop controller](https://en.wikipedia.org/wiki/Control_theory#Closed-loop_transfer_function). At the input, there is the desired speed of the robot. At the output, there is the rotation speed of wheels. As a feedback there are the current wheel speeds and angles.

Now let's create `abot_base.cpp` node, which starts the closed-loop controller and hardware interface with the specified `control_frequency`. The `max_wheel_angular_speed` parameter is necessary to prevent accidentally sending large speed values to the driver. This value can be taken from previous chapters.

```cpp
#include <chrono>
#include <functional>
#include <ros/callback_queue.h>

#include "abot_hardware_interface.h"

typedef boost::chrono::steady_clock time_source;

void controlLoop(AbotHardwareInterface& hardware, controller_manager::ControllerManager& cm, time_source::time_point& last_time) {

    time_source::time_point this_time = time_source::now();
    boost::chrono::duration<double> elapsed_duration = this_time - last_time;
    ros::Duration elapsed(elapsed_duration.count());
    last_time = this_time;

    hardware.updateJointsFromHardware(elapsed);
    cm.update(ros::Time::now(), elapsed);
    hardware.writeCommandsToHardware();
}

int main(int argc, char** argv) {
    ros::init(argc, argv, "abot_base_node");
    ros::NodeHandle node;
    ros::NodeHandle private_node("~");

    int control_frequency;
    double max_wheel_angular_speed;

    private_node.param<int>("control_frequency", control_frequency, 1);
    private_node.param<double>("max_wheel_angular_speed", max_wheel_angular_speed, 1.0);

    AbotHardwareInterface hardware(node, private_node, max_wheel_angular_speed);

    controller_manager::ControllerManager cm(&hardware, node);

    ros::CallbackQueue abot_queue;
    ros::AsyncSpinner abot_spinner(1, &abot_queue);

    time_source::time_point last_time = time_source::now();

    ros::TimerOptions control_timer(
        ros::Duration(1 / control_frequency),
        boost::bind(controlLoop, std::ref(hardware), std::ref(cm), std::ref(last_time)), &abot_queue);

    ros::Timer control_loop = node.createTimer(control_timer);

    abot_spinner.start();
    ros::spin();
    return 0;
}
```

Build the new source files:

```bash
catkin_make
```

### Base Launcher

Create a launch file for the `abot_base` node. In package `abot_base`, create folder `launch` with file `abot_base.launch`:

```xml
<launch>
	<node name="abot_base_node" pkg="abot_base" type="abot_base_node" output="screen">
    	<param name="control_frequency" type="int" value="100"/>
		<param name="max_wheel_angular_speed" type="double" value="16.4"/>
	</node>
</launch>
```

## Test the Movement

It's time to test the robot's movement. We have all the packages for this. Let's create a new launcher file for robot motion tests. I name it `bringup.launch`. This launch file does not belong to any package, so I put it in the `launch` folder in the `abot_description` package. In this launcher file, launch all the created nodes and put the robot's URDF model to the parameters server.

```xml
<launch>
	<param name="robot_description" command="$(find xacro)/xacro '$(find abot_description)/urdf/abot.xacro' --inorder"/>
	<node name="robot_state_publisher" pkg="robot_state_publisher" type="robot_state_publisher" respawn="false" output="screen" />

	<include file="$(find abot_base)/launch/abot_base.launch" />
	<include file="$(find abot_control)/launch/abot_control.launch" />
	<include file="$(find abot_driver)/launch/abot_drivers.launch" />
	<include file="$(find abot_teleop)/launch/abot_teleop.launch" />
</launch>
```

I'm going to control the robot's movement from the desktop computer through the ROS network. Make sure that both the robot and the desktop computer are online. Connect to the robot via SSH from your desktop computer.

At the robot, start the ROS core.

```bash
roscore
```

At the robot, in a new terminal, launch the created launch file.

```bash
cd ~/ros
sudo -s
source devel/setup.bash
roslaunch abot_description bringup.launch
```

```bash
root@robot:/home/ubuntu/ros# roslaunch abot_description bringup.launch 
... logging to /root/.ros/log/840711c6-1eaa-11eb-97e3-f90dffb31ac1/roslaunch-robot-3854.log
Checking log directory for disk usage. This may take a while.
Press Ctrl-C to interrupt
Done checking log file disk usage. Usage is <1GB.

xacro: in-order processing became default in ROS Melodic. You can drop the option.
started roslaunch server http://robot:45673/

SUMMARY
========

PARAMETERS
 * /abot_base_node/control_frequency: 100
 * /abot_base_node/max_wheel_angular_speed: 16.4
 * /joint_state_controller/publish_rate: 100
 * /joint_state_controller/type: joint_state_contr...
 * /mobile_abot/angular/z/has_acceleration_limits: True
 * /mobile_abot/angular/z/has_velocity_limits: True
 * /mobile_abot/angular/z/max_acceleration: 10.0
 * /mobile_abot/angular/z/max_velocity: 5.0
 * /mobile_abot/base_frame_id: base_footprint
 * /mobile_abot/cmd_vel_timeout: 0.1
 * /mobile_abot/enable_odom_tf: True
 * /mobile_abot/left_wheel: left_wheel_to_base
 * /mobile_abot/linear/x/has_acceleration_limits: True
 * /mobile_abot/linear/x/has_velocity_limits: True
 * /mobile_abot/linear/x/max_acceleration: 6.1152
 * /mobile_abot/linear/x/max_velocity: 0.6642
 * /mobile_abot/pose_covariance_diagonal: [0.001, 0.001, 10...
 * /mobile_abot/publish_rate: 100.0
 * /mobile_abot/right_wheel: right_wheel_to_base
 * /mobile_abot/twist_covariance_diagonal: [0.001, 0.001, 10...
 * /mobile_abot/type: diff_drive_contro...
 * /mobile_abot/wheel_radius_multiplier: 1.0
 * /mobile_abot/wheel_separation_multiplier: 1.0
 * /robot_description: <?xml version="1....
 * /rosdistro: noetic
 * /rosversion: 1.15.8

NODES
  /
    abot_base_node (abot_base/abot_base_node)
    controller_spawner (controller_manager/spawner)
    dc_motors (abot_driver/dc_motors)
    encoders (abot_driver/encoders)
    robot_state_publisher (robot_state_publisher/robot_state_publisher)

ROS_MASTER_URI=http://robot:11311

process[robot_state_publisher-1]: started with pid [3870]
process[abot_base_node-2]: started with pid [3871]
process[controller_spawner-3]: started with pid [3872]
process[encoders-4]: started with pid [3873]
process[dc_motors-5]: started with pid [3874]
[ INFO] [1604500742.269429269]: DCMotor wiringPi: GPIO setup
[ INFO] [1604500742.270396124]: DCMotor wiringPi: Motor setup
[ INFO] [1604500742.271003256]: DCMotor wiringPi: GPIO setup
[ INFO] [1604500742.274570547]: DCMotor wiringPi: Motor setup
[ INFO] [1604500742.288459728]: Encoder wiringPi: GPIO setup
[ INFO] [1604500742.584368161]: Encoder wiringPi: ISR setup
[ INFO] [1604500742.584681718]: Encoder wiringPi: GPIO setup
[ INFO] [1604500742.770387149]: Encoder wiringPi: ISR setup
[INFO] [1604500744.036463]: Controller Spawner: Waiting for service controller_manager/load_controller
[INFO] [1604500744.056506]: Controller Spawner: Waiting for service controller_manager/switch_controller
[INFO] [1604500744.074904]: Controller Spawner: Waiting for service controller_manager/unload_controller
[INFO] [1604500744.091380]: Loading controller: joint_state_controller
[INFO] [1604500744.170848]: Loading controller: mobile_abot
[ INFO] [1604500744.248660336]: Controller state will be published at 100Hz.
[ INFO] [1604500744.262246442]: Wheel separation will be multiplied by 1.
[ INFO] [1604500744.268321427]: Left wheel radius will be multiplied by 1.
[ INFO] [1604500744.268528169]: Right wheel radius will be multiplied by 1.
[ INFO] [1604500744.271149938]: Velocity rolling window size of 10.
[ INFO] [1604500744.277268405]: Velocity commands will be considered old if they are older than 0.1s.
[ INFO] [1604500744.279907285]: Allow mutiple cmd_vel publishers is enabled
[ INFO] [1604500744.285368250]: Base frame_id set to base_footprint
[ INFO] [1604500744.288966763]: Odometry frame_id set to odom
[ INFO] [1604500744.294588950]: Publishing to tf is enabled
[ INFO] [1604500744.378008407]: left wheel to origin: 0,0.068, 0.0145
[ INFO] [1604500744.378288501]: right wheel to origin: 0,-0.068, 0.0145
[ INFO] [1604500744.378540428]: Odometry params : wheel separation 0.136, left wheel radius 0.03195, right wheel radius 0.03195
[ INFO] [1604500744.391293679]: Adding left wheel with joint name: left_wheel_to_base and right wheel with joint name: right_wheel_to_base
[ INFO] [1604500744.463016167]: Dynamic Reconfigure:
DynamicParams:
	Odometry parameters:
		left wheel radius multiplier: 1
		right wheel radius multiplier: 1
		wheel separation multiplier: 1
	Publication parameters:
		Publish executed velocity command: disabled
		Publication rate: 100
		Publish frame odom on tf: enabled
[INFO] [1604500744.482717]: Controller Spawner: Loaded controllers: joint_state_controller, mobile_abot
[INFO] [1604500744.506911]: Started controllers: joint_state_controller, mobile_abot
```

On the desktop computer, check that all the topics we need have appeared:

```bash
rostopic list
```

![../media/movement_topics.png](../media/movement_topics.png)

To control the robot, use the already familiar utility `rqt` ROS utility and the `rqt_robot_steering` plugin.

![../media/movement_rqt.png](../media/movement_rqt.png)

Set the topic for publishing `geometry_msgs/Twist` messages - `/abot_mobile/cmd_vel`. Move the sliders. The robot should start moving.

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_movement.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

### Visualize Odometry

So we checked how our controller works, but only in one direction. Let's check the operation of the controller in the opposite direction - visualize the odometry.

Create a new launcher file to launch `rviz` visualization. Let's call it `display_movement.launch` and put it in `abot_description/launch`. 

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_movement.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

Here for `rviz`, use the same settings as when viewing the model (`abot_model.rviz`) only this time in *Global Options* set the *Fixed Frame* to `odom`.

Do all the same steps to start the movement described above but now on a desktop machine, in addition to `rqt` steering plugin, also run `rviz`:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_description display_movement.launch
```

Control the robot using the steering plugin and monitor its position in the `rviz` window.

![../media/movement_rviz.png](../media/movement_rviz.png)

This stage is very, very important. You need to ensure that the robot's display in `rviz` does not differ from the robot's actual position. If in reality, for example, your robot drives 1 meter straight and then turns 90 degrees, then in odometry visualization, the robot should go the exact way! If your odometry differs from the robot's actual position, you incorrectly configured the parameters of either the controller or the urdf model. Carefully review all config files.

ВИДЕО! СПЛИТСКРИН ИРЛ+РВИЗ+РУЛЕЖКА RQT.

# Robot Teleoperation

You can control the robot's movement via the `rqt_robot_steering` plugin, but it is not very convenient. It is much easier to control the robot with a joystick.

Let's make the robot's movement teleoperation from a regular Dualshock 4 joystick from the PS4 console. The Dualshock 4 joystick communicates via Bluetooth.

![../media/dualshock_800.jpg](../media/dualshock_800.jpg)

## Setup Drivers

### Setup Raspberry Pi 4 Bluetooth Device

Raspberry Pi 4 already has a Bluetooth module, and you don't need to buy any additional Bluetooth hardware modules. However, the Bluetooth chip communicates with the Raspberry controller via UART, and this UART interface is open for use by default.

We have to sacrifice one hardware UART Raspberry interface and assign the Bluetooth module to it. For Ubuntu Focal (20.04) the Bluetooth activation sequence is as follows:

```bash
sudo apt-get install pi-bluetooth
sudo apt-get install bluetooth bluez blueman
```

Edit the `/boot/firmware/usrcfg.txt` file:

```bash
sudo nano /boot/firmware/usrcfg.txt
```

And add the following line at the end:

```bash
include btcfg.txt
```

Save the file and reboot the Raspberry. Then, check that the Bluetooth device is detected:

```bash
hciconfig -a
```

![../media/teleop_bl_1.png](../media/teleop_bl_1.png)

### Setup Dualshock 4 Driver

Now install the driver for the Dualshock4 joystick on Raspberry. I use an excellent open-source driver [https://github.com/naoki-mizuno/ds4drv](https://github.com/naoki-mizuno/ds4drv). The ROS already has a wrapper package for this driver.

Install the `pip` package installer for Python and the driver:

```bash
sudo apt-get install python3-venv python3-pip
sudo apt-get install python-is-python3
sudo pip3 install ds4drv
```

Pair the PS4 joystick with the Raspberry Pi. For this, take the joystick and simultaneously press the *Sharing* button and the *PS4* button. The joystick LED indicator will start blinking rapidly. 

ВИДЕО! РЕЗКИЕ МИГАНИЯ ДУАЛШОКА 4.

On Raspberry desktop use `blueman` to pair the joystick the first time and create connection. In general, you need a joystick to be defined as a HID device.

![../media/bl_blueman.jpg](../media/bl_blueman.jpg)

If it is neccesary change the Raspbery Pi Bluetooth visibility setting:

![../media/bl_adapter.jpg](../media/bl_adapter.jpg)

When you pair the joystick test the `ds4drv` driver, under root: 

```bash
sudo -s
ds4drv --hidraw
```

![../media/bl_ds4drv.jpg](../media/bl_ds4drv.jpg)

In a new terminal check the new `js` input devices:

![../media/bl_js.jpg](../media/bl_js.jpg)

You can test the joystick buttons with `jstest`:

```bash
sudo apt-get install jstest-gtk
jstest /dev/input/js1
```

### Setup ROS Dualshock Package

In ROS, there is the `[ds4_driver](http://wiki.ros.org/ds4_driver)` package, which is a wrapper for the `ds4drv`. This package was made by the [naoki-mizuno](https://github.com/naoki-mizuno/ds4_driver) community member and is not available in the official ROS Noetic assembly. But, you can build it manually, simply adding it to the `ros` workspace. 

```bash

cd ~/ros/src
git clone https://github.com/naoki-mizuno/ds4_driver.git
cd ~/ros
catkin_make
```

Or you can just clone into the `ros` workspace and build along with abot packages.
Also, install the `[joy](http://wiki.ros.org/joy)` package:

```bash
sudo apt-get install ros-noetic-joy
```

## Abot_teleop Package

Let's create a new package in our `ros` workspace - `abot_teleop`. This package will store all nodes that are somehow connected to the remote control. Set the package dependencies -`[roscpp](http://wiki.ros.org/roscpp)`, `geometry_msgs`, `sensor_msgs`, `joy`.

Conventionally, in the ROS, joystick devices publish messages of the `[sensor_msgs/Joy](http://docs.ros.org/en/api/sensor_msgs/html/msg/Joy.html)` type. The `[ds4_driver](http://wiki.ros.org/ds4_driver)` package that we installed sends messages of this type to the topic `/joy`. This message contains the states of all buttons and joysticks on the device.

I use the Dualshock's left and right joysticks to control the robot's speed. The left joystick's vertical movement is responsible for the linear velocity vector of the robot along the X-axis. The horizontal movement of the right joystick is responsible for the robot's angular velocity around the Z-axis.

We need to write a simple C++ class that responds to changes in joystick buttons states. In the `abot_teleop` package, I create an `src` folder and put the `abot_teleop.hpp` header with the `AbotTeleop` class in it.

What does the `AbotTeleop` class do? This class subscribes to the `/joy` topic and gets data about the states of all Dualshock buttons. Then the positions of the left and right joysticks are multiplied by the limiting coefficients `_linear_speed_scale` and `_angular_speed_scale`. The adjusted positions are translated into velocity vectors and placed in the `geometry_msgs::Twist` type message. The ready message with the robot speed is sent directly to the topic of the differential drive controller - `/mobile_abot/cmd_vel`.

```cpp
#ifndef ABOT_TELEOP_HPP_
#define ABOT_TELEOP_HPP_

#include <ros/ros.h>
#include <geometry_msgs/Twist.h>
#include <sensor_msgs/Joy.h>

#define PS4_AXIS_STICK_LEFT_LEFTWARDS 0
#define PS4_AXIS_STICK_LEFT_UPWARDS 1
#define PS4_AXIS_STICK_RIGHT_LEFTWARDS 2
#define PS4_AXIS_STICK_RIGHT_UPWARDS 3

class AbotTeleop {
public:
    AbotTeleop(ros::NodeHandle private_node);
private:
    ros::NodeHandle _node;
    ros::NodeHandle _private_node;
    ros::Subscriber _joy_sub;
    ros::Publisher _cmd_vel_pub;

    bool _last_zero_twist = true; 
    double _linear_speed_scale;
    double _angular_speed_scale;
    
    void joyCallback(const sensor_msgs::Joy::ConstPtr& joy);
};

AbotTeleop::AbotTeleop(ros::NodeHandle private_node) :
    _private_node(private_node) {

    _private_node.param<double>("linear_speed_scale", _linear_speed_scale, 0.0);
    _private_node.param<double>("angular_speed_scale", _angular_speed_scale, 0.0);
    _cmd_vel_pub = _node.advertise<geometry_msgs::Twist>("/mobile_abot/cmd_vel", 1);
    _joy_sub = _node.subscribe<sensor_msgs::Joy>("joy", 10, &AbotTeleop::joyCallback, this);
    ROS_INFO("Abot teleop node: Start");
}

void AbotTeleop::joyCallback(const sensor_msgs::Joy::ConstPtr& joy) {

    geometry_msgs::Twist twist;

    double twist_linear_x_vel =  _linear_speed_scale * joy->axes[PS4_AXIS_STICK_LEFT_UPWARDS];
    double twist_angular_z_vel = _angular_speed_scale * joy->axes[PS4_AXIS_STICK_RIGHT_LEFTWARDS];

    twist.linear.x = twist_linear_x_vel;
    twist.angular.z = twist_angular_z_vel;

    if (twist_linear_x_vel == 0 && twist_angular_z_vel == 0) {
        if (_last_zero_twist == false) {
            _cmd_vel_pub.publish(twist);
            _last_zero_twist = true;
        } 
    } else {
        _last_zero_twist = false;
        _cmd_vel_pub.publish(twist);
    }
}

#endif // ABOT_TELEOP_HPP_
```

In the `src` folder, create the `abot_teleop.cpp` file that contains the node to work with our class.

```cpp
#include "abot_teleop.hpp"

int main(int argc, char **argv) {
    ros::init(argc, argv, "abot_teleop_node");
    ros::NodeHandle private_node("~");
    AbotTeleop abotTeleop(private_node);
    ros::spin();
}
```

Add the executable to the `CMakelists.txt` file in the `abot_teleop` pakage:

```makefile
add_executable(abot_teleop src/abot_teleop.cpp)
target_link_libraries(abot_teleop ${catkin_LIBRARIES})
```

Finally, build the new nodes:

```bash
cd ~/ros
catkin_make
```

### Teleoperation Launch

Let's create the new launch file to run the `ds4drv` wrapper and the teleoperation node.

In the `abot_teleop` package, create the `launch` folder and put the following `abot_teleop.launch` file into it.

```xml
<launch>
	<arg name="addr" default="" />
	<arg name="use_standard_msgs" default="true" />
	<arg name="autorepeat_rate" default="50" if="$(arg use_standard_msgs)" />
	<node pkg="ds4_driver" type="ds4_driver_node.py" name="ds4_driver" output="screen" >
		<param name="device_addr" value="$(arg addr)" />
		<param name="use_standard_msgs" value="$(arg use_standard_msgs)" />
		<param name="autorepeat_rate" value="$(arg autorepeat_rate)" if="$(arg use_standard_msgs)" />
		<param name="deadzone" value="0.1" />
	</node>
	<node pkg="abot_teleop" type="abot_teleop" name="abot_teleop" >
		<param name="linear_speed_scale" type="double" value="0.04"/> 
		<param name="angular_speed_scale" type="double" value="0.80"/>
	</node>
</launch>
```

The `linear_speed_scale` parameter sets the robot's maximum linear speed to 0,04 m/s, and the `angular_speed_scale` parameter sets the angular speed to 0,8 rad/s. 

Also include the new launcher file in the shared launcher file `abot_description/bringup_movement.launch` that we use for robot's movement:

```xml
<include file="$(find abot_teleop)/launch/abot_teleop.launch" />
```

## Launch the Motion

Everything is ready to control the robot with the joystick. On the Raspberry, in a new terminal, launch the bring up file:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_description bringup.launch
```

To visualize the movement, on the desktop computer run rviz:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_description display_movement.launch
```

Control the robot with the joystick and monitor its movement in the `rviz`.

ВИДЕО! РУЛИМ РОБОТОМ С ДЖОЙСТИКА. СПЛИТ СКРИН ИРЛ+ДЖОЙ+РВИЗ.

# Robot Navigation

Let's deal with navigation. Suppose there is some environment around the robot. To navigate in this environment, the robot must "see" it and localize in it. For this, robots use different sensors. How a robot sees the surrounding environment depends on the sensors it has.

These sensors can be simple or complex, 2D or 3D. These can be cameras, depth cameras, laser/ultrasonic/infrared rangefinders, simple binary contact sensors (bumpers), etc. The more sensors installed at the robot and the better they are synchronized with each other, the more information the robot can get about the world around it. ROS supports a wide variety of sensors. Read more in the [documentation](http://wiki.ros.org/Sensors).

## RPLIDAR A1

For beginners, it is best to start with simple, effective, and popular sensors. The best sensor for beginners is a [LIDAR](https://en.wikipedia.org/wiki/Lidar) with a 360-degree field of view. 

This 2D sensor can scan the entire plane in which it is installed. Why LIDAR? This type of sensor is so effective that a single device can be enough for a robot to perform navigation in a room. I chose the most popular and low-cost [RPLIDAR A1](https://www.slamtec.com/en/Lidar/A1) by SLAMTEC.

![../media/lidar.jpg](../media/lidar.jpg)

This sensor provides a 360-degree scanning field, with a 5.5Hz/10Hz rotation frequency. The range of the RPLIDAR A1 is about 8 meters. This lidar comes as a complete device. You just need to mount it on your robot and connect it to the robot's onboard computer. The easiest way to connect the RPLIDAR is to use the USB port.

The main reason I use this particular sensor is the [ROS RPLIDAR package](http://wiki.ros.org/rplidar) and ROS support from the manufacturer.

### Mount the Sensor

For the lidar mount, I cut out another plexiglass pad and attached RPLIDAR A1 to it. 

ФОТО! Лидар с падом.

The LIDAR rotates, and there should be no other robot parts around to interfere with the scan. Most often, the LIDAR is the highest point of the robot. On different robots, LIDARs are installed different ways and in different places. It is best to install LIDAR closer to the ground. The efficiency of detecting obstacles for LIDARs installed in this way is higher. However, the low-level LIDAR has a reduced viewing angle because of other surrounding robot parts. I decided to install my LIDAR on top of the robot. So, it cannot detect low-height obstacles, but it keeps a circular view.

ФОТО! Лидар с падом на роботе.

### Update the Robot Description

Get used to reflect any real robot changes in the 3D model and URDF description. I added new parts to the 3D model CAD model of the robot.

![../media/6.png](../media/6.png)

For the LIDAR, you also need to create a link in the URDF robot description. 

When adding sensors to the robot description, it is crucial to set the correct proper coordinate systems and axes of the sensor action. For RPLIDAR A1 in ROS, the following reference coordinate system orientation is recommended:

![../media/rplidar_A1_frame.png](../media/rplidar_A1_frame.png)

Create a new coordinate system for the LIDAR sensor:

![../media/ABOT_4.png](../media/ABOT_4.png)

Export the new URDF data. Add a new link and a fixed joint to the element tree; Link to indicate the LIDAR's frame and joint to define the LIDAR scan plane's initial point. I named my link `abot_lidar` and joint `lidar_to_base`.

![../media/4-1-1-1.png](../media/4-1-1-1.png)

Go to the `ros` workspace to the `abot_description` package. Put the new *.STL lidar file to the `meshes` folder. In the `urdf` folder, create a new `xacro` file for describing the sensors and fill it with new URDF export data. I called mine `abot_sensors.xacro`.

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- lidar -->
	<link name="abot_lidar">
		<inertial>
			<origin xyz="0.0118769386096909 -0.000753838771765047 -0.0199066395735294" rpy="0 0 0" />
			<mass value="0.601249620501043" />
			<inertia ixx="0.000163971147126097" ixy="-2.03059193776652E-07" ixz="-3.50083356803378E-06" iyy="0.000195001082010381" iyz="1.20160266671478E-07" izz="0.000341179024466778" />
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_lidar.STL" />
			</geometry>
			<material name="Yellow" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_lidar.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="lidar_to_base" type="fixed">
		<origin xyz="-0.01 0 0.1494" rpy="0 0 3.14159265358979" />
		<parent link="abot_base" />
		<child link="abot_lidar" />
		<axis xyz="0 0 0" />
	</joint>
</robot>
```

Include the sensors file at the end of the main description file `abot.xacro`:

```xml
<xacro:include filename="$(find abot_description)/urdf/abot_sensors.xacro" />
```

 In the `ros` workspace, launch the `display_model.launch` file and observe description changes in `rviz`.

![../media/rivz_with_lidar.jpg](../media/rivz_with_lidar.jpg)

### USB Device Alias

RPLIDAR connects to the Raspberry via the USB port. Let's create a USB device alias for LIDAR. Using the alias, the OS determines the lidar device, no matter which USB port it is physically plugged.

Connect the LIDAR and see how it is defined in the system:

```bash
lsusb
ls /dev | grep ttyUSB
```

I've got LIDAR defined as `Bus 001 Device 003: ID 10c4:ea60 Silicon Labs CP210x UART Bridge`. Here the `10c4` is the Vendor ID, `ea60` is the Product ID. I use this data to identify the LIDAR.

![../media/usb-1.png](../media/usb-1.png)

Also, you can get more information about the unique attributes of the USB device:

```bash
udevadm info -a -n /dev/ttyUSB0
```

Create a new UDEV rule. Make a new file `99-usb-serial.rules` inside `/etc/udev/rules.d`. Under root.

```bash
sudo nano /etc/udev/rules.d/99-usb-serial.rules
```

Put the following line into the rule.

```bash
SUBSYSTEM=="tty", ATTRS{idVendor}=="10c4", ATTRS{idProduct}=="ea60", SYMLINK+="lidar"
```

According to this rule, any connected device with such `idVendor` and `idProduct` is defined with the `lidar` name. Reload UDEV rules, reconnect RPLIDAR, and make sure that the new alias works:

```bash
sudo udevadm control --reload-rules && udevadm trigger
ls -l /dev/lidar
```

![../media/usb-2.png](../media/usb-2.png)

### PLIDAR ROS Package

To use RPLIDAR A1 in ROS, you do not need to install any additional drivers, just install the ROS `[rplidar_ros](http://wiki.ros.org/rplidar)` package. This package is not yet available in the official ROS Noetic assembly, but you can clone it into your ROS workspace and build it.

```bash
cd ~/ros/src
git clone https://github.com/Slamtec/rplidar_ros.git
cd ~/ros
catkin_make
```

To launch the RPLIDAR, create a new launcher file `abot_lidar.launch`. Since the LIDAR refers to the robot's hardware devices, put the launch file in the `abot_driver/launch` package folder. This file runs the `rplidarNode` node from the `rplidar_ros` package. The RPLIDAR communicates via the UART interface at a default baud rate of 115200. As a path to the interface, specify the USB device alias `/dev/lidar` created earlier. Also here you need to specify the `frame_id` name of the link that describes the LIDAR in URDF. I have this link named `abot_lidar`.

```xml
<launch>
	<node name="rplidarNode" pkg="rplidar_ros"  type="rplidarNode" output="screen">
		<param name="serial_port" type="string" value="/dev/lidar"/>  
		<param name="serial_baudrate" type="int" value="115200"/>
		<param name="frame_id" type="string" value="abot_lidar"/>
		<param name="inverted" type="bool" value="false"/>
		<param name="angle_compensate" type="bool" value="true"/>
		<param name="scan_mode" type="string" value="Boost" />
	</node>
</launch>
```

 Include the file for launching LIDAR into the general `abot_drivers.launch` file for launching all robot drivers:

```xml
<include file="$(find abot_driver)/launch/abot_lidar.launch" />
```

### Visualize the LIDAR Scan

Let's test how the LIDAR works. On the Raspberry side, launch:

```bash
cd ~/ros
sudo -s 
source devel/setup.bash
roslaunch abot_desription bringup.launch
```

Visualize the LIDAR's operation in `rviz`. In the `abot_description` package, create a new launch file to visualize the robot's sensors. I called my `display_sensors.launch`.

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_sensors.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

This launch file runs `rviz` with new visualization settings `abot_sensors.rviz`. As a source `rviz` settings, you can use any existing file, for example, `abot_movement.rviz`. At the desktop computer, at the `ros` workspace run:

```bash
roslaunch abot_description display_sensors.launch
```

In the `rviz` settings, add a new visualization for an existing topic. By default, the data from the LIDAR is of the `sensor_msgs/laserscan` type, and it is published to the `/scan` topic. In `rviz` click *Add → Create visualization → By topic* and select the `/scan` topic.

![../media/lidar_rviz.png](../media/lidar_rviz.png)

Take a look at the scan points that appear. Try to control the robot with the joystick and make sure that everything works as it should.

![../media/lidar_rviz_2.png](../media/lidar_rviz_2.png)

ВИДЕО! Сплит скрин. Рвиз+скан+движение+джойстик.

## Navigation Theory

The creation of autonomous mobile robots is a challenging task that requires enormous theoretical and practical knowledge. Here is how I understand it. Autonomous robot navigation is based on three main tasks:

- *[Mapping](https://en.wikipedia.org/wiki/Robotic_mapping)*
- *[Localization](https://en.wikipedia.org/wiki/Robot_navigation)*
- *[Path planning](https://en.wikipedia.org/wiki/Motion_planning)*

The *Mapping* task is to answer the robot's question: "What does the world around me look like?" During *Mapping*, the data from various sensors passes to a robot in a given and understandable representation (map). 

The *Localization* task is to answer the robot's question: "Where am I in the world around me?" During *Localization*, a robot calculates its position relative to the known map. A robot should be able to find itself on the known map wherever it is placed.

The *Path planning* task is to answer the robot's question: "How can I get to a specific point on the map?" A human can set a specific point for a robot to move to, or a robot can set a target point itself. A robot should plan the motion path to the target point and safely and efficiently reach it.

Various combinations of these three components allow a mobile robot to solve different navigation tasks.

![../media/tasks.png](../media/tasks.png)

*SLAM* is [simultaneous localization and mapping](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping). There is a close relationship between *Localization* and *Mapping*. In an unknown environment, mapping and localization cannot be separated. This is because a robot needs to know its current accurate position to make a map, and it needs a good map to know its current position.

The *Active localization* seeks to guide a robot to target points within a map to improve its current position.

The *Exploration* assumes that a robot knows its accurate position and focuses on guiding a robot eﬃciently through the unknown environment to build a map.

The *Integrated approaches* is also called *SPLAM* (simultaneous planning, localization, and mapping). *SPLAM* enables a mobile robot to acquire sensor data by autonomously moving the unknown environment while at the same time building a map.

The task of my robot is good-quality room navigation. First, I'm going to use *SLAM* algorithms to build a map of the room. Then my robot will move autonomously on this map using *Active localization* and *Path planning*.

## Mapping

There are several SLAM algorithms. I'm going to use the [OpenSLAM](https://openslam-org.github.io/) algorithm. ROS has a popular wrapper package for this algorithm - `[gmapping](http://wiki.ros.org/gmapping)`. 

### Gmapping package

For the `[gmapping](http://wiki.ros.org/gmapping)` package to build a map, you need a mobile controlled robot, robot's Odometry, and a LIDAR attached to the robot. I already have all of this. My robot is mobile, I can control the robot from the joystick. I've got simple robot's Odometry at the `/odom` topic. My Odometry comes from the `mobile_abot` differential drive controller. The LIDAR that i have publishs laser scans to the default `/scan` topic.

I create a new package `abot_slam` in the `ros` workspace with dependencies `gmapping` and `sensor_msgs`. In this package, I create three folders: `launch`, `config`, and `maps`. In the `config` folder I store the `gmapping` package settings. In the `launch` folder, I have ROS launch files for SLAM. In the `maps` folder, I keep obtained maps.

Let's create the `gmapping_params.yaml` config file for the `gmapping` settings. Read more about all parameters in the official [ROS documentation for the `gmapping` package](http://wiki.ros.org/gmapping). Most of the settings can be left default. The main thing is to specify the following parameters: `base_frame`, `odom_frame`, `map_frame`, `xmax`, `xmin`, `ymax`, `ymin`, `delta`, `particles`, `map_update_interval`, `maxUrange`, `linearUpdate`, `angularUpdate`, `temporalUpdate`, `resampleThreshold`.

The finished map is an image consisting of white or black squares. A black square indicates an occupied space; a white one indicates a free space. I'm building square map 40 by 40 meters with the origin in the square center and resolution of one `0.02`m. With these parameters, I get the highest map quality:

```yaml
base_frame: base_footprint # The frame attached to the mobile base. 
odom_frame: odom # The frame attached to the odometry system. 
map_frame: map # The frame attached to the map.

map_update_interval: 2.0 # How long (in seconds) between updates to the map. Lowering this number updates the occupancy grid more often, at the expense of greater computational load. 
maxUrange: 5.0 # The maximum usable range of the laser. A beam is cropped to this value. 

linearUpdate: 0.2 # Process a scan each time the robot translates this far 
angularUpdate: 0.2 # Process a scan each time the robot rotates this far 
temporalUpdate: 0.5 # Process a scan if the last scan processed is older than the update time in seconds. A value less than zero will turn time based updates off. 
resampleThreshold: 0.5 # The Neff based resampling threshold 

particles: 100 # Number of particles in the filter (int, default: 30)
minimumScore: 50

xmax: 20.0
xmin: -20.0
ymax: 20.0
ymin: -20.0

delta: 0.02 # Resolution of the map (in metres per occupancy grid block) 

# Keep default
sigma: 0.05 # The sigma used by the greedy endpoint matching (float, default: 0.05) 
kernelSize: 1 # The kernel in which to look for a correspondence (int, default: 1) 
lstep: 0.05 # The optimization step in translation (float, default: 0.05) 
astep: 0.05 # The optimization step in rotation (float, default: 0.05)
iterations: 5 # The number of iterations of the scanmatcher (int, default: 5)

lsigma: 0.075 # The sigma of a beam used for likelihood computation float, default: 0.075) 
ogain: 3.0 # Gain to be used while evaluating the likelihood, for smoothing the resampling effects float, default: 3.0)
lskip: 0 # Number of beams to skip in each scan. Take only every (n+1)th laser ray for computing a match (0 = take all rays) 

srr: 0.1 # Odometry error in translation as a function of translation (rho/rho) (float, default: 0.1) 
srt: 0.2 # Odometry error in translation as a function of rotation (rho/theta) (float, default: 0.2) 
str: 0.1 # Odometry error in rotation as a function of translation (theta/rho) (float, default: 0.1) 
stt: 0.2 # Odometry error in rotation as a function of rotation (theta/theta) (float, default: 0.2) 

llsamplerange: 0.01 # Translational sampling range for the likelihood  (float, default: 0.01) 
llsamplestep: 0.01 # Translational sampling step for the likelihood (float, default: 0.01) 
lasamplerange: 0.005 # Angular sampling range for the likelihood (float, default: 0.005) 
lasamplestep: 0.005 # Angular sampling step for the likelihood (float, default: 0.005)
```

In the `launch` folder, create a new file `abot_slam.launch` to launch SLAM. This file runs the `gmapping` package with the settings specified in the `config`.

```xml
<launch>
	<node pkg="gmapping" type="slam_gmapping" name="abot_slam_gmapping" output="screen">
		<rosparam command="load" file="$(find abot_slam)/config/gmapping_params.yaml" />
	</node>
</launch>
```

Also, you need to create a new visualization file for mapping. As usual, I place visualization files in the `abot_description` package. There I make a new launch file `display_slam.launch`. This file runs the SLAM package and rviz with new settings.

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_slam.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false" output="screen"/>
	
	<include file="$(find abot_slam)/launch/abot_slam.launch" />
</launch>
```

The new visualization settings `abot_slam.rviz` differ from the previous in the *Global Options → Fixed Frame* attribute. It should be `map`. In addition the camera is positioned perpendicular to the ground.

### Launch Mapping

Let's start the mapping process. Mapping can be computationally intensive, while my Raspberry is pretty weak. So I run it on my desktop ROS.

Make sure that both the robot and the desktop computer are in the ROS network. Launch the packages placed in the Raspbbery's workspace with the familiar launch file:

```bash
cd ~/ros
sudo -s 
source devel/setup.bash
roslaunch abot_desription bringup.launch
```

On desktop ROS, run the SLAM algorithm and visualization:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_desription display_slam.launch
```

![../media/slam_1.png](../media/slam_1.png)

Build a map by controlling the movement of the robot. You can control it using the joystick or the `rqt` steering plugin.

![../media/slam_2.png](../media/slam_2.png)

ВИДЕО! СПЛИТ скрин, контроллим робота с джоя. Строим карту. Ездим по офису.

### Save Map

When the map is ready save it. While SLAM is active, in a new terminal run the `map_saver` utility:

```bash
cd ~/ros/src/abot_slam/maps/
rosrun map_server map_saver -f map1
```

Finished maps are stored as a yaml file and a graphic image in *pgm format. If you want you can edit the map in a graphical editor, for example, to place additional walls or clear excess points.

![../media/map1.png](../media/map1.png)

## ROS Navigation Stack

When the map is ready, you can start navigating it and path planning. For navigation in ROS, I use the conventional [navigation stack](http://wiki.ros.org/navigation?distro=noetic). It contains a lot of cool packages. The stack's essence is that it takes data from Odometry, data from sensors, robot's goal position on the map, and calculates the robot's speeds for the motion controller.

I create a new package and name it `abot_navigation`. There I make two folders `config` and `launch` to store the navigation settings and launch files, respectively.

My robot's navigation is based on two packages from the ROS stack: `[move_base](http://wiki.ros.org/move_base)` and `[acml](http://wiki.ros.org/amcl?distro=noetic)`. The `move_base` node is responsible for planning the path and reaching the specified point on the map. The `acml` is an active localization node that implements an adaptive (or KLD-sampling) [Monte Carlo localization algorithm](https://en.wikipedia.org/wiki/Monte_Carlo_method). I advise you to read the official ROS documentation for these nodes. Try to get an understanding of what these nodes are for and how they work.

At first, configure the `move_base` node. When planning a robot path, the `move_base` works with two types of path planners: `[global_planner](http://wiki.ros.org/global_planner?distro=noetic)` and [`base_local_planner`](http://wiki.ros.org/base_local_planner?distro=noetic). The global planner makes a route to the goal position using a global map. The map can be ready-made or can be built in real-time. The local planner is a kind of add-on to the global planner. The local planner is responsible for driving the robot around obstacles encountered on the global path. Suppose you have a ready-made map and place the robot on it and specify the goal position. The global planner builds you a path to this position avoiding the global obstacles found on the map (for example, the walls). While moving to the goal position, the local planner corrects the path if dynamic obstacles (such as a person) appear.