
---
title: Как сделать своего ROS робота
short: Пошаговая инструкция как сделать простого робота работающего на Raspberry Pi 4, ROS и C++
date: 2021-04-07
author: Максим Данилин
all_tags:
 - Raspberry Pi 4
 - С++
 - ROS
 - Linux
 - Solidworks
 - RPLIDAR
 - Troyka Hat
 - 3D Печать
 - Двухканальный Н-мост
---

# Введение

Привет!

В этой статье мы на примере расскажем о том как создать простого робота работающего на OS ROS. Это будет наш первый настоящий робот со своей операционной системой. Далее мы постараемся пошагово и как можно подробней рассказать вам о процессе проектирования, конструирования и программирования робота а так же расскажем с каким трудностями и проблемами мы столкнулись.

Создание свеого робота это не сложная но и нетривиальная задача. Данная задача требует определенных хотя бы минимальных следующих навыков:

- Работа с OS Linux
- 3Д твердотельное моделирование
- Программирование на С++ или Python
- Навыки 3Д печати

Так же понадобится персональный компьютер под управлением OS Linux и OS Windows и локальная Wi-Fi сеть.

Все исходники как конструкторские CAD файлы так и код мы разместили в Github репозитории [https://github.com/gabbapeople/abot](https://github.com/gabbapeople/abot).

# Цель робота

Постройка робота начинается с идеи. Прежде чем лететь собирать робота вам нужно ответить для себя на следующие вопросы:

- Как должен выглядеть мой робот?
- Из каких частей/узлов мой робот будет состоять?
- Что мой робот должен делать и как?

Все настоящие роботы создаются с какой либо целью. Человек стремится облегчить себе жизнь переложив часть своих задач на робота. Робот может выполнять тяжелую физическую работу, например сварочные роботы манипуляторы или транспортные роботы на автоматизированных складах-хранилищах. Или же робот может выполнять потенциально опасные для человека работы, например разминирование или работа в завалах или токсичных, ядовитых средах. Так же робот робот может избавить человека от рутинных задач для экономия времени - робот пылесос, автономный транспорт.

Цель создания робота практически полностью определяет его внешний вид, конструкцию и программу. Обычно робот созданный для работы в одной области не способен работать в какой либо другой. Цель создания нашего робота будет скорее обучающей и развлекательной нежели практической.

Мы попробуем создать робота "офисного питомца". Этакий робот который будет жить с нами в офисе и передвигаться туда куда мы ему скажем при этом робот должен будет самостоятельно ориентироваться в помещении. Кажется что навигация в помещении это легкая задача однако это совсем не так. В дальнейшем мы будем добавлять функционал нашему роботу но начнем именно с этой конкретной задачи.

Итак раз мы решили что робот не стационарный а мобильный то он должен каким то образом передвигаться.

# Привод робота

## Типы приводов

Рассмотрим разные типы приводов мобильных роботов, выясним какую механику эти привода используют, выделим их плюсы и минусы. Затем выберем привод для нашего робота.

Роботы могут передвигаться в 2D или 3D пространстве. Очевидно, роботы способные двигаться в трехмерном пространстве - летающие. Это чрезвычано сложные роботы, например летающие дроны способные ориентироваться в помещении или на местности используя трехмерные камеры глубины. Постойка такого робота требует сложнейшего железа и программного обеспечения поэтому летающего робота мы не рассматриваем.

Если робот передвигается только в двухмерном пространстве то все становится уже проще. Мы можем рассмотреть движение робота как движение материальной точки в плоскости (X, Y) в [прямоугольной или Декартовой системе координат](https://ru.wikipedia.org/wiki/Прямоугольная_система_координат) (X, Y, Z).

В этой плоскости движение робота может быть [голономным](https://ru.wikipedia.org/wiki/Голономная_система) (Holonomic) или [неголономным](https://ru.wikipedia.org/wiki/Неголономная_система) (Non-holonomic). Что это значит? При голономном движении, движение робота не имеет каких либо ограничений и он способен двигаться по любому верктору XY не меняя при этом своей ориентации. При неголономном движении, движение робота ограничено и он может передвигаться только в нескольких направлениях.

![../media/part_1_robot_drive_1_scheme_1.png](../media/part_1_robot_drive_1_scheme_1.png)

Например, обычный классический автомобиль не может из места переехать строго вправо или влево, значит его движение неголономно. С другой стороны если бы у автомобиля вместо обычных колес стояли [всенаправленные колеса](https://ru.wikipedia.org/wiki/Всенаправленное_колесо) то он смог бы двигаться голономно.

Вы наверное спрашиваете себя "Зачем мне все это нужно знать?". Понимание того каким именно образом двигается робот и понимание принципов получения проекций его скоростей в системе координат чрезвычано важно при создании программы контроллера движения робота. Чем больше направлений движения и вращения имеет робот тем сложнее сконструировать его механику и контролировать его движение.

Еще одиним важным фактором при выборе привода робота является сложность получения одометрии и ее точность.

[Одометрия](https://ru.wikipedia.org/wiki/Одометрия) это использование данных полученных с различных сенсоров и датчиков установленных на роботе для расчета его текущего положения и ориентации в пространстве. С некоторых приводов получить качественную одометрию очень легко, например с двухколесного дифференциального привода (2WD differential drive). Для этого достаточно парочки колесных энкодеров. С других же приводов получить точную одометрию невероятно трудно, например шагающие робо-собаки или роботы гуманоиды. Для одометрии подобных роботов понадобятся десятки различных 2D и 3D сенсоров и сложнейший софт.

Мы попробовали выделить как двигаются самые популярыне хобби роботы.

## Дифференциальный привод двумя ведущими колесами и пассивными колесами

[Двухколесный дифференциальный привод](https://en.wikipedia.org/wiki/Differential_wheeled_robot) это самый простой и распространенный тип привода робота в хобби робототехнике. Именно такой тип привода установлен на домашних роботах пылесосах.

Двухколесное дифференциально шасси состоит из двух ведущих колес установленных на противоположных сторонах корпуса робота и одного или нескольких всенаправленных (пассивных) колес или опор. Каждое ведущее колесо приводится в движение собственным мотором. Моторы управляются независимо друг от друга. Пассивные колеса устанавливаются на такое шасси для достжения равновесия всей платформы.

К слову такой тип привода имеет наша [Робоняша](prod://robonyasha-iskra-js) и [Драгстер](prod://dragster).

Движение двухколесного дифференциально привода неголономно. Движение робота задается линейной скоротью по оси Х (вперед или назад) и угловой скоростью вокруг оси Z (вращение на месте). Синтез этих двух скоротей заставляет робота поворачивать во время движения.

Вот основные типы движения такого робота:

![../media/ru_part_1_robot_drive_2_scheme_1.png](../media/ru_part_1_robot_drive_2_scheme_1.png)

![../media/ru_part_1_robot_drive_2_scheme_2.png](../media/ru_part_1_robot_drive_2_scheme_2.png)

![../media/ru_part_1_robot_drive_2_scheme_3.png](../media/ru_part_1_robot_drive_2_scheme_3.png)

![../media/ru_part_1_robot_drive_2_scheme_4.png](../media/ru_part_1_robot_drive_2_scheme_4.png)

Особенности шасси:

- Легко сконструировать.
- Легко программировать контроллер движения.
- Легко получить относительно качественную одометрию всего двумя датчиками вращения колес.
- Шасси не предназначено для движения по бездорожью. Любая значительная преграда на пути может вывести двухколесную платформу из равновесия. Чаще всего это шасси используется в помещении и для движения по ровной поверхности.

![../media/part_1_robot_drive_2_showcase_1.jpg](../media/part_1_robot_drive_2_showcase_1.jpg)

Turtlebot3 от Robotis

![../media/part_1_robot_drive_2_showcase_2.jpg](../media/part_1_robot_drive_2_showcase_2.jpg)

PAL Robotics

![../media/part_1_robot_drive_2_showcase_3.jpg](../media/part_1_robot_drive_2_showcase_3.jpg)

Мобильный робот MP-500 от Neobotix

![../media/part_1_robot_drive_2_showcase_4.jpg](../media/part_1_robot_drive_2_showcase_4.jpg)

The Innok Robotics

## Дифференциальный привод Skid-steer

Привод skid-steer это расширенная версия простого двухколсеного дифференциальный привода. В этом приводе состояние равновесия платформы достигается не пассивными колесами как в двухколесном приводе а дополнительными ведущими. На каждой стороне робота может быть четыре, пять, шесть и более колес. Все колеса на одной стороне робота управляются общим мотором через передачи и вращаются с одинаковой скоростью. Обычно, в этом шасси, так же как и в двухколесном, используются два мотора, но бывают плафтормы где каждое колесо управлятся собственным мотором.
  
Движение привода skid-steer неголономно. Принцип движения такой же как и у двухколесного дифференциального привода.

Пример задания скоростей робота:

![../media/ru_part_1_robot_drive_3_scheme_1.png](../media/ru_part_1_robot_drive_3_scheme_1.png)

Особенности шасси:

- В сравенении с двухколесной платформой skid-steer обладает большей проходимостью. Это достигается благодаря множеству колес и отсутствии пассивных колес и опор. Робот с большими колесами может быть очень эффективен на пересеченой местности.
- Одометрию так же легко получить используя датчики вращения колес. Однако каждое колесо шасси skid-steer нуждается в собственном сенсоре. Точность одометрии, в сравенении с двухколесной платформой, заметно ниже. При поворотах робота, колеса шасси проскальзывают. При движении такого шасси по ровной местности, моменты заноса и скольжения можно определить и исправить программно. Для получения одометрии при движении skid-steer робота по пересеченной местности одних только датчиков вращения колес может быть уже не достаточно.

![../media/part_1_robot_drive_3_showcase_1.jpg](../media/part_1_robot_drive_3_showcase_1.jpg)

Husky robot

![../media/part_1_robot_drive_3_showcase_2.jpg](../media/part_1_robot_drive_3_showcase_2.jpg)

Wild Thumper 6WD by DAGU Electronics

![../media/part_1_robot_drive_3_showcase_3.jpg](../media/part_1_robot_drive_3_showcase_3.jpg)

The Innok Robotics

## Дифференциальный привод с гусеницами

Дифференциальный привод с гусеницами (танковое шасси) это версия привода skid-steer только с гусеницами вместо дополнительный колес. Как и ранее, каждая гусеница и сторона робота контролируется одним мотором.
Можно интерпретировать этот привод как двухколесный дифференциальный привод где колесо имеет не круглую форму и большую длину окружности. Или как привод skid-steer с бесконечным количеством колес на определенной длине.

Движение привода с гусеницами неголономно. Принцип движения такой же как и у skid-steer привода. В этом случае для расчета скоростей робота используются не угловые скорости колес а скорости гусениц.

Особенности шасси:

- Танковое шасси обладает самыми высокими эксплуатационными характеристиками на пересеченной местности благодаря форме гусениц и сцеплению с землей.
- Усложненная механика. В конструкции танкового шасси множество не простых деталей: части трака, натяжители, опорные колеса и.т.д.
- Получить одометрию еще сложнее, чем при использовании skid-steer привода. Как и при использовании skid-steer привода, при движении танкового шасси происходят проскальзывания гусениц и заносы (особенно это заметно, когда робот танк вращается на месте на ровной поверхности). Однако ввиду наличия всего двух датчиков вращения программно компенсировать ошибки одометрии очень тяжело. Использование датчиков вращения при движении по пересеченой местности практически бесполезно и для одометрии нужны другие источники. При движении по ровной поверхности, одометрия с датчиков вращения не точная.

![../media/part_1_robot_drive_4_showcase_1.jpg](../media/part_1_robot_drive_4_showcase_1.jpg)

Robodyne MAXXII

![../media/part_1_robot_drive_4_showcase_2.jpg](../media/part_1_robot_drive_4_showcase_2.jpg)

Tank chassis

![../media/part_1_robot_drive_4_showcase_3.jpg](../media/part_1_robot_drive_4_showcase_3.jpg)

Dragon Runner Bomb Disposal Robot

## Рулевой привод Аккермана

[Ackermann steering](https://en.wikipedia.org/wiki/Ackermann_steering_geometry) привод - самый распространенный в мире, так как используется в каждом автомобиле. Привод Аккермана состоит из двух ведущих колес и двух рулевых колес. Ведущая пара колес отвечает за движение робота. Рулевые колеса отвечают за поворот робота. Чтобы избежать заноса и скольжения, рулевое управление Аккермана спроектировано таким образом, что при повороте внутреннее колесо поворачивается на больший угол, чем внешнее. Для каждого колеса угол поворота рассчитывается на основе желаемого диапазона углов поворота робота.

Рулевой привод Аккермана имеет неголономное движение. Этот привод управляется линейной скоростью вдоль оси X и угловой скоростью по оси Z. Но в отличие от дифференциальных приводов, при ненулевой угловой скоростью вокруг оси Z, линейная скорость по X не может быть равна нулю. Робот, как и автомобиль не может развернуться стоя на месте.

![../media/ru_part_1_robot_drive_5_scheme_1.png](../media/ru_part_1_robot_drive_5_scheme_1.png)

Особенности шасси:

- Рулевое управление Аккермана обычно используется на ровной поверхности для быстро движущихся роботов, которые нуждаются в большом дорожном просвете и сцеплении с землей.
- Наличие рулевых вращающихся колес усложняет конструкцию робота и требует дополнительных двигателей и приводов.
- Отличный пример использования этого привода в робототехнике это настоящие беспилотные автомобили. Кроме того, этот привод используется в хобби-робототехнике, если робот построен на базе радиоуправляемой игрушечной машинке.

![../media/part_1_robot_drive_5_showcase_1.jpg](../media/part_1_robot_drive_5_showcase_1.jpg)

VolksBots

![../media/part_1_robot_drive_5_showcase_2.jpg](../media/part_1_robot_drive_5_showcase_2.jpg)

RB-CAR by Robotnik

## Привод с Omni колесами

Этот тип привода использует вместо обычных [Omni колеса](https://en.wikipedia.org/wiki/Omni_wheel). Omni колесо - это колесо с небольшими роликами по расположенными по окружности. Оси роликов перпендикулярны оси вращения колеса. С помощью этих колес, контролируя их скорость и направление вращения, вы можете заставить робота двигаться в любом направлении, другими словами, сделать движение робота голономным.

Обычно привод с Omni колесами шасси имеет 3 или 4 колеса.

Шасси с тремя колесами обеспечивает большую тягу, поскольку любая реактивная сила распределяется только через три точки, и робот хорошо сбалансирован даже на неровной местности. Omni колеса имеют высокую стоимость, поэтому шасси с тремя колесами дешевле, чем с четырьмя.

В различных конструкциях трехколесных шасси колеса могут устанавливаться под разными углами. Чаще всего шасси имеет колеса установленные под углом 120° друг к другу. Иногда два колеса параллельны друг другу, а третье колесо перпендикулярно первым двум. Последняя конструкция может быть более эффективной, потому что, когда колеса расположены под углом 120°, только одно колесо является ведущим, а два других по сути тормозят его, заставляя двигаться с меньшей скоростью.

Поскольку колеса на таком шасси не выровнены по осям, каждое колесо требуют индивидуального расчета скорости.

Пример определения векторов скоростей колес для трехколесного шасси:

![../media/ru_part_1_robot_drive_6_scheme_1.png](../media/ru_part_1_robot_drive_6_scheme_1.png)

Конструкция четырехколсеного шасси имеет четыре ведущих колеса, расположенные под углом 90° друг к другу. Эта конструкция более удобна для расчета скоростей колес, так как два колеса параллельны друг другу, а два других колеса перпендикулярны первым двум. Как и в трехколсеном шасси, КПД всех колес также не используется на 100%. Но в отличие от трехколсеного шасси, здесь есть два ведущих колеса и два свободных. Таким образом, с двумя ведущими колесами четырехколесное шасси движется быстрее, чем трехколесное. Четвертое колесо добавляет шасси еще одну точку опоры, и на неровной местности одно из колес робота может оказаться в воздухе.

Пример определения скорости вращения колес для четырехколесного шасси:

![../media/ru_part_1_robot_drive_6_scheme_2.png](../media/ru_part_1_robot_drive_6_scheme_2.png)

Особенности шасси:

- Поскольку колеса Omni представляют собой комбинацию из множества роликов, возникает сопротивление вращению, что приводит к более высокому трению и более значительным потерям энергии.
- Не все колеса являются ведущими, в каждый момент времени эффективно работает лишь одно или два Omni колеса.
- С помощью Omni колес достигается голономное движение робота.
- Работа Omni колес изначально строится на принципах проскальзывания. Невозможно поставить датчик вращения на каждый ролик Omni колеса, поэтому полученная одометрия не точная.
- Чаще всего роботы с таким шасси используются внутри помещений и ровных и гладких поверхностях.

![../media/part_1_robot_drive_6_showcase_1.jpg](../media/part_1_robot_drive_6_showcase_1.jpg)

3WD Omni wheel chassis by NEXUS robot

![../media/part_1_robot_drive_6_showcase_2.jpg](../media/part_1_robot_drive_6_showcase_2.jpg)

Soccer robots by RoboFEI Team

![../media/part_1_robot_drive_6_showcase_3.jpg](../media/part_1_robot_drive_6_showcase_3.jpg)

King Kong 4WD Omni Wheel chassis

## Привод с Mecanum колесами

Этот тип привода использует вместо обычных [Mecanum колеса](https://en.wikipedia.org/wiki/Mecanum_wheel). Колесо Mecanum - это разновидность Omni колеса. Mecanum колеса предназначены для грузоподьемных и проходимых роботов. Как и на Omni колесе, на колесе Mecanum ролики расположены по всей окружности обода, но здесь ролики имеют ось вращения под углом 45° к плоскости колеса и 45° к оси вращения колеса.

Поворот оси ролика позволяет использовать колеса Mecanum в приводах skid-steer. Эта комбинация использует преимущества skid-steer привода и привода с всенаправленными колесами. Колеса Mecanum заменяют обычные колеса для достижения голономного движения робота. Чаще всего этот тип привода имеет 4 Mecanum колеса, но иногда шасси может иметь и шесть колес.

При вращении Mecanum колеса к его вращению прилагается сила под углом 45°. Направление вращения определяет направление приложенной силы. Комбинации сил от всех колес позволяют роботу двигаться в разных направлениях.

Вгляните на схемы получения скоростей робота:

![../media/ru_part_1_robot_drive_7_scheme_1.png](../media/ru_part_1_robot_drive_7_scheme_1.png)

![../media/ru_part_1_robot_drive_7_scheme_2.png](../media/ru_part_1_robot_drive_7_scheme_2.png)

![../media/ru_part_1_robot_drive_7_scheme_3.png](../media/ru_part_1_robot_drive_7_scheme_3.png)

![../media/ru_part_1_robot_drive_7_scheme_4.png](../media/ru_part_1_robot_drive_7_scheme_4.png)

Особенности шасси:

- Привод с Mecanum колесами используется если робот должен обладать голономным движением и высокой грузоподьемностью.
- Чаще всего роботы с эти типом шасси это грузовые роботы, которые работают на ровной и гладкой поверхности. При использовании такого шасси на бездорожье, управление движением и получение качественной колесной одометрии с датчиков вращения может крайне труднено.

![../media/part_1_robot_drive_7_showcase_1.jpg](../media/part_1_robot_drive_7_showcase_1.jpg)

Kuka robot

![../media/part_1_robot_drive_7_showcase_2.jpg](../media/part_1_robot_drive_7_showcase_2.jpg)

Mobile Robot MPO-500 by Neobotix

![../media/part_1_robot_drive_7_showcase_3.jpg](../media/part_1_robot_drive_7_showcase_3.jpg)

SUMMIT-XL STEEL by Robotnik

## Скелетные роботы

Эти роботы используют конечности или ноги, чтобы двигаться. Движение таких роботов имитирует естественное движение живого организма.

Роботы на конечностях обладают голономным движением, также как и живые организмы, кинематику которых они повторяют. Например, робот-гексапод может идти в любом направлении, не меняя ориентацию своего тела.

Подобные роботы являюстя самыми мобильными но и самыми сложными в конструировании. Скелет конечности должен обладать множеством стенепенй свободы. Для этого требуется множество двигателей, приводов а так же сложные системы управления движеним. Из за большого количества приводов, скелетные роботы потребляют больше всего энергии. Для получение одометрии с шагающего шасси используется синтез данных с множества различных сенсоров (энкодеры приводов, IMU сенсоры, 3D лидары, 3D RGB камеры глубины, контактные датчики давления и.т.д) а так же машинное обучение.

![../media/part_1_robot_drive_8_showcase_1.jpg](../media/part_1_robot_drive_8_showcase_1.jpg)

Agility Robotics

![../media/part_1_robot_drive_8_showcase_2.jpg](../media/part_1_robot_drive_8_showcase_2.jpg)

Spot by Boston Dynamics

## Другие типы приводов

В действительности, в хобби-робототехнике, существует великое множество различных уникальных приводов движения. Все они используются крайне редко. Вот лишь некоторые из не упомянутых выше:

- Segway drive - дифференциальный двухколесный привод без пассивных колес. Равновесное состояние робота достигается с помощью датчиков и контроллеров.
- Forklift steering drive - разновидность рулевого привода Аккермана но с задней парой рулевых колес.
- Independent drive - это привод, в котором все колеса являются ведущими и рулевыми одновременно. Колес может быть четыре, шесть и более. Пример - марсоход.
- Articulated drive - разновидность рулевого привода Аккермана. Для того чтобы повернуть роботом в движении Articulated drive не поворачивает рулевые колеса а деформирует всю рулевую часть рамы или шасси.
- Ball drive - привод при котором, робот балансирует и перемещается на сфере.
- Ползучие червеобразные и змееподобные роботы движение которых основано на трении тела робота с поверхностью.

# Выбор шасси

Шасси робота напрямую зависит от выбранного типа привода. Мы выбрали двухколесный дифференциальный привод с пассивными колесами. Такой же привод используется в домашних роботах-пылесосах, а они как никто лучше справляются с задачей ориентации в помещении. Кроме того, это самое бюджетное шасси и самое простое в программировании.

При выборе типа привода мы руководствовались эффективностью колесной одометрии. Самая простая одометрия робота, которую вы можете получить - это датчики вращения, установленные на колесах. Обычно, такие датчики скорости представляют собой энкодеры, установленные на валах колес, валах двигателей или валах коробок передач.

Сперва мы попробовали танковое шасси [Rover 5](prod://rover-5-chassis) с резиновыми гусеницами. Установили дополнительные двигатели и энкодеы на колеса. Но, как оказалось, получить качественную одометрию только с помощью энкодеров довольно сложно. Когда робот вращается на месте и на высоких скоростях, гусеницы регулярно проскальзывают, и результирующая одометрия отличается от фактического положения робота. Поэтому мы решили начать с более простого шасси.

Вы можете сначала выбрать тип привода, который вам нравится, а затем самостоятельно построить шасси робота для этого типа. Или наоборот, купить готового шасси для робота и написать программу контроллер под него.

Чтобы самостоятельно собрать качественное робо-шасси, нужно обладать некоторыми навыками проектирования машин, разбираться в материалах, комплектующих и умело работать руками. Собранное своими руками шасси дает вам полное знание всех его деталей, узлов, ключевых моментов и слабых мест. Чем сложнее тип привода и шасси, тем больше вероятность, что вам придется собирать его самостоятельно.

С другой стороны, многие производители предоставляют высококачественные шасси для хобби робототехники. Если вы приобретете готовое шасси, то сможете сэкономить много времени на механической составляющей робота и потратить это время на электронную и программную часть.

**Это важно!** При покупке готового шасси выбирайте наиболее документированное, с маркировкой деталей, информацией о двигателях и полными чертежами основных деталей и компонентов в САПР.

## Шасси Turtle

В нашем роботе мы решили использовать двухколесный диффернциальный привод и робо-платформу [Turtle](prod://turtle-chassis) от DFRobot.

![../media/part_2_chassis_1.jpg](../media/part_2_chassis_1.jpg)

Это шасси для небольшого робота. Рама изготовлена из металла и состоит из 2 согнутых листовых металлических пластин. Обе пластины имеют перфорацию и вырезы для установки электроники. Шасси поставляется с двумя [Мотор-редукторами типа TT с двухсторонним валом (160 об / мин 6 В L-образной формы)](https://www.dfrobot.com/product-100.html), два пластиковых колеса диаметром 65 мм и [15-миллиметровое стальное шариковое колесо](https://www.dfrobot.com/product-225.html). Этот комплект шасси также содержит много других деталей и креплений, но они нам не нужны. Нам нужна только рама шасси.

![../media/part_2_chassis_2.jpg](../media/part_2_chassis_2.jpg)

Это не дорогое шасси, но и не самого лучшего качества:

- Данное шасси слабо документировано. Мы не нашли чертежи шасси в открытом доступе.
- Покрышки колес, которые идут в комплекте, пластиковые и бесполезные, потому что у них почти нет сцепления с землей. Мы сразу же заменили их резиновыми шинами от того же производителя - [Резиновое колесо для 4WD и 2WD (пара)](https://www.dfrobot.com/product-352.html).
- 1:120 Коробки передач моторов типа TT имеют пластиковые шестерни. Было бы лучше, если бы коробка передач была сделана из металла.
- Двигатели постоянного тока работают без обвязки и генерируют значительное количество электромагнитных наводок. На полной скорости эти двигатели существенно влияют на работу близлежащих аналоговых и цифровых электронных устройств.

Подводя итог, можно сказать, что это шасси не предел мечтаний, но оно доступно и популярно в хобби-робототехнике. Выбирая не дорогое шасси, будьте готовы приобрести важные детали и комплектующие или изготовить их самостоятельно.

## Энкодеры

Для колесной одометрии нам понадобятся датчики угла поворота или [энкодеры](https://en.wikipedia.org/wiki/Rotary_encoder). Часто готовые шасси уже имеют энкодеры, но эта платформа поставляется без них. По типу отдаваемых данных энкодеры могут быть [абсолютными](https://en.wikipedia.org/wiki/Rotary_encoder#Absolute_encoder) или [инкрементный](https://en.wikipedia.org/wiki/Incremental_encoder).

Абсолютный энкодер выдает сигнал, который однозначно соответствует углу поворота вала. Энкодеры этого типа не требуют привязки системы отсчета к какому-либо нулевому положению.

Инкрементный энкодер генерирует импульсы на выходе. Контроллер подсчитывает количество импульсов с помощью счетчика и определяет текущее положение вала. Сразу после включения контроллера положение вала неизвестно. Существует специальная нулевая отметка, через которую вал должен пройти после включения. Эта метка используется для привязки системы отсчета к нулевой позиции. Основным недостатком энкодеров такого типа является невозможность определить пропуск импульса, вызванный какой-либо причиной. Пропуски импульсов накапливают погрешность в угле поворота вала до тех пор, пока не будет пройдена нулевая отметка. Инкрементный кодер может быть без нулевой отметки. В этом случае отсчет импульсов, полученный в начале накопления, является началом системы отсчета.

По типу действия энкодеры могут быть оптическими, магнитными и механическими. Оптический энкодер использует свет, падающий на фотодиод через щели в металлическом или стеклянном диске, установленном на вращающемся валу. Механический энкодер также имеет вращающийся диск, но здесь угол считывают механические переключатели или контакты. Магнитные энкодеры имеют магнит, установленный на вращающемся валу. Эти энкодеры используют датчики Холла для считывания вращения вала с магнитом.

В основном в хобби-робототехнике используются оптические и магнитные инкрементные энкодеры или магнитные абсолютные энкодеры. Не имеет значения, какой тип энкодера использовать. При выборе энкодера основными параметрами являются количество каналов передачи данных, количество импульсов на оборот (PPR) и максимально допустимая скорость вращения вала.

Наиболее популярны квадратурные энкодеры с двумя каналами А и В. Редко у энкодеров хобби есть канал с нулевой отметкой - Z. Чем выше значение PPR, тем меньше угол поворота вала, который может зафиксировать датчик. Чем точнее энкодер, тем точнее одометрия робота, поэтому не пренебрегайте высококачественными энкодерами и не используйте энкодеры с низким значением PPR. Максимальная скорость вращения может быть любой, так как большинство энкодеров способно работать на очень высоких скоростях. Скорее всего, скорость вращения, которую вы будете измернять, будет в несколько раз меньше максимальной. Даже если вы планируете использовать высокоскоростные BLDC двигатели с высоким значением kv, то существуют энкодеры работающие с максимальными скоростями 28000 об/мин, 60000 об/мин или даже больше.

Если вы используете двигатель с коробкой передач, установите поворотный энкодер на вал двигателя, а не на вал колеса или коробки передач. Это важно. Эта настройка уменьшает минимальный читаемый угол поворота колеса и делает вашу одометрию более точной. Энкодеры могут устанавливаться и на оси передач и редукторов но обычно это делается в приводах скелетных роботов.

Мы обзавелись двумя такими двигателями с энкодерами - [Мотор-редуктор TT с энкодером (6V 160RPM 120:1 L Shape)](https://www.dfrobot.com/product-1458.html)

![../media/part_2_chassis_3.jpg](../media/part_2_chassis_3.jpg)

Почему мы выбрали именно эти моторы?

- Во-первых, их конструкция специально разработана для нашего Turtle шасси, и нам не придется придумывать крепление.
- Во-вторых, производитель исправил существенные недостатки, заменил пластиковые шестерни металлическими и добавил схему двигателя обвязку.
- Эта сборка имеет квадратурный магнитный энкодер с разрешением 16 PPR. Энкодер установлен на валу двигателя. Передаточное отношение 120:1 дает полное разрешение в 1920 импульсов на оборот колеса с минимальным измеряемым шагом в 0°11'15". Для поставленной нам задачи такой точности более чем достаточно.

Заменив моторы и убрав все лишнее, мы получил вот такое шасси:

ФОТО! ШАССИ ИРЛ В СБОРЕ.

# ROS

Мы разобрались с шасси. Давайте начнем разбираться в программном обеспечении. Для настоящих роботов классические программы микроконтроллеров нам не подходят. Вместо этого мы используем ROS.

[ROS(Robot Operation System)](https://www.ros.org) - это [операционная система](https://en.wikipedia.org/wiki/Operating_system) для роботов. ROS обеспечивает весь необходимый функционал для распределенной работы всех узлов робота. На самом деле ROS-это библиотека, надстройка поверх компьютерной операционной системы. ROS предоставляет стандартные услуги операционной системы, такие как аппаратная абстракция, низкоуровневое управление устройствами, реализация часто используемых функций, передача сообщений между процессами и управление пакетами.

ROS имеет графовую архитектуру, где обработка данных происходит в узлах - нодах (`nodes`), которые могут принимать и передавать сообщения между собой. ROS состоит из двух частей. Первая, это ядро - `roscore`. Ядро отвечает за работу системы и взаимодействие всех пакетов. Вторая часть - это пользовательские пакеты (`packages`) или наборы этих пакетов, организованных в стек.

Пакетов очень и очень много. Поскольку ROS-это проект с открытым исходным кодом, благодаря сообществу уже написало большинство пакетов, реализующих стандартные функции роботов.

Вот почему мы используем ROS. Из-за наличия готовых пакетов. Тем не менее, некоторые ноды нам придется написать самостоятельно, например низкоуровневые драйверы, но большая часть программного обеспечения уже сделана. Нам лишь нужно только собрать все это вместе.

Сам ROS и большинство его пакетов очень хорошо документированы. Вы можете найти ответы практически на любые вопросы в [ROS wiki](http://wiki.ros.org). Для ознакомления с разработкой под ROS настоятельно рекомендуем вам ознакомиться с ROS wiki.

ROS содержит множество пакетов для создания виртуального робота и моделирования его поведения, например стек [`gazebo_ros_pkgs`](http://wiki.ros.org/gazebo_ros_pkgs).

Изначально ROS предназначен для постройки сложных роботов, которые могут стоить тысячи долларов. Поэтому, прежде чем тратить финансы на какие - либо реальные дорогостоящие физические детали и узлы робота, ROS предлагает - сначала смоделировать робота в виртуальной среде и только потом реализовать его в реальном мире.

Мы сделаем все наоборот. Мы сделаем робота из дешевых деталей, которые у нас уже есть. Не будем использовать симуляцию, но настроим ROS для моего конкретного робота.

Чтобы использовать программное обеспечение ROS эффективно и для мониторинга, лучше установить его на две разные машины. Первая машина с ROS - это ваш настольный компьютер под управлением ОС Linux. Вторая машина - это бортовой компьютер, установленный на роботе, также работающем под управлением Linux. Позже мы свяжем эти две машины, и ROS будет работать в сети.

Предположим, что у вас уже есть настольный компьютер. Теперь вам нужно рзобраться с бортовым.

# Бортовой компьютер

## Выбор железа

Итак, робот работает на ROS, ROS работает на Linux. Давайте выберем для робота бортовой компьютер работающий на OS Linux.

Большие мобильные роботы способные нести большую нагрузку имеют на борту большие и мощные компьютеры. Если не стоит вопрос в размере боротвого компьютера то чаше всего на робота устанавливают мощный бортовой ноутбук. Наш робот маленький. На нем нет места для кучи оборудования и нечем это оборудование питать. Поэтому мы и используем [одноплатный компьютер](https://en.wikipedia.org/wiki/Single-board_computer). Сегодня существует множество одноплатных компьютеров. Самые популярные это:

- [Raspberry Pi Zero, 3, 4](https://www.raspberrypi.org) - это самые популярные платы. Изначально Raspberry Pi предназначен для обучения программированию и Linux. Эти платы самые дешевые. Семейство Raspberry Pi имеет множество реплик и копий платы оригинала дополненного различными периферийными интерфейсами и устройствами для любой задачи - Orange Pi, Rock Pi, Banana Pi.
- [NVIDIA Jetson Nano Developer Kit](https://www.nvidia.com/ru-ru/autonomous-machines/embedded-systems/jetson-nano/) - это самая многофункциональная плата. Она может быть использована для настольного ПК, но изначально предназначена для разработки мобильного искусственного интеллекта и машинного обучения. Эта плата использует мощный графический процессор из множдества ядер NVIDIA для вычислений.
- [Coral Dev Board](https://coral.ai/products/dev-board/) - это лучшая плата машинного обучения с использованием фреймворка Tensorflow. Плата специально разработана для работы с нейронной сетью TensorFlow Lite для микроконтроллеров.
- [ODYSSEY X86J4105800](https://www.seeedstudio.com/ODYSSEY-X86J4105800-p-4445.html) - самый большой и мощный одноплатник. Он способная работать под полноценной Windows 10 и имеет все функции настольного ПК.
- [Rock Pi N10](https://wiki.radxa.com/RockpiN10) - лучшая плата для машинного обучения. Эта плата имеет вычислительную мощность до 3,0 Терафлопс.

Вы можете выбрать любой одноплатник для робота. Тщательно выясните особенности каждой конкретной платы и определите ту, которая подходит вам лучше всего. Мы не планируюем заниматься машинным обучением или выполнять массивные вычисления, а это означает, что почти любой негабаритный одноплатник подходит для нашего робота. Мы выбрали [Raspberry Pi 4 Model B на 4 ГБ](prod://raspberry-pi-4-model-b-4-gb).

![../media/part_3_mcu_1.jpg](../media/part_3_mcu_1.jpg)

## Выбор и установка дистрибутива Linux

Прежде чем выбрать ОС для установки, вам нужно выбрать, какую версию ROS использовать. ROS [выпускает дистрибутивы](http://wiki.ros.org/Distributions) для различных операционных систем и архитектур - Ubuntu, Debian, Windows, других ОС Linux. Глобальные обновления ROS основаны на глобальных обновлениях ОС Ubuntu. Вскоре после выходна новой версии Ubuntu появляется и новая версия ROS. Предыдущие версии ROS продолжают поддерживаться до тех пор, пока поддерживается дистрибутивы Ubuntu, для которого они были созданы ([EOL](https://en.wikipedia.org/wiki/End-of-life_(продукт))). На момент написания этого руководства нам доступны два поддерживаемых дистрибутива ROS:

- [ROS Melodic Morenia](http://wiki.ros.org/melodic) нацеленная на [Ubuntu 18.04 (Bionic)](https://releases.ubuntu.com/bionic/). Поддерживает Ubuntu 17.10 (Artful). Дата релиза - 23 мая 2018. Дата конца поддержки - май 2023 (Bionic).
- [ROS Noetic Ninjemys](http://wiki.ros.org/noetic) нацеленная на [Ubuntu 20.04 (Focal)](https://releases.ubuntu.com/focal/). Дата релиза - 23 мая 2020. Дата конца поддержки - май 2025 (Focal).

Официальная документация [рекомендует](https://www.ros.org/install/) установку последней версии ROS - Noetic для последней версии Ubuntu ОС - Focal. ROS живет благодаря сообществу. Если ядро обновляется всегда вовремя то обноваление и поддержка различных пакетов может запаздывать. Обратите внимание, что некоторые интересные пакеты все еще не обновлены для новой версии Noetic, и вам, возможно, придется собирать их вручную.

Перейдем в раздел установки ROS Noetic и взглянем, какие OS и какие [архитектуры](https://en.wikipedia.org/wiki/Comparison_of_instruction_set_architectures) мы можем использовать:

- Ubuntu Focal на `amd64`, `armhf`, `arm64`.
- Debian Buster на `amd64`, `arm64`.
- Windows 10 на `amd64`.
- Не гарантировано, любой дистрибутив Linux на `amd64`, `i686`, `arm`, `armv6h`, `armv7h`, `aarch64`.

Raspberry Pi 4 B имеет набор инструкций ARMv8-A и поддерживает 32-разрядные и 64-разрядные вычисления. Обычно пользователи устанавливают 32-разрядную ОС на Raspberry. Однако у нашей малины 4 ГБ оперативной памяти, (и, кстати, может быть и 8 ГБ). С таким объемом оперативной памяти вы можете попробовать 64-разрядную ОС. С определенными задачами 64-разряжная версия ОС будет справляться быстрее.

Для ROS Noetic мы устанавливаем на одноплатник Ubuntu server 20.04.1 arm64. Для хранения ОС вам понадобится флэш-накопитель microSD. Чем больше емкость карты, тем лучше. Мы использовали карточку на 16 ГБ.

- Скачайте образ ОС. Перейдите на официальный сайт [Ubuntu](https://ubuntu.com). Затем перейдите в раздел **Downloads → Ubuntu for IOT → [Raspberry Pi 2, 3 or 4](https://ubuntu.com/download/raspberry-pi)**. Загрузите образ ОС [ubuntu-20.04.1-preinstalled-server-arm64+raspi.img.xz](https://ubuntu.com/download/raspberry-pi/thank-you?version=20.04.1&architecture=server-arm64+raspi)
- Установите программу для создания загрузочных флэш-дисков. Мы используем официальную программу от Raspberry - Raspberry Pi Imager. Перейдите на официальный сайт [Raspberry website](http://www.raspberrypi.org). Затем перейдите в раздел **Downloads → Raspberry Pi Imager**. Загрузите и установите [Raspberry Pi Imager](https://downloads.raspberrypi.org/imager/imager_1.4_amd64.deb) для вашей ОС.
- Запустите Raspberry Pi Imager. Вставьте и отформатируйте SD-карту. Затем войдите в меню **Operating system** menu and select **Use custom**.

![../media/part_4_linux_install_1.png](../media/part_4_linux_install_1.png)

- Укажите путь к скаченному образу Ubuntu, затем путь к вашей флеш карте и нажмите кнопку **Write**.

![../media/part_4_linux_install_2.png](../media/part_4_linux_install_2.png)

- Когда запись ОС завершена вставьте microSD флешку в Raspberry Pi. Подключите любую клавиатуру и мышь к USB-портам. Подключите любой дисплей или монитор с помощью кабеля micro-HDMI. Все это нам нужно для установки программного обеспечения и отладки программ в первый раз. Позже мы не будем использовать мышь, клавиатуру или дисплей, так как будем работать с Raspberry Pi по сети с помощью SSH.
- Включите Raspberry Pi. Производитель одноплатника рекомендует использовать источник питания 3А или более. Когда мы установим Raspberry Pi на робота, мы обеспечим плату достаточным напряжением и током, но в первый раз мы можем запитать плату от любого источника питания USB на 2 или 2,5 А через кабель USB Type-C.

## Первый запуск

Turn on the Raspberry and ensure that Linux works. At the first Ubuntu boot, the login is `ubuntu`, and the password is `ubuntu`. When you login the first time, the OS asks you to change the standard password. Set a new one. Note, the password cannot be a palindrome; this is one of the standard Ubuntu server settings.

```bash
Ubuntu 20.04.1 LTS ubnutu tty1

ubuntu login: ubuntu
Password:
You are requested to change your password immediately (root enforced)
Changing password for ubuntu.
(current) UNIX password:
Enter new UNIX password:
Retype new UNIX password:
Welcome to Ubuntu 20.04.1 LTS (GNU/Linux 5.4.0-1015-raspi aarch64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Thu Aug 6 23:01:23 UTC 2020

  System load:  0.08                Swap usage:  0%          Users logged in: 0
  Usage of /:   10.5% of 13.89GB    Temperature: 46.7 C 
  Memory usage: 5%                  Processes:   117

0 packages can be updated.
0 updates are security updates.

The programs included with the Ubuntu system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by
applicable law.

To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.

ubuntu@ubuntu:~$
```

The `root` password is not set in Ubuntu, and the root login is disabled by default. Enable the root account and set a password for it. Then switch to `root`:

```bash
sudo passwd root
Enter new UNIX password:
Retype new UNIX passord:
passwd: password updated successfully
```

```bash
su root
Password:
```

At desire you can rename the standard hostname with a more attractive one, for example, `robot`. Edit the `/etc/hostname` file and replace `ubuntu` with `robot`:

```bash
nano /etc/hostname
```

Then reboot and login under `root` again:

```bash
reboot now
```

## Wi-Fi and Desktop Setup

Now we need to connect to the Internet via Raspberry Wi-Fi. It is assumed that you have a Wi-Fi hotspot. The first step is to identify the name of your wireless network interface. The wireless network interface name would be something like `wlan0`:

```bash
ls /sys/class/net/
eth0 l0 wlan0
```

Next, navigate to the `/etc/netplan` directory and locate the appropriate Netplan configuration files. The configuration file might have a name like `50-cloud-init.yaml`:

```bash
ls /etc/netplan/
50-cloud-init.yaml
```

Edit the Netplan configuration file:

```bash
nano /etc/netplan/50-cloud-init.yaml
```

The entire configuration file should look similar to the one below. Please make sure that all blocks are aligned, as it showed. To align, use spaces instead of tabs. Replace the `SSID` and `PASSWORD` strings with the ID name and password of your Wi-Fi network.

```bash
# This file is generated from information provided by the datasource.  Changes
# to it will not persist across an instance reboot.  To disable cloud-init's
# network configuration capabilities, write a file
# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:
# network: {config: disabled}
network:
    ethernets:
        eth0:
            dhcp4: true
            optional: true
    version: 2
    wifis:
        wlan0:
            optional: true
            access-points:
                "SSID":
                    password: "PASSWORD"
            dhcp4: true
```

Start the service, reboot, and re-login:

```bash
systemctl start wpa_supplicant
reboot now
```

Apply the Netplan changes and connect to your wireless interface:

```bash
sudo netplan generate
sudo netplan apply
ip addr
```

Reboot and relogin.

Now, Raspberry is online and you can ping your Wi-Fi network gateway:

```bash
ping 192.168.1.1
```

The next step is to install a GUI for convenience work. Update the list of packages from the repository, upgrade them, and install any graphical shell you like. I prefer [XFce](https://en.wikipedia.org/wiki/Xfce):

```bash
sudo apt-get update && apt-get upgrade
sudo apt-get install xubuntu-desktop
```

Installing the GUI may take some time. Reboot after installation and log in under `ubuntu`. 

# ROS Setup

As I said before, I need to install ROS on two machines. On the Raspberry Pi and the desktop computer. 

Why do I need two computers? Creating a robot is closely related to visualization, and it requires computing power. Visualization is slow on Raspberry, and it slows down the whole development. If I had a powerful computer at the robot, I could work on it from beginning to end exclusively, but this is extremely difficult with Raspberry Pi.

## Install ROS on Raspberry

Install ROS Noetic on Raspberry as recommended in the [installation guide for ROS Noetic](http://wiki.ros.org/noetic/Installation/Ubuntu). Open new terminal shell pressing *CTRL + ALT + T* and continue under `ubuntu` user. 

Setup Raspberry to accept software from [packages.ros.org](http://packages.ros.org/):

```bash
sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
```

Set up keys:

```bash
sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654
```

Update package list:

```bash
sudo apt-get update
```

Install the full ROS configuration `ros-noetic-desktop-full`:

```bash
sudo apt install ros-noetic-desktop-full
```

Setup ROS environment variables and make them automatically added to your bash session every time a new shell is launched:

```bash
echo "source /opt/ros/noetic/setup.bash" >> ~/.bashrc
source ~/.bashrc
```

Install `rosdep`. `rosdep` enables you to easily install system dependencies for source you want to compile and is required to run some core components in ROS:

```bash
sudo apt-get install python3-rosdep python3-rosinstall-generator python3-vcstool build-essential
```

Initialize `rosdep`:

```bash
sudo rosdep init
rosdep update
```

Now make sure that the ROS is working as expected. For example, open terminal and run the ROS core:

```bash
roscore
```

![../media/roscore.png](../media/roscore.png)

## Install ROS on Desktop Computer

Installing ROS on a desktop computer doesn't differ from installing ROS on a Raspberry. The installation still depends on the Linux OS installed on the desktop computer.

As a desktop, I use my laptop running under Ubuntu 18.04. So I installed ROS Melodic.

## Create ROS workspace

Before creating a workspace, I highly recommend you to read the [tutorials for ROS beginners](http://wiki.ros.org/ROS/Tutorials). It is excellent documentation. However, it looks tricky for the first time. Over time, when you get used to the ROS, official documentation will answer all your questions. Now, try to understand some basic ROS principles:

- What are ROS environment variables?
- What the ROS file system looks like, and what is the structure of the ROS package?
- What are ROS nodes, topics, services, messages, publishers, subscribers?

Let's create a new ROS workspace on the Raspberry. The ROS workspace is a place where you store all your robot software: packages with nodes, executables, configuration files, descriptions files, etc. In fact, a workspace is a folder in the Linux file system. I called my workspace `ros`. The packages with the source code must be in the `src` subdirectory.

```bash
mkdir -p ~/ros/src
cd ~/ros/
```

The workspace is currently empty but let's build it with the [catkin](http://wiki.ros.org/catkin). This is a convenient tool to compile the C++ or Python source code, create executables, link packages, and this tool is regularly used working with ROS.

```bash
catkin_make
```

Look in the workspace directory. Now there are `build` and `devel` folders. The `build` folder has executables and build files. The `devel` folder has several setup.*sh files that are used to overlay the ROS workspace on top of your Linux environment.

At the desktop ROS, create exactly the same workspace as at the Raspberry.

## ROS Netwok

TODO

## Development Process

In my opinion, it is faster to develop a project on a desktop machine and then clone and build it on the Raspberry Pi.

I will create packages and write code on a desktop computer. But I will run and check it either on Raspberry or on a desktop computer, depending on the package.

# Robot Description

It's time to give the robot a name. Its name is a kind of namespace when working with the software. I decided to name my robot - `abot`.

A human working with a robot can physically interact with it. You can touch a robot, glance at the parts it consists of, and measure its weight or dimensions. Robot software should also have full access to a robot at any given time. For this, the program needs a complete description of a real robot.

## URDF Format

ROS uses the URDF - [Unified Robot Description Format](http://wiki.ros.org/urdf) to describe robots. This format is a specialization of the [XML](https://en.wikipedia.org/wiki/XML) format.

With URDF, it is possible to describe each physical part of the robot. The better the robot's description, the more software functions you can use, for example, physics simulations. Robot parts: links, joints, sensors are organized in the form of a tree. The URDF description differs depending on the implementation, but there are some primary elements:

- The `<link>` describes the kinematic and dynamic properties of a rigid robot part with inertia. It can also include visual features and collision properties.
- The `<visual>` describes the visual properties of the link. This element specifies the geometric shape of the robot part object (box, cylinder, etc.) or 3D model for visualization purposes.
- The `<collision>` describes the simplified geometry of the robot part. It is used to specify hitboxes and areas used in physics calculations during simulations.
- The `<inertial>` describes the inertial properties of the robot part. It specifies the mass of a robot part, center of gravity, and the 3x3 rotational inertia matrix.
- The `<joint>` describes the connection of two links. This element specifies the joint's kinematics and dynamics, safety limits, physical damping, and friction parameters.
- The `<transmission>` describes the relationship between an actuator and a joint.

The description of a robot with many parts and joints can be cumbersome to read and take up a lot of lines. The solution is the [xacro macro language](http://wiki.ros.org/xacro). With `xacro`, you can create shorter and more readable XML files using macros that expand to larger XML expressions.

I use `urdf` and `xacro` to describe my `abot`. You can view examples of robot descriptions in the ROS [URDF tutorials](http://wiki.ros.org/urdf/Tutorials).

You can write the URDF description of your robot manually. Create a new empty file and describe element by element. It is a time-consuming process that requires attention because you can make a lot of mistakes. However, you can automate the URDF file creation process with special software that exports the 3D model to URDF. And to do this, you need a 3D CAD model of the robot.

## 3D CAD Robot Model

You can create the 3D model of the robot in any CAD system, but it is better to use solid-state modeling.

I use [SolidWorks](https://www.solidworks.com) 2017 and a desktop computer running Windows OS. I chose SolidWorks because It has an excellent URDF export plugin.

Try not to describe the whole robot at once, but add different parts to the model gradually. It helps you master the describing process. I started with the robot chassis. 

My entire chassis had to be detailed manually. That's why drawings from the manufacturer are so important. Here's what I got:

![../media/ABOT_1_1.png](../media/ABOT_1_1.png)

By now my model consists of four links:

- `abot_base`
- `abot_left_wheel`
- `abot_right_wheel`
- `abot_caster_wheel`

And three joints:

- `left_wheel_to_base`
- `right_wheel_to_base`
- `caster_wheel_to_base`

For a better export, perform several steps:

Add coordinate systems. Define all coordinate systems for all links. It is best to specify coordinate systems from the origin points of the model parts. It is better to use the part's symmetry center or center of gravity as the coordinate system origin.

ROS and URDF require right-handed coordinate systems ([Right-hand rule](https://en.wikipedia.org/wiki/Right-hand_rule)). Determine where is the front, back, and top of your robot. The X-axis should point forward, the Y-axis to the left, and the Z-axis up. By default, the standard Solidworks views and the coordinate system are rotated 90 degrees around the X and Z axes. You can place guide lines for the correct axis placements. 

Each link has its own coordinate system:

- `CS_BASE`
- `CS_RIGHT_WHEEL`
- `CS_LEFT_WHEEL`
- `CS_CASTER_WHEEL`

The `CS_BASE` coordinate system is conventionally located at the center of my robot. The `CS_LEFT_WHEEL` and `CS_RIGHT_WHEEL` are at the wheels' centers. The `CS_CASTER_WHEEL` is at the center of the Omni-directional wheel ball.

![../media/ABOT_2.png](../media/ABOT_2.png)

Add  rotation axes for movable joints. I have three movable joints - two wheel joints and one Omni-directional joint. An Omni-directional wheel does not need an axis. For the wheels, I placed the `AXIS_LEFT_WHEEL` and `AXIS_RIGHT_WHEEL`. 

![../media/ABOT_3.png](../media/ABOT_3.png)

If you plan to use the robot in a simulation, you need to set the materials for all model parts. You can choose materials approximately from the standard SolidWorks materials library. Exporter uses parts materials to define the inertial parameters of rigid body links - link mass, link inertia matrix, link center of gravity.

## CAD URDF Export

To export the model, install a special plugin [`solidworks_urdf_exporter`](https://github.com/ros/solidworks_urdf_exporter). The installation steps are well described in the [documentation](http://wiki.ros.org/sw_urdf_exporter). 

After installation, enable this plugin in SolidWorks. For this, go to the *Settings →  Add-Ins* menu and check the box next to the `SW2URDF` plugin. To start exporting, go to *Tools - Export as UPDF*. The export menu opens. In this menu, you need to specify all the links used in the model.

At first, I specify the `abot_base` link. As a robot base, it is better to choose something massive, such as the robot's body frame.

Then, I define three child links for the `abot_base` and mention the `CS_BASE` coordinate system as a reference. For the link's rigid bodies, I select all parts of the 3D model except the side wheels and the Omni-directional wheel ball. When exporting, these parts are converted to STL meshes for visualization.

![../media/1-1-1-1.png](../media/1-1-1-1.png)

The next step is to describe the side wheel links. These links are descendants of `abot_base`. I set the `abot_left_wheel` and `abot_right_wheel` names of the joints. As the coordinate systems, I select the corresponding `CS_LEFT_WHEEL` and `CS_RIGHT_WHEEL`. The axes of rotation of the wheels are `AXIS_LEFT_WHEEL` and `AXIS_RIGHT_WHEEL`. As the visual component, I choose the wheel parts of the 3D model. For the standard wheel, the joint type is `continuous`.

![../media/2-1-1-1.png](../media/2-1-1-1.png)

I add the final link `abot_caster_wheel` and the joint `caster_wheel_to_base` for the Omni-directional wheel. Here the joint type should be `fixed`, and the coordinate system is `CS_CASTER_WHEEL`.

![../media/3-1-1-1.png](../media/3-1-1-1.png)

When you set all links and joints, push the *Preview and Export.. button*. Сheck the joints parameters and push *Next*.

![../media/4-1.png](../media/4-1.png)

Сheck the links parameters.

![../media/5-1.png](../media/5-1.png)

Note that if you specify the parts' material, the program calculates the mass of your links and their inertia matrices. 

Complete the export by pressing on *Export URDF and Meshes..* button. Specify the name of the folder to export. I named my `abot`. The exporter creates a ready-made ROS package with many files that you don't need. You need *. stl 3D files from the `meshes` folder and the *. urdf file from the `urdf` folder. Put these files aside for a while.

## Robot_description Package

Let's go to our ROS project and to the workspace at the desktop computer, and create our first package to describe the robot. Conventionally, this package is called `robot_description`. To avoid confusion with the naming, I call it `abot_description`. In the `ros/src` workspace type:

```bash
catkin_create_pkg abot_description tf rviz urdf xacro
```

With this command, you can create a blank ROS package, namely files `CMakelists.txt` and `package.xml`. Dependency packages are specified after the package name. For the `abot_description` package, I set the `tf`, `urdf`, `xacro`, and `rviz` dependency packages. 

For each ROS package, specify the necessary dependencies. Don't forget to edit `CMakelists.txt` and `package.xml` when adding new features. Read the [tutorial article](http://wiki.ros.org/ROS/Tutorials/CreatingPackage).

Create 4 folders in the new package: `urdf`, `meshes`, `rviz`, and `launch`.

```bash
mkdir abot_description/urdf abot_description/meshes abot_description/rviz abot_description/launch
```

In the `abot_description/meshes` folder, you need to put the 3D *.STL files generated by SolidWorks exporter. These files are located at `abot/meshes`. In the `abot_description/urdf` folder, place the `abot.urdf` file from the exported `abot/urdf` folder.

## Prepare the URDF with Xacro

The exporter generates an URDF description in one large file. This is not always convenient. Open the `abot.urdf` file and look at what the description of the robot looks like. 

Over time, I will continuously expand the description, so for convenience, let's split the `abot.urdf` file into several parts using Xacro macros and fix some generated errors.

I decided to split the description into several parts:

- `abot.xacro` - basic information about the robot and parameters.
- `abot_left_wheel.xacro` - left wheel link and joints.
- `abot_right_wheel.xacro` - right wheel link and joints.
- `abot_caster_wheel.xacro` - Omni-directional wheel link and joint.
- `abot_materials.xacro` - robot colors for visualization.

Let's start with a simple one: create colors for visualization. Create the file `abot_matherials.xacro` file in the `urdf` folder and fill it with some colors:

```xml
<?xml version="1.0"?>
<robot
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<material name="Green">
		<color rgba="0.0 1.0 0.0 1.0"/>
	</material>
	<material name="Blue">
		<color rgba="0.0 0.0 1.0 1.0"/>
	</material>
	<material name="Red">
		<color rgba="1.0 0.0 0.0 1.0"/>
	</material>
	<material name="White">
		<color rgba="1.0 1.0 1.0 1.0"/>
	</material>
	<material name="Yellow">
		<color rgba="1.0 1.0 0.0 1.0"/>
	</material>
</robot>
```

Now create `abot.xacro` and fill it with exported data. 

Fix the correct path to meshes - from `package://abot/meshes/base_link.STL` to `package://abot_description/meshes/base_link.STL`. 

Include the file with new materials and replace the exported materials with new ones. Let the `abot_base` be `White`.

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- Matherials -->
	<xacro:include filename="$(find abot_description)/urdf/abot_matherials.xacro" />
	<!-- abot_base -->
	<link name="abot_base">
	  <inertial>
			<origin xyz="-0.02452 1.4288E-14 0.021229" rpy="0 0 0" />
			<mass value="0.26675" />
			<inertia ixx="0.00032378" ixy="-1.1141E-12" ixz="-9.1302E-06" iyy="0.00030073" iyz="-3.3253E-10" izz="0.000561" />
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/base_link.STL" />
			</geometry>
			<material name="White" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/base_link.STL" />
			</geometry>
		</collision>
	</link>
</robot>
```

An essential detail. Conventionally, the URDF description for ROS must have a `base_link`. This link serves as a starting point for the robot description tree. You can add this link to the tree with any simple geometry, for example, a 1mm radius sphere. I add the `base_link` and attach it to the `abot_base` with a `fixed` joint. Add the following lines the to `about.xacro` file:

```xml
<!-- base_link -->
<link name="base_link">
	<visual>
		<origin xyz="0 0 0" rpy="0 0 0" />
		<geometry>
			<sphere radius="0.001" />
		</geometry>
	</visual>
</link>
<joint name="base_link_to_abot_base" type="fixed">
	<origin xyz="0 0 0" rpy="0 0 0" />
	<parent link="base_link" />
	<child link="abot_base" />
</joint>
```

Fill files for the right wheel (`abot_right_wheel.xacro`), for the left wheel (`abot_left_wheel.xacro`), and the caster wheel (`abot_caster_wheel.xacro`).  Edit the exported data as well as with `abot.xacro`. Let all the wheels be `Green`. 

Left wheel:

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- left_wheel -->
	<link name="abot_left_wheel">
		<inertial>
			<origin xyz="1.4324E-10 0.00056576 4.9274E-11" rpy="0 0 0" />
			<mass value="0.050464" />
			<inertia ixx="2.0701E-05" ixy="-1.8954E-14" ixz="-1.2393E-15" iyy="3.5827E-05" iyz="-1.8375E-14" izz="2.0701E-05" />
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_left_wheel.STL" />
			</geometry>
			<material name="Green" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_left_wheel.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="left_wheel_to_base" type="continuous">
		<origin xyz="0 0.068 0.0145" rpy="0 0 0" />
		<parent link="abot_base" />
		<child link="abot_left_wheel" />
		<axis xyz="0 1 0" />
	</joint>
</robot>
```

Right wheel:

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- right_wheel -->
	<link name="abot_right_wheel">
		<inertial>
			<origin xyz="1.9255E-10 -0.00056576 1.0414E-10" rpy="0 0 0" />
			<mass value="0.050464" />
			<inertia ixx="2.0701E-05" ixy="3.8089E-14" ixz="-1.3584E-15" iyy="3.5827E-05" iyz="2.1838E-15" izz="2.0701E-05" />
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_right_wheel.STL" />
			</geometry>
			<material name="Green" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_right_wheel.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="right_wheel_to_base" type="continuous">
		<origin xyz="0 -0.068 0.0145" rpy="0 0 0" />
		<parent link="abot_base" />
		<child link="abot_right_wheel" />
		<axis xyz="0 1 0" />
	</joint>
</robot>
```

Caster wheel:

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- caster_wheel -->
	<link name="abot_caster_wheel">
		<inertial>
			<origin xyz="0 1.6073E-19 0" rpy="0 0 0" />
			<mass value="0.011207" />
			<inertia ixx="2.1965E-07" ixy="0" ixz="-1.9776E-56" iyy="2.1965E-07" iyz="0" izz="2.1965E-07" />
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_caster_wheel.STL" />
			</geometry>
			<material name="Green" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_caster_wheel.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="caster_wheel_to_base" type="fixed">
		<origin xyz="-0.078 0 -0.011" rpy="0 0 0" />
		<parent link="abot_base" />
		<child link="abot_caster_wheel" />
		<axis xyz="0 0 0" />
	</joint>
</robot>
```

Include the new wheel files at the end of the main file `abot.xacro`.

```xml
<!-- Wheels -->
<xacro:include filename="$(find abot_description)/urdf/abot_left_wheel.xacro" />
<xacro:include filename="$(find abot_description)/urdf/abot_right_wheel.xacro" />
<xacro:include filename="$(find abot_description)/urdf/abot_caster_wheel.xacro" />
```

## Visualize URDF Model

Let's visualize our robot in ROS on the desktop machine. For visualization, use the powerful `rviz` tool. You can read more about `rviz` in the [documentation](http://wiki.ros.org/rviz).

If you installed the full ROS version, you already have all ROS packages for visualization, but you should also install the additional package to manipulate joints. For my ROS Melodic on the desktop machine:

```bash
sudo apt-get install ros-melodic-joint-state-publisher-gui
```

Сreate a launch `display_model.launch` file in the `abot_description` package in the `launch` folder. 
This file runs the ROS packages required for visualization and also upload our URDF model to the parametric ROS server.  Add the following lines to `display_model.launch`:

```xml
<launch>
	<!-- Args -->
	<arg name="gui" default="true" />
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_display.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<!-- Params -->
	<param name="use_gui" value="$(arg gui)" />
	<!-- Robot Description from URDF -->
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="joint_state_publisher_gui" pkg="joint_state_publisher_gui" type="joint_state_publisher_gui" />
	<node name="robot_state_publisher" pkg="robot_state_publisher" type="robot_state_publisher" />
	<!-- Rviz -->
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

 Go to the ROS workspace and build it. Overlay the workspace and launch the `display_model.launch` file.

```bash
cd ~/ros
catkin_make
source devel/setup.bash
roslaunch abot_description display_model.launch
```

The `rviz` window appears.

![../media/R1.png](../media/R1.png)

In the *Displays →Global Options* menu, set the *Fixed Frame* to the `base_link`. Press *Add* and select the *RobotModel* and *TF* visualizations.

![../media/R2.png](../media/R2.png)

The 3D model we created and the `tf` element tree should appear.

![../media/P3.png](../media/P3.png)

It doesn't look very clear. By now rviz has standard settings. You can customize all the displays for yourself and save the settings file. For example, I save the rviz settings for displaying the model as the `abot_model.rviz` file in the `abot_description/rviz` folder and add the corresponding argument `<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_display.rviz" />` to the launcher file. 

![../media/P4.png](../media/P4.png)

It's much clearer this way. Turn off the model's visibility and check the tree of elements and the directions of the coordinate systems.

![../media/P5.png](../media/P5.png)

Using the `joint_state_publisher_gui` plugin in ROS, you can manually manage all the moving parts of your model. Spin the robot's wheels and make sure that all the axes are set correctly and in the right direction.

![../media/P6.png](../media/P6.png)

## Robot Footprint

If you may have noticed, the robot is at the (0, 0, 0) point on the *Grid* plane and in the *Global Frame*. In reality, the robot stands with its wheels and is not immured in the floor.

It is necessary to lift the robot above the floor and indicate its projection onto the floor - the footprint. According to the ROS convention, use the `base_footprint` link. You need to link `base_footprint` to `base_link` and specify the print's geometric dimensions and the robot's clearance. 

Let's expand the description of the `abot.xacro` file. Add the `clearance` parameter to the beginning of the file. This is the distance (in meters) from the floor to the `base_link` and `abot_base` links' origin points.

```xml
<xacro:property name="clearance" value="0.018" />
```

As a footprint, I indicate a blue cylinder 1mm high and 10cm radius.

```xml
<!-- base_footprint -->
<link name="base_footprint">
	<visual>
		<origin xyz="0 0 0" rpy="0 0 0" />
		<geometry>
			<cylinder length="0.001" radius="0.010" />
		</geometry>
		<material name="Blue" />
	</visual>
</link>
<joint name="base_footprint_to_base_link" type="fixed">
	<origin xyz="0 0 ${clearance}" rpy="0 0 0" />
	<parent link="base_footprint" />
	<child link="base_link" />
</joint>
```

Let's launch `rviz` again, but as *Fixed Frame* indicate `base_footprint`. Now our robot is on the ground with its wheels.

![../media/P7.png](../media/P7.png)

# Raspberry Pi Hat and Electronics Mount

In the next steps, I connect motors and sensors to the robot. Raspberry pie is an excellent choice in this regard since it has direct access to GPIO pins.

However, it is not always convenient to connect everything to the RPi board directly. It is better to use special shields and adapters. For my robot, I use the Troyka-Hat Raspberry Pi adapter by Amperka:

![../media/TROYKA_CAP_800.jpg](../media/TROYKA_CAP_800.jpg)

This Board easily fits on the raspberry Pi pin comb. Troyka-Hat also has an additional controller-expander for GPIO ports. This controller provides eight extra I/O pins with hardware support for 12-bit ADC and 16-bit PWM. It is handy, and I will take this advantage in the robot. Here is the Troyka-Hat pinout:

![../media/CAP_PINOUT_800.png](../media/CAP_PINOUT_800.png)

You can attach Electronic components to the robot's chassis any way you want, but I decided to do it properly.

Using the laser-cut, I made for Raspberry and other electronic components, the 3mm thickness plexiglass pad with many holes for fasteners. On this pad, I'm going to mount all electronic components.

ФОТО! ШАССИ С ПЕРВЫМ БЛИНОМ, МАЛИНОЙ + ХАТ

It is advisable to update the documentary with any changes in robot design. I add new parts to the 3D model of the robot. I also updated the robot's URDF description by changing the link's `abot_base` visual.

![../media/5.png](../media/5.png)

I also updated the robot's URDF description by changing the link's `abot_base` visual.

![../media/rivz_with_pi.jpg](../media/rivz_with_pi.jpg)

# Robot Drivers

Let's start writing drivers for our robot.

This driver package is in the `ros` workspace. Use driver package only on Raspberry ROS. I create a new package in the project and name it `abot_driver`. As dependency packages in `CMakelists.txt` and `package.xml` set the `[roscpp](http://wiki.ros.org/roscpp)` and `[std_msgs](http://wiki.ros.org/std_msgs)` packages. Create the `src` folder in the package. This is the place for the source files.

## WiringPi Library

To use Raspberry GPIO pins, you need a library. There are many libraries to manage GPIO; they differ in language and depth of controllers function usage. There are libraries for C, C#, Python, JavaScript, Perl, Java, and Ruby. You can view the [full list of existing libraries](https://docs.google.com/spreadsheets/d/1sFCJuPZ9k5GN0A6j7gHRckvbwIdnwzPH1sTCuPNFNRQ/edit#gid=0) that I found. I will use the [WiringPi](http://wiringpi.com/) library for C++ because I will also write ROS nodes in C++.

This library is elementary and famous, but it has not been supported for a long time because its [development has been stopped](http://wiringpi.com/wiringpi-deprecated/), so there are unrealized features and bugs. The latest official version of the library is [2.52 for the Raspberry Pi 4B](http://wiringpi.com/wiringpi-updated-to-2-52-for-the-raspberry-pi-4b/), and it is assembled for the armhf architecture.

There is a good fork of the library on Github - [https://github.com/WiringPi/WiringPi](https://github.com/WiringPi/WiringPi). I use this version and manually build it for my Linux:

```bash
git clone https://github.com/WiringPi/WiringPi.git
cd WiringPi
./build
```

Make sure that the library is installed correctly:

```bash
gpio -v
```

To view the assignment of Raspberry Pi 4B GPIO/Broadcom/WiringPi pins, use the command:

```bash
gpio readall
```

## Motor Driver

The first driver is for the chassis motors. 

### Wiring

Connect the motors to the Raspberry. You cant connect DC motors to the Raspberry Pi directly. You need a driver module board. My DC motors do not consume much current, and I can use a simple DC motor driver board.

I use a two-channel H-bridge shield from Amperka in the form of a Troyka module. This Module is designed for two DC motors with a current of up to 1,2A.

![../media/H_BRIDGE_800.jpg](../media/H_BRIDGE_800.jpg)

I also use a convenient Troyka adapter. With this adapter, it is easier to attach the Troyka module to the robot frame parts and wire it.

![../media/TROYKA_PAD_800.jpg](../media/TROYKA_PAD_800.jpg)

Two pins, D and E, control one motor channel. The E pin (Enable) awaits the PWM signal and is responsible for the motor's rotation speed. The D pin (Direction) uses a logical (HIGH or LOW) signal to set the rotation direction. In total, you need four pins to control two DC motors.

The Raspberry Pi 4B can generate a hardware PWM signal only on two channels `PWM0` and `PWM1`. These are the channels I use. Also, Raspberry can generate a software PWM on any of its pins, but it takes up almost all computing power. The `PWM0` channel can be assigned to the Broadcom pin `BCM 12` (WiringPi pin 26) or `BCM 18` (WiringPi pin 1). The `PWM1` channel can be assigned to the Broadcom pin `BCM 13` (WiringPi pin 23) or `BCM 19` (WiringPi pin 24). The direction H-bridge pins can be connected to any Raspberry pins.

I connected the left motor channel to WiringPi pins 7 and 1 and the right channel to pins 12 and 13:

![../media/1.png](../media/1.png)

The motors are powered by a voltage of 4,5V - 7,5V. The power should be applied to the P screw terminals of the Troyka H-bridge. I power the motors from a 2S 7,2V Lithium battery.

### DCMotor class

Let's write a С++ class to control the DC motor on a Raspberry through the H bridge. I create a C++ `dc_motor_wiring_pi.hpp` header file and place it in the `abot_driver/src` folder.

The motor can move `cw` (clockwise), move `ccw` (counterclockwise) or `stop`. The Raspberry PWM resolution is 10 bit (`1023`).

```cpp
#ifndef DC_MOTOR_WIRING_PI_HPP_
#define DC_MOTOR_WIRING_PI_HPP_

#include <ros/ros.h>
#include <wiringPi.h>

#define RPI_MAX_PWM_VALUE 1023

class DCMotorWiringPi {
public:
    DCMotorWiringPi(int8_t direction_pin, int8_t enable_pin);
    void cw(uint16_t val);
    void ccw(uint16_t val);
    void stop();
private:
    int8_t _direction_pin;
    int8_t _enable_pin;
    uint16_t protectOutput(uint16_t val);
};

DCMotorWiringPi::DCMotorWiringPi(int8_t direction_pin, int8_t enable_pin) {
    _direction_pin = direction_pin;
    _enable_pin = enable_pin;
    if (wiringPiSetupGpio() < 0) {
        ROS_ERROR("DCMotor wiringPi error: GPIO setup error");
        throw std::runtime_error("");
    }
    ROS_INFO("DCMotor wiringPi: GPIO setup");
    pinMode(_direction_pin, OUTPUT);
    pinMode(_enable_pin, PWM_OUTPUT);
    stop();
    ROS_INFO("DCMotor wiringPi: Motor setup");
}

void DCMotorWiringPi::stop() {
    pwmWrite(_enable_pin, 0);
    digitalWrite(_direction_pin, 0);
}

void DCMotorWiringPi::cw(uint16_t val) {
    pwmWrite(_enable_pin, protectOutput(val));
    digitalWrite(_direction_pin, 1);
}

void DCMotorWiringPi::ccw(uint16_t val) {
    pwmWrite(_enable_pin, protectOutput(val));
    digitalWrite(_direction_pin, 0);
}

uint16_t DCMotorWiringPi::protectOutput(uint16_t val) {
    return val > RPI_MAX_PWM_VALUE ? RPI_MAX_PWM_VALUE : val;
}

#endif // DC_MOTOR_WIRING_PI_HPP_
```

### Friction Test

Let's write a simple test for debugging the motors. We need this to ensure that the robot's motors are working and determine the minimum PWM signal to overcome the ground friction.

The fact is that only at a certain voltage on the motor, the wheel begins to rotate. If you specify that the robot wheel should rotate, for example, at an angular velocity of 0.5rad/s, it should rotate at this speed, and you should not wait for the PWM value to grow. 

Creating a new file `motors_friction_test.cpp` and place it in the `abot_driver/src/test` directory. To control the speed of motors, I use the topics `/left_motor` and `/right_motor` and values in the range from [-1,1], where 0 corresponds to the zero PWM, -1 and 1 to the maximum PWM.

```cpp
#include "../dc_motor_wiring_pi.hpp"
#include "std_msgs/Float32.h"

#define MOTOR_1_PIN_D 4     // Wiring pi 7 = BCM 4
#define MOTOR_1_PIN_E 18    // Wiring pi 1 = BCM 18
#define MOTOR_2_PIN_D 12    // Wiring pi 26 = BCM 12
#define MOTOR_2_PIN_E 13    // Wiring pi 23 = BCM 13

DCMotorWiringPi left_dc_motor(MOTOR_1_PIN_D, MOTOR_1_PIN_E);
DCMotorWiringPi right_dc_motor(MOTOR_2_PIN_D, MOTOR_2_PIN_E);

double mapSpeed(double angluar_wheel_speed, double max_angluar_wheel_speed, double min_pwm, double max_pwm) {
    return angluar_wheel_speed * (max_pwm - min_pwm) / (max_angluar_wheel_speed - 0) + min_pwm;
}

void leftMotorCallback(const std_msgs::Float32& msg) {
    double spd = msg.data;
    uint16_t pwm = mapSpeed(std::abs(spd), 1.0, 0.0, RPI_MAX_PWM_VALUE);
    ROS_INFO("LEFT MOTOR PWM: %d", pwm);
    if (spd > 0) {
        left_dc_motor.ccw(pwm);
    } else if (spd < 0) {
        left_dc_motor.cw(pwm);
    } else if (spd == 0) {
        left_dc_motor.stop();
    }
}

void rightMotorCallback(const std_msgs::Float32& msg) {
    double spd = msg.data;
    uint16_t pwm = mapSpeed(std::abs(spd), 1.0, 0.0, RPI_MAX_PWM_VALUE);
    ROS_INFO("RIGHT MOTOR PWM: %d", pwm);
    if (spd > 0) {
        right_dc_motor.cw(pwm);
    } else if (spd < 0) {
        right_dc_motor.ccw(pwm);
    } else if (spd == 0) {
        right_dc_motor.stop();
    }
}

int main(int argc, char **argv) {
    ros::init(argc, argv, "motors_friction_test");
    ros::NodeHandle node;
    ros::Subscriber left_motor_sub = node.subscribe("left_motor", 1, &leftMotorCallback);
    ros::Subscriber right_motor_sub = node.subscribe("right_motor", 1, &rightMotorCallback);
    ros::spin();
    return 0;
}
```

Edit the `CMakelists.txt` file to specify the compile flags to the Wiringpi library:

```makefile
add_executable(motors_friction_test src/test/motors_friction_test.cpp)
target_link_libraries(motors_friction_test ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

Build the workspace and launch ROS core:

```bash
cd ~/ros
catkin_make
```

The WiringPi reqires root permissions. In a new terminal run the test: 

```bash
sudo -s
cd ros
source devel/setup.bash
rosrun abot_driver motors_friction_test
```

![../media/motors_friction_test.png](../media/motors_friction_test.png)

Open a new terminal and check whether the necessary topics `/left_motor` and `/right_motor` have appeared.

```bash
rostopic list
```

![../media/rostopic_friction.png](../media/rostopic_friction.png)

To publish values to the topics manually, use the `rqt` ROS utility and the *Topics* → *MessagePublisher* `rqt` plugin.

![../media/rqt_friction_test.png](../media/rqt_friction_test.png)

Set the robot chassis on the ground. Gradually increase values in the topics `/left_motor` and `/right_motor` while observing the PWM values in the terminal with the running test. Determine at what PWM values the wheels overcomes the friction force and begins to rotate.

I got these values: 143 PWM for the left motor and 153 PWM for the right motor.

ВИДЕО! СПЛИТСКРИН, РОБОТ НА ПОЛУ + ПАБЛИШЕР, ПОСТЕПЕННО УВЕЛИЧИВАЕМ СКОРОСТЬ.

### Motors Node

Now we can write the final ROS node for motors - `dc_motors.cpp`. Put the `dc_motors.cpp` into the `abot_driver/src` folder in the workspace.

How does it work? The `dc_motors` node subscribe to two topics `/abot/left_wheel_velocity` and `/abot/right_wheel_velocity`. Through these topics, the node receives the `double` values of the angular velocities in rad/s with which the wheels should rotate. Then these angular velocities are mapped to PWM signals. 

For correct mapping, you need to set the minimum value of the PWM to overcome friction (`MOTOR_LEFT_PWM_THRESHOLD`, `MOTOR_RIGHT_PWM_THRESHOLD`), and the maximum value of each wheel's angular velocity in rad/s (`MAX_ANGLUAR_LEFT_WHEEL_SPEED`, `MAX_ANGLUAR_RIGHT_WHEEL_SPEED`). We will get the last values when we write a test for encoders.

```cpp
#include "dc_motor_wiring_pi.hpp"
#include "std_msgs/Float32.h"

#define MOTOR_1_PIN_D 4     // Wiring pi 7 = BCM 4
#define MOTOR_1_PIN_E 18    // Wiring pi 1 = BCM 18
#define MOTOR_2_PIN_D 12    // Wiring pi 26 = BCM 12
#define MOTOR_2_PIN_E 13    // Wiring pi 23 = BCM 13

#define MOTOR_LEFT_PWM_THRESHOLD 143
#define MOTOR_RIGHT_PWM_THRESHOLD 153

#define MAX_ANGLUAR_LEFT_WHEEL_SPEED 0.0
#define MAX_ANGLUAR_RIGHT_WHEEL_SPEED 0.0

DCMotorWiringPi left_dc_motor(MOTOR_1_PIN_D, MOTOR_1_PIN_E);
DCMotorWiringPi right_dc_motor(MOTOR_2_PIN_D, MOTOR_2_PIN_E);

double mapSpeed(double angluar_wheel_speed, double max_angluar_wheel_speed, double min_pwm, double max_pwm) {
    return angluar_wheel_speed * (max_pwm - min_pwm) / (max_angluar_wheel_speed - 0) + min_pwm;
}

void leftMotorCallback(const std_msgs::Float32& msg) {
    double motor_spd = msg.data;
    uint16_t motor_pwm = mapSpeed(std::abs(motor_spd), MAX_ANGLUAR_LEFT_WHEEL_SPEED, MOTOR_LEFT_PWM_THRESHOLD, RPI_MAX_PWM_VALUE);
    if (motor_spd > 0) {
        left_dc_motor.ccw(motor_pwm);
    } else if (motor_spd < 0) {
        left_dc_motor.cw(motor_pwm);
    } else if (motor_spd == 0) {
        left_dc_motor.stop();
    }      
}

void rightMotorCallback(const std_msgs::Float32& msg) {
    double motor_spd = msg.data;
    uint16_t motor_pwm = mapSpeed(std::abs(motor_spd), MAX_ANGLUAR_RIGHT_WHEEL_SPEED, MOTOR_RIGHT_PWM_THRESHOLD, RPI_MAX_PWM_VALUE);
    if (motor_spd > 0) {
        right_dc_motor.ccw(motor_pwm);
    } else if (motor_spd < 0) {
        right_dc_motor.cw(motor_pwm);
    } else if (motor_spd == 0) {
        right_dc_motor.stop();
    }
}

int main(int argc, char **argv) {
    ros::init(argc, argv, "dc_motors");
    ros::NodeHandle node;
    ros::Subscriber left_motor_sub = node.subscribe("abot/left_wheel_velocity", 1, &leftMotorCallback);
    ros::Subscriber right_motor_sub = node.subscribe("abot/right_wheel_velocity", 1, &rightMotorCallback);
    ros::spin();
    return 0;
}
```

Add the executable to the `CMakelists.txt` file in the `abot_driver` pakage:

```makefile
add_executable(dc_motors src/dc_motors.cpp)
target_link_libraries(dc_motors ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

## Encoder Driver

The second driver is for the motors encoders. 

### Wiring

The quadrature encoder has two channels, A and B, and communicates via two wires. The encoder generates simple logic signals on these two channels. If the motor shaft rotates quickly, it is better to use hardware interrupts to read signals. Raspberry allows interrupts on all pins, and you can connect the encoder to any unused pins.

I wired the left motor encoder to the Broadcom pins `BCM 17` (WiringPi pin 0) and `BCM 27` (WiringPi pin 2). Right side encoder to pins `BCM 24` (WiringPi pin 5) and `BCM 25` (WiringPi pin 6). 

Encoders are powered from 5V. 5V can be taken from Troyka Hat pads.

![../media/2.png](../media/2.png)

### Encoder class

Write a С++ class to decode a quadrature encoder on a Raspberry using interrupts. I create a C++ `encoder_wiring_pi.hpp` header file and place it in the `abot_driver/src` folder.

Using interrupts in WiringPi can be tricky. To use interrupts, I created two global functions `encoderISR1` and `encoderISR2`. The raw tick values are contained in the `long` variables `encoderPosition1` and `encoderPosition2`. I haven't written an overflow check yet. 

Set the PPR (Pulses per revolution) value of your encoder in the code. For my encoders the `PULSES_PER_REVOLUTION` value is `1920`.

```cpp
#ifndef ENCODER_WIRING_PI_HPP_
#define ENCODER_WIRING_PI_HPP_

#include <ros/ros.h>
#include <wiringPi.h>

#define ENCODER_1_PIN_A 17  // Wiring pi 0 = BCM 17
#define ENCODER_1_PIN_B 27  // Wiring pi 2 = BCM 27
#define ENCODER_2_PIN_A 24  // Wiring pi 5 = BCM 24
#define ENCODER_2_PIN_B 25  // Wiring pi 6 = BCM 25

#define PULSES_PER_REVOLUTION 1920

namespace EncoderWiringPiISR {

    volatile long encoderPosition1;
    volatile long encoderPosition2;
    volatile uint8_t encoderState1;
    volatile uint8_t encoderState2;

    void encoderISR(const int pinA, const int pinB, volatile long &encoderPosition, volatile uint8_t &encoderState) {
        uint8_t valA = digitalRead(pinA);
        uint8_t valB = digitalRead(pinB);
        uint8_t s = encoderState & 3;
        if (valA) s |= 4;
        if (valB) s |= 8; 
        encoderState = (s >> 2);
        switch (s) {
            case 1: case 7: case 8: case 14:
                encoderPosition++;
                return;
            case 2: case 4: case 11: case 13:
                encoderPosition--;
                return;
            case 3: case 12:
                encoderPosition += 2;
                return;
            case 6: case 9:
                encoderPosition -= 2;
                return;
        }
    }

    void encoderISR1(void) {
        encoderISR(ENCODER_1_PIN_A, ENCODER_1_PIN_B, encoderPosition1, encoderState1);
    }

    void encoderISR2(void) {
        encoderISR(ENCODER_2_PIN_A, ENCODER_2_PIN_B, encoderPosition2, encoderState2);
    }
}

class EncoderWiringPi {
public:
    EncoderWiringPi(const int &pinA, const int &pinB, void (*isrFunction)(void), volatile long* encoderPosition);
    double getAngle();
private:
    int _pinA;
    int _pinB;
    volatile long* _encoderPosition;
    double _initial_angle;
    double ticks2Angle(long position);
};

EncoderWiringPi::EncoderWiringPi(const int &pinA, const int &pinB, void (*isrFunction)(void), volatile long* encoderPosition) {
    _encoderPosition = encoderPosition;

    if (wiringPiSetupSys() < 0) {
        ROS_ERROR("Encoder wiringPi error: GPIO setup error");
        throw std::runtime_error("");
    }
    ROS_INFO("Encoder wiringPi: GPIO setup");

    _pinA = pinA;
    _pinB = pinB;
    pinMode(_pinA, INPUT);
    pinMode(_pinB, INPUT);
    pullUpDnControl(_pinA, PUD_UP);
    pullUpDnControl(_pinB, PUD_UP);

    if (wiringPiISR(_pinA, INT_EDGE_BOTH, isrFunction) < 0) {
        ROS_ERROR("Encoder wiringPi error: ISR pinA error");
        throw std::runtime_error("");
    }

    if (wiringPiISR(_pinB, INT_EDGE_BOTH, isrFunction) < 0) {
        ROS_ERROR("Encoder wiringPi error: ISR pinB error");
        throw std::runtime_error("");
    }

    _initial_angle = ticks2Angle(*_encoderPosition);
    ROS_INFO("Encoder wiringPi: ISR setup");
}

double EncoderWiringPi::getAngle() {
    double current_angle = ticks2Angle(*_encoderPosition);
    return current_angle - _initial_angle;
}

double EncoderWiringPi::ticks2Angle(long position) {
	return position * ((double)2 * M_PI / PULSES_PER_REVOLUTION / 2);
}

#endif // ENCODER_WIRING_PI_HPP_
```

### Encoders Node

Let's write a node for encoders - `encoders.cpp`. Put the `encoders.cpp` into the `abot_driver/src` folder in the workspace.

This node use current left and right wheel angles from encoders and publish them into topics `/abot/left_wheel_angle` and `/abot/right_wheel_angle`. Angle values are published to topics on timer `encoders_timer;`, 100 times per second `EncodersPair encoders_pair(0.01);`.

```cpp
#include "encoder_wiring_pi.hpp"
#include "std_msgs/Float32.h"

class EncodersPair {
public:
    EncodersPair(double update_rate);
private:
    ros::NodeHandle node;
    ros::Publisher left_wheel_angle_pub;
    ros::Publisher right_wheel_angle_pub;

    ros::Timer encoders_timer;

    std_msgs::Float32 left_wheel_angle_msg;
    std_msgs::Float32 right_wheel_angle_msg;

    EncoderWiringPi encoder_left;
    EncoderWiringPi encoder_right;

    double left_wheel_angle;
    double right_wheel_angle;

    void encodersCallback(const ros::TimerEvent& event);
};

EncodersPair::EncodersPair(double update_rate) :
    encoder_left(ENCODER_1_PIN_A, ENCODER_1_PIN_B, &EncoderWiringPiISR::encoderISR1, &EncoderWiringPiISR::encoderPosition1),
    encoder_right(ENCODER_2_PIN_A, ENCODER_2_PIN_B, &EncoderWiringPiISR::encoderISR2, &EncoderWiringPiISR::encoderPosition2) {
    left_wheel_angle_pub = node.advertise<std_msgs::Float32>("/abot/left_wheel_angle", 1);
    right_wheel_angle_pub = node.advertise<std_msgs::Float32>("/abot/right_wheel_angle", 1);
    encoders_timer = node.createTimer(ros::Duration(update_rate), &EncodersPair::encodersCallback, this);
}

void EncodersPair::encodersCallback(const ros::TimerEvent& event) {
    left_wheel_angle = -1 * encoder_left.getAngle();
    right_wheel_angle = 1 * encoder_right.getAngle();

    left_wheel_angle_msg.data = left_wheel_angle;
    right_wheel_angle_msg.data = right_wheel_angle;

    left_wheel_angle_pub.publish(left_wheel_angle_msg);
    right_wheel_angle_pub.publish(right_wheel_angle_msg);
}

int main(int argc, char** argv) {
    ros::init(argc, argv, "encoders");
    EncodersPair encoders_pair(0.01);
    ros::spin();
    return 0;
}
```

Add the executable to the `CMakelists.txt` file in the `abot_driver` pakage:

```makefile
add_executable(encoders src/encoders.cpp)
target_link_libraries(encoders ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

Build the new nodes:

```bash
cd ~/ros
catkin_make
```

Let's check that everything works. Run the core in a new terminal:

```bash
roscore
```

Run the `encoders` node in a new terminal under `root`:

```bash
cd ~/ros
sudo -s
source devel/setup.bash
rosrun abot_driver encoders
```

![../media/encoders.png](../media/encoders.png)

Launch the topic monitor, for example, for the right wheel. Manually rotate the robot wheel and watch for changes in the current angle. In a new terminal:

```bash
rostopic list
rostopic echo /abot/right_wheel_angle
```

I turned the wheel about 1 turn, which is `2*PI`:

![../media/rostopic_encoders.png](../media/rostopic_encoders.png)

ВИДЕО! СПЛИТ СКРИН 1 ОБОРОТ КОЛЕСА + ТЕРМИНАЛ.

### Encoders Velocity Test

Now, when you are sure that encoders work, you need to find out the maximum angular wheel speed at maximum PWM. I write another test - `encoders_velocity_test.cpp` and put it in the `abot_driver/src/test` folder. 

Speed is easy to measure - divide the distance traveled by time. I publish velocities in topics `/left_wheel_encoder_velocity` and `/right_wheel_encoder_velocity`.

```cpp
#include "../encoder_wiring_pi.hpp"
#include "std_msgs/Float32.h"
#include <chrono>

typedef boost::chrono::steady_clock time_source;

class EncodersPair {
public:
    EncodersPair(double update_rate);
private:
    ros::NodeHandle node;

    ros::Publisher left_wheel_velocity_pub;
    ros::Publisher right_wheel_velocity_pub;

    ros::Timer timer;

    std_msgs::Float32 left_wheel_velocity_msg;
    std_msgs::Float32 right_wheel_velocity_msg;

    EncoderWiringPi encoder_left;
    EncoderWiringPi encoder_right;

    double left_wheel_angle;
    double right_wheel_angle;
    double left_wheel_velocity;
    double right_wheel_velocity;
    double left_wheel_position;
    double right_wheel_position;

    time_source::time_point last_time;

    void encodersCallback(const ros::TimerEvent& event);
};

EncodersPair::EncodersPair(double update_rate) :
    encoder_left(ENCODER_1_PIN_A, ENCODER_1_PIN_B, &EncoderWiringPiISR::encoderISR1, &EncoderWiringPiISR::encoderPosition1),
    encoder_right(ENCODER_2_PIN_A, ENCODER_2_PIN_B, &EncoderWiringPiISR::encoderISR2, &EncoderWiringPiISR::encoderPosition2) {
    
    left_wheel_velocity_pub = node.advertise<std_msgs::Float32>("/left_wheel_encoder_velocity", 1);
    right_wheel_velocity_pub = node.advertise<std_msgs::Float32>("/right_wheel_encoder_velocity", 1);

    timer = node.createTimer(ros::Duration(update_rate), &EncodersPair::encodersCallback, this);
    last_time = time_source::now();
}

void EncodersPair::encodersCallback(const ros::TimerEvent& event) {
    time_source::time_point this_time = time_source::now();
    boost::chrono::duration<double> elapsed_duration = this_time - last_time;
    ros::Duration elapsed(elapsed_duration.count());
    last_time = this_time;

    left_wheel_angle = -1 * encoder_left.getAngle();
    right_wheel_angle = 1 * encoder_right.getAngle();

    double delta_left_wheel = left_wheel_angle - left_wheel_position;
    double delta_right_wheel = right_wheel_angle - right_wheel_position;

    left_wheel_position += delta_left_wheel;
    left_wheel_velocity = delta_left_wheel / elapsed.toSec();

    right_wheel_position += delta_right_wheel;
    right_wheel_velocity = delta_right_wheel / elapsed.toSec();
 
    left_wheel_velocity_msg.data = left_wheel_velocity;
    right_wheel_velocity_msg.data = right_wheel_velocity;

    left_wheel_velocity_pub.publish(left_wheel_velocity_msg);
    right_wheel_velocity_pub.publish(right_wheel_velocity_msg);
}

int main(int argc, char** argv) {
    ros::init(argc, argv, "encoders_velocity_test");
    EncodersPair encoders_pair(0.01);
    ros::spin();
    return 0;
}
```

Add the executable to the `CMakelists.txt` file in the `abot_driver` pakage:

```makefile
add_executable(encoders_velocity_test src/test/encoders_velocity_test.cpp)
target_link_libraries(encoders_velocity_test ${catkin_LIBRARIES} -lwiringPi -lpthread -lcrypt -lm -lrt)
```

Build the workspace with the new test:

```bash
cd ~/ros
catkin_make
```

Run the core in a new terminal:

```bash
roscore
```

Run the `encoders_velocity_test` node in a new terminal under `root`:

```bash
cd ~/ros
sudo -s
source devel/setup.bash
rosrun abot_driver encoders_velocity_test
```

Run the `friction_test` to manually set the maximum PWM value:

```bash
cd ~/ros
sudo -s
source devel/setup.bash
rosrun abot_driver friction_test
```

Set the maximum PWM value (1023) for both motors using the `rqt` utility, as we did in previous chapters.
Open the topic monitor for each wheel and find out its maximum rotation velocity.

For the right wheel:

```bash
rostopic echo /right_wheel_encoder_velocity
```

![../media/wheel_speed_right.png](../media/wheel_speed_right.png)

For the left wheel:

```bash
rostopic echo /left_wheel_encoder_velocity
```

![../media/wheel_speed_left.png](../media/wheel_speed_left.png)

I got that the left wheel rotates at a maximum speed of about `16.4` Rad/s and the right wheel at a speed of `15.1` Rad/s. You need to define these values in the `dc_motors` node:

```cpp
#define MAX_ANGLUAR_LEFT_WHEEL_SPEED 16.4
#define MAX_ANGLUAR_RIGHT_WHEEL_SPEED 15.1
```

## Drivers Launcher

Excellent, two main drivers are ready. Let's create the new launch file so that you don't have to run these drivers separately each time.

In the `abot_driver` package, create the `launch` folder and put the following `abot_drivers.launch` file into it.

```xml
<launch>
    <node name="encoders" pkg="abot_driver" type="encoders" output="screen" />
    <node name="dc_motors" pkg="abot_driver" type="dc_motors" output="screen" />
</launch>
```

Open a new terminal, build the workspace, and run drivers.

```bash
cd ~/ros
catkin_make
sudo -s
source devel/setup.bash
roslaunch abot_driver abot_drivers.launch
```

Make sure that both drivers are running, monitore active ROS topics:

```bash
rostopic list
```

![../media/terminal_4.png](../media/terminal_4.png)

# Movement Control

Now I can control the robot's wheels separately, but this is entirely useless. You need to create a controller that will handle the robot's movement. 

## Abot_control Package

The chassis of my robot is a type of 2WD differential drive with a caster wheel. The ROS has many ready-made controllers - `[ros_controllers](http://wiki.ros.org/ros_controllers?distro=noetic)`. For my kind of drive, there is also a ready-made controller - `[diff_drive_controller](http://wiki.ros.org/diff_drive_controller)`. It means that I don't have to write the differential engine algorithm myself but use a ready-made solution.

I create a new `abot_control` package in the `ros` workspace with the following package dependencies: `[controller_manager](http://wiki.ros.org/controller_manager)`, `[hardware_interface](http://wiki.ros.org/hardware_interface?distro=noetic)`, `[trajectory_msgs](http://wiki.ros.org/trajectory_msgs)`, `[ros_controllers](http://wiki.ros.org/ros_controllers)`, `[joint_state_controller](http://wiki.ros.org/joint_state_controller)`, `[robot_state_publisher](http://wiki.ros.org/robot_state_publisher)`.

### Controllers Config

In the `abot_control` package, create the `config` folder and place the `abot_controllers.yaml` file with the description of the robot's controllers. I use two controllers.

The first one is type `joint_state_controller/JointStateController`. I called it `joint_state_controller`. This controller is responsible for updating all robot joints positions on the parametric server. The `publish_rate` parameter sets the frequency of updating the joints positions. I set the rate to `100` times per second.

```yaml
joint_state_controller:
  type: joint_state_controller/JointStateController
  publish_rate: 100
```

The second controller is of the `diff_drive_controller/DiffDriveController` type. I named it `mobile_abot`. This is the controller directly responsible for the robot's movement. I set the contoller rate to `100` times per second.

In ROS, a robot's movement is carried out through topics that communicate type `geometry_msgs/Twist` messages. A message of this type consists of two vectors `geometry_msgs/Vector3 linear` and
`geometry_msgs/Vector3 angular`. The `geometry_msgs/Vector3 linear` vector describes a robot's linear velocities along the X Y Z axes in the global coordinate system. The `geometry_msgs/Vector3 angular` vector represents the rotation velocity of a robot along these axes. 

The differential 2WD drive is non-holomonic and it is controlled only by linear speed along the X axis and angular velocity around the Z axis.

Here is the controller priciple. You pass the robot velocity vectors to the `/cmd_vel` topic. The controller analyzes the received vectors, calculates the required rotation speeds of the right and left wheels, and sends calculated values to the left and right wheel motor topic. Simultaneously, the controller reads the current angles of the wheels and calculates the robot's path and Odometry. The Odometry messages are of the `nav_msgs/Odometry type` and are published in the `/odom` topic.

The controller is set by many parameters, but you can adjust just the main ones. You need to specify the names of the right and left wheel joints - `left_wheel` and `right_wheel`, the base robot link - `base_frame_id`, the maximum linear speed and acceleration of the robot along the X axis, and the maximum angular speed and acceleration of the robot around the Z axis. The minimum value can be omitted, by default it is equal to the maximum with the opposite sign. Set up the controllers working frequency - `publish_rate`. The `twist_covariance_diagonal` and `pose_covariance_diagonal` matrices for the Odometry can be left default.

```yaml
mobile_abot:
  type : "diff_drive_controller/DiffDriveController"
  left_wheel: 'left_wheel_to_base'
  right_wheel: 'right_wheel_to_base'
  publish_rate: 100.0
  pose_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  twist_covariance_diagonal: [0.001, 0.001, 1000000.0, 1000000.0, 1000000.0, 1000.0]
  wheel_separation_multiplier: 1.0 # default: 1.0
  wheel_radius_multiplier    : 1.0 # default: 1.0
  cmd_vel_timeout: 0.1
  base_frame_id: base_footprint
  linear:
    x:
      has_velocity_limits : true
      max_velocity : 0.6642 # m/s
      has_acceleration_limits: true
      max_acceleration : 6.1152 # m/s^2
  angular:
    z:
      has_velocity_limits : true
      max_velocity : 5.0 # rad/s
      has_acceleration_limits: true
      max_acceleration : 10.0 # rad/s^2  
  enable_odom_tf: true
```

Where do I get the robot's speed values? The robot's maximum linear speed can be calculated from the robot's wheels' maximum rotational speeds. However, it is better to set all speeds and accelerations to 0 and gradually increase them while debugging the robot. I took these values empirically. 

### Adjust the Robot Description

For the correct calculation of speeds and odometry, the controller needs two more important parameters - `wheel_radius` and `wheel_separation`. By default, the controller searches for these parameters in the `robot_description`. 

Furthermore, you need to make some changes to the `robot description`. In the controller settings, you specify the names of the robot wheel joints. The controller expects that the child links attached to these joints are circular wheels.

But, in my model, wheels are stored as mesh, *.STL files. The circular part stored in the *.STL file is not actually circular but is an approximation of a circle and consists of many polygons. The controller needs wheels to be described mathematically.

To do this, I create two more links in the `abot_description` URDF model, `left_wheel`, and `right_wheel`. In these links, the visual component is described by the `geometry` tag, not a Mesh. Now the `left_wheel_to_base` and `right_wheel_to_base` joints should lead to the new links `left_wheel` and `right_wheel`. The old links `abot_left_wheel` and `abot_right_wheel` can be attached fixed to the new ones with new fixed joints. I define the robot wheels as cylinders with a height of 26mm and a diameter of 65mm

Add new params to the `abot.xacro`:

```xml
<xacro:property name="wheel_radius" value="0.0325"/>
<xacro:property name="wheel_separation" value="0.128"/>
<xacro:property name="wheel_width" value="0.026"/>
<xacro:property name="PI" value="3.1415926"/>
```

Adjust the left wheel description:

```xml
<link name="left_wheel">
	<visual>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
		<material name="Green" />
	</visual>
	<collision>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
	</collision>
</link>
<joint name="left_wheel_to_abot_left_wheel" type="fixed">
	<origin xyz="0 0 0" rpy="0 0 0" />
	<parent link="left_wheel" />
	<child link="abot_left_wheel" />
</joint>
<joint name="left_wheel_to_base" type="continuous">
	<origin xyz="0 0.068 0.0145" rpy="0 0 0" />
	<parent link="abot_base" />
	<child link="left_wheel" />
	<axis xyz="0 1 0" />
</joint>	
```

And the right wheel description:

```xml
<link name="right_wheel">
	<visual>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
		<material name="Green" />
	</visual>
	<collision>
		<origin xyz="0 0 0" rpy="${PI/2} 0 0" />
		<geometry>
			<cylinder length="${wheel_width}" radius="${wheel_radius}"/>
		</geometry>
	</collision>
</link>
<joint name="right_wheel_to_abot_right_wheel" type="fixed">
	<origin xyz="0 0 0" rpy="0 0 0" />
	<parent link="right_wheel" />
	<child link="abot_right_wheel" />
</joint>
<joint name="right_wheel_to_base" type="continuous">
	<origin xyz="0 -0.068 0.0145" rpy="0 0 0" />
	<parent link="abot_base" />
	<child link="right_wheel" />
	<axis xyz="0 1 0" />
</joint>
```

### Controllers Launcher

Create a launch file for both controllers. In package `abot_control`, create folder `launch` with file `abot_control.launch`:

```xml
<launch>
	<rosparam file="$(find abot_control)/config/abot_controllers.yaml" command="load"/>
	<node name="controller_spawner" pkg="controller_manager" type="spawner" respawn="false" output="screen"
		args="joint_state_controller mobile_abot"></node>
</launch>
```

## Abot_base Package

The controllers themselves that we have described are universal. By now, they have been configured, but they don't know with what they should work. We need to link controllers to our specific hardware, i.e., create a ROS [hardware interface](http://wiki.ros.org/hardware_interface). For this, in ROS, there is a conventional robot `base` node. I called mine `abot_base`.

I create a new `abot_base` package. Set the dependency packages: `controller_manager`, `hardware_interface`, `trajectory_msgs`, `[roscpp](http://wiki.ros.org/roscpp)`, `diff_drive_controller`.

In this package, you need to create a specific C++ class, a descendant of the ROS `hardware_interface::RobotHW` C++ class, which registers all the described controllers and communicates with drivers topics. My class subscribes to driver topics `abot/left_wheel_angle` and `abot/right_wheel_angle` and publishes to driver topics `/abot/left_wheel_velocity` and `/abot/right_wheel_velocity`. 

The `updateJointsFromHardware` method processes the current wheel angles, calculates the current wheels velocities and push them to the `mobile_abot` controller. On the other hand, the `writeCommandsToHardware` method sends to the driver the desired wheel speeds calculated by the `mobile_abot` controller.

Сreate the `src` folder in the `abot_base` package and place the `abot_hardware_interface.h` header file in it.

```cpp
#ifndef ABOT_HARDWARE_INTERFACE_HPP_
#define ABOT_HARDWARE_INTERFACE_HPP_

#include <boost/assign/list_of.hpp>
#include <sstream>
#include <std_msgs/Float32.h>
#include <std_srvs/Empty.h>

#include <controller_manager/controller_manager.h>
#include <hardware_interface/joint_command_interface.h>
#include <hardware_interface/joint_state_interface.h>
#include <hardware_interface/robot_hw.h>
#include <ros/ros.h>
#include <ros/console.h>

class AbotHardwareInterface : public hardware_interface::RobotHW {
public:
    AbotHardwareInterface(ros::NodeHandle node, ros::NodeHandle private_node, double target_max_wheel_angular_speed);

    void updateJointsFromHardware(const ros::Duration& period);
    void writeCommandsToHardware();
private:
    ros::NodeHandle _node;
    ros::NodeHandle _private_node;

    hardware_interface::JointStateInterface _joint_state_interface;
    hardware_interface::VelocityJointInterface _velocity_joint_interface;

    ros::Subscriber _left_wheel_angle_sub;
    ros::Subscriber _right_wheel_angle_sub;
    ros::Publisher _left_wheel_vel_pub;
    ros::Publisher _right_wheel_vel_pub;

    struct Joint {
        double position;
        double position_offset;
        double velocity;
        double effort;
        double velocity_command;

        Joint()
            : position(0)
            , velocity(0)
            , effort(0)
            , velocity_command(0) {}
    } _joints[2];

    double _left_wheel_angle;
    double _right_wheel_angle;
    double _max_wheel_angular_speed;

    void registerControlInterfaces();
    void leftWheelAngleCallback(const std_msgs::Float32& msg);
    void rightWheelAngleCallback(const std_msgs::Float32& msg);
    void limitDifferentialSpeed(double& diff_speed_left_side, double& diff_speed_right_side);
};

AbotHardwareInterface::AbotHardwareInterface(ros::NodeHandle node, ros::NodeHandle private_node, double target_max_wheel_angular_speed)
    : _node(node)
    , _private_node(private_node)
    , _max_wheel_angular_speed(target_max_wheel_angular_speed) {

    registerControlInterfaces();

    _left_wheel_vel_pub = _node.advertise<std_msgs::Float32>("/abot/left_wheel_velocity", 1);
    _right_wheel_vel_pub = _node.advertise<std_msgs::Float32>("/abot/right_wheel_velocity", 1);
    _left_wheel_angle_sub = _node.subscribe("abot/left_wheel_angle", 1, &AbotHardwareInterface::leftWheelAngleCallback, this);
    _right_wheel_angle_sub = _node.subscribe("abot/right_wheel_angle", 1, &AbotHardwareInterface::rightWheelAngleCallback, this);
}

void AbotHardwareInterface::writeCommandsToHardware() {
    double diff_angle_speed_left = _joints[0].velocity_command;
    double diff_angle_speed_right = _joints[1].velocity_command;

    limitDifferentialSpeed(diff_angle_speed_left, diff_angle_speed_right);

    std_msgs::Float32 left_wheel_vel_msg;
    std_msgs::Float32 right_wheel_vel_msg;

    left_wheel_vel_msg.data = diff_angle_speed_left;
    right_wheel_vel_msg.data = diff_angle_speed_right;

    _left_wheel_vel_pub.publish(left_wheel_vel_msg);
    _right_wheel_vel_pub.publish(right_wheel_vel_msg);
}

void AbotHardwareInterface::updateJointsFromHardware(const ros::Duration& period) {
    double delta_left_wheel = _left_wheel_angle - _joints[0].position - _joints[0].position_offset;
    double delta_right_wheel = _right_wheel_angle - _joints[1].position - _joints[1].position_offset;

    if (std::abs(delta_left_wheel) < 1) {
        _joints[0].position += delta_left_wheel;
        _joints[0].velocity = delta_left_wheel / period.toSec();
    } else {
        _joints[0].position_offset += delta_left_wheel;
    }

    if (std::abs(delta_right_wheel) < 1) {
        _joints[1].position += delta_right_wheel;
        _joints[1].velocity = delta_right_wheel / period.toSec();
    } else {
        _joints[1].position_offset += delta_right_wheel;
    }
}

void AbotHardwareInterface::registerControlInterfaces() {
    ros::V_string joint_names = boost::assign::list_of("left_wheel_to_base")("right_wheel_to_base");

    for (unsigned int i = 0; i < joint_names.size(); i++) {
        hardware_interface::JointStateHandle joint_state_handle(joint_names[i], &_joints[i].position, &_joints[i].velocity, &_joints[i].effort);
        _joint_state_interface.registerHandle(joint_state_handle);

        hardware_interface::JointHandle joint_handle(joint_state_handle, &_joints[i].velocity_command);
        _velocity_joint_interface.registerHandle(joint_handle);
    }
    registerInterface(&_joint_state_interface);
    registerInterface(&_velocity_joint_interface);
}

void AbotHardwareInterface::leftWheelAngleCallback(const std_msgs::Float32& msg) {
    _left_wheel_angle = msg.data;
}

void AbotHardwareInterface::rightWheelAngleCallback(const std_msgs::Float32& msg) {
    _right_wheel_angle = msg.data;
}

void AbotHardwareInterface::limitDifferentialSpeed(double& diff_speed_left_side, double& diff_speed_right_side) {
    double large_speed = std::max(std::abs(diff_speed_left_side), std::abs(diff_speed_right_side));
    if (large_speed >  _max_wheel_angular_speed) {
        diff_speed_left_side *=  _max_wheel_angular_speed / large_speed;
        diff_speed_right_side *=  _max_wheel_angular_speed / large_speed;
    }
}

#endif // ABOT_HARDWARE_INTERFACE_HPP_
```

This whole process can be described by classical [Control theory](https://en.wikipedia.org/wiki/Control_theory). We have a [closed-loop controller](https://en.wikipedia.org/wiki/Control_theory#Closed-loop_transfer_function). At the input, there is the desired speed of the robot. At the output, there is the rotation speed of wheels. As a feedback there are the current wheel speeds and angles.

Now let's create `abot_base.cpp` node, which starts the closed-loop controller and hardware interface with the specified `control_frequency`. The `max_wheel_angular_speed` parameter is necessary to prevent accidentally sending large speed values to the driver. This value can be taken from previous chapters.

```cpp
#include <chrono>
#include <functional>
#include <ros/callback_queue.h>

#include "abot_hardware_interface.h"

typedef boost::chrono::steady_clock time_source;

void controlLoop(AbotHardwareInterface& hardware, controller_manager::ControllerManager& cm, time_source::time_point& last_time) {

    time_source::time_point this_time = time_source::now();
    boost::chrono::duration<double> elapsed_duration = this_time - last_time;
    ros::Duration elapsed(elapsed_duration.count());
    last_time = this_time;

    hardware.updateJointsFromHardware(elapsed);
    cm.update(ros::Time::now(), elapsed);
    hardware.writeCommandsToHardware();
}

int main(int argc, char** argv) {
    ros::init(argc, argv, "abot_base_node");
    ros::NodeHandle node;
    ros::NodeHandle private_node("~");

    int control_frequency;
    double max_wheel_angular_speed;

    private_node.param<int>("control_frequency", control_frequency, 1);
    private_node.param<double>("max_wheel_angular_speed", max_wheel_angular_speed, 1.0);

    AbotHardwareInterface hardware(node, private_node, max_wheel_angular_speed);

    controller_manager::ControllerManager cm(&hardware, node);

    ros::CallbackQueue abot_queue;
    ros::AsyncSpinner abot_spinner(1, &abot_queue);

    time_source::time_point last_time = time_source::now();

    ros::TimerOptions control_timer(
        ros::Duration(1 / control_frequency),
        boost::bind(controlLoop, std::ref(hardware), std::ref(cm), std::ref(last_time)), &abot_queue);

    ros::Timer control_loop = node.createTimer(control_timer);

    abot_spinner.start();
    ros::spin();
    return 0;
}
```

Build the new source files:

```bash
catkin_make
```

### Base Launcher

Create a launch file for the `abot_base` node. In package `abot_base`, create folder `launch` with file `abot_base.launch`:

```xml
<launch>
	<node name="abot_base_node" pkg="abot_base" type="abot_base_node" output="screen">
    	<param name="control_frequency" type="int" value="100"/>
		<param name="max_wheel_angular_speed" type="double" value="16.4"/>
	</node>
</launch>
```

## Test the Movement

It's time to test the robot's movement. We have all the packages for this. Let's create a new launcher file for robot motion tests. I name it `bringup.launch`. This launch file does not belong to any package, so I put it in the `launch` folder in the `abot_description` package. In this launcher file, launch all the created nodes and put the robot's URDF model to the parameters server.

```xml
<launch>
	<param name="robot_description" command="$(find xacro)/xacro '$(find abot_description)/urdf/abot.xacro' --inorder"/>
	<node name="robot_state_publisher" pkg="robot_state_publisher" type="robot_state_publisher" respawn="false" output="screen" />

	<include file="$(find abot_base)/launch/abot_base.launch" />
	<include file="$(find abot_control)/launch/abot_control.launch" />
	<include file="$(find abot_driver)/launch/abot_drivers.launch" />
	<include file="$(find abot_teleop)/launch/abot_teleop.launch" />
</launch>
```

I'm going to control the robot's movement from the desktop computer through the ROS network. Make sure that both the robot and the desktop computer are online. Connect to the robot via SSH from your desktop computer.

At the robot, start the ROS core.

```bash
roscore
```

At the robot, in a new terminal, launch the created launch file.

```bash
cd ~/ros
sudo -s
source devel/setup.bash
roslaunch abot_description bringup.launch
```

```bash
root@robot:/home/ubuntu/ros# roslaunch abot_description bringup.launch 
... logging to /root/.ros/log/840711c6-1eaa-11eb-97e3-f90dffb31ac1/roslaunch-robot-3854.log
Checking log directory for disk usage. This may take a while.
Press Ctrl-C to interrupt
Done checking log file disk usage. Usage is <1GB.

xacro: in-order processing became default in ROS Melodic. You can drop the option.
started roslaunch server http://robot:45673/

SUMMARY
========

PARAMETERS
 * /abot_base_node/control_frequency: 100
 * /abot_base_node/max_wheel_angular_speed: 16.4
 * /joint_state_controller/publish_rate: 100
 * /joint_state_controller/type: joint_state_contr...
 * /mobile_abot/angular/z/has_acceleration_limits: True
 * /mobile_abot/angular/z/has_velocity_limits: True
 * /mobile_abot/angular/z/max_acceleration: 10.0
 * /mobile_abot/angular/z/max_velocity: 5.0
 * /mobile_abot/base_frame_id: base_footprint
 * /mobile_abot/cmd_vel_timeout: 0.1
 * /mobile_abot/enable_odom_tf: True
 * /mobile_abot/left_wheel: left_wheel_to_base
 * /mobile_abot/linear/x/has_acceleration_limits: True
 * /mobile_abot/linear/x/has_velocity_limits: True
 * /mobile_abot/linear/x/max_acceleration: 6.1152
 * /mobile_abot/linear/x/max_velocity: 0.6642
 * /mobile_abot/pose_covariance_diagonal: [0.001, 0.001, 10...
 * /mobile_abot/publish_rate: 100.0
 * /mobile_abot/right_wheel: right_wheel_to_base
 * /mobile_abot/twist_covariance_diagonal: [0.001, 0.001, 10...
 * /mobile_abot/type: diff_drive_contro...
 * /mobile_abot/wheel_radius_multiplier: 1.0
 * /mobile_abot/wheel_separation_multiplier: 1.0
 * /robot_description: <?xml version="1....
 * /rosdistro: noetic
 * /rosversion: 1.15.8

NODES
  /
    abot_base_node (abot_base/abot_base_node)
    controller_spawner (controller_manager/spawner)
    dc_motors (abot_driver/dc_motors)
    encoders (abot_driver/encoders)
    robot_state_publisher (robot_state_publisher/robot_state_publisher)

ROS_MASTER_URI=http://robot:11311

process[robot_state_publisher-1]: started with pid [3870]
process[abot_base_node-2]: started with pid [3871]
process[controller_spawner-3]: started with pid [3872]
process[encoders-4]: started with pid [3873]
process[dc_motors-5]: started with pid [3874]
[ INFO] [1604500742.269429269]: DCMotor wiringPi: GPIO setup
[ INFO] [1604500742.270396124]: DCMotor wiringPi: Motor setup
[ INFO] [1604500742.271003256]: DCMotor wiringPi: GPIO setup
[ INFO] [1604500742.274570547]: DCMotor wiringPi: Motor setup
[ INFO] [1604500742.288459728]: Encoder wiringPi: GPIO setup
[ INFO] [1604500742.584368161]: Encoder wiringPi: ISR setup
[ INFO] [1604500742.584681718]: Encoder wiringPi: GPIO setup
[ INFO] [1604500742.770387149]: Encoder wiringPi: ISR setup
[INFO] [1604500744.036463]: Controller Spawner: Waiting for service controller_manager/load_controller
[INFO] [1604500744.056506]: Controller Spawner: Waiting for service controller_manager/switch_controller
[INFO] [1604500744.074904]: Controller Spawner: Waiting for service controller_manager/unload_controller
[INFO] [1604500744.091380]: Loading controller: joint_state_controller
[INFO] [1604500744.170848]: Loading controller: mobile_abot
[ INFO] [1604500744.248660336]: Controller state will be published at 100Hz.
[ INFO] [1604500744.262246442]: Wheel separation will be multiplied by 1.
[ INFO] [1604500744.268321427]: Left wheel radius will be multiplied by 1.
[ INFO] [1604500744.268528169]: Right wheel radius will be multiplied by 1.
[ INFO] [1604500744.271149938]: Velocity rolling window size of 10.
[ INFO] [1604500744.277268405]: Velocity commands will be considered old if they are older than 0.1s.
[ INFO] [1604500744.279907285]: Allow mutiple cmd_vel publishers is enabled
[ INFO] [1604500744.285368250]: Base frame_id set to base_footprint
[ INFO] [1604500744.288966763]: Odometry frame_id set to odom
[ INFO] [1604500744.294588950]: Publishing to tf is enabled
[ INFO] [1604500744.378008407]: left wheel to origin: 0,0.068, 0.0145
[ INFO] [1604500744.378288501]: right wheel to origin: 0,-0.068, 0.0145
[ INFO] [1604500744.378540428]: Odometry params : wheel separation 0.136, left wheel radius 0.03195, right wheel radius 0.03195
[ INFO] [1604500744.391293679]: Adding left wheel with joint name: left_wheel_to_base and right wheel with joint name: right_wheel_to_base
[ INFO] [1604500744.463016167]: Dynamic Reconfigure:
DynamicParams:
	Odometry parameters:
		left wheel radius multiplier: 1
		right wheel radius multiplier: 1
		wheel separation multiplier: 1
	Publication parameters:
		Publish executed velocity command: disabled
		Publication rate: 100
		Publish frame odom on tf: enabled
[INFO] [1604500744.482717]: Controller Spawner: Loaded controllers: joint_state_controller, mobile_abot
[INFO] [1604500744.506911]: Started controllers: joint_state_controller, mobile_abot
```

On the desktop computer, check that all the topics we need have appeared:

```bash
rostopic list
```

![../media/movement_topics.png](../media/movement_topics.png)

To control the robot, use the already familiar utility `rqt` ROS utility and the `rqt_robot_steering` plugin.

![../media/movement_rqt.png](../media/movement_rqt.png)

Set the topic for publishing `geometry_msgs/Twist` messages - `/abot_mobile/cmd_vel`. Move the sliders. The robot should start moving.

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_movement.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

### Visualize Odometry

So we checked how our controller works, but only in one direction. Let's check the operation of the controller in the opposite direction - visualize the odometry.

Create a new launcher file to launch `rviz` visualization. Let's call it `display_movement.launch` and put it in `abot_description/launch`. 

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_movement.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

Here for `rviz`, use the same settings as when viewing the model (`abot_model.rviz`) only this time in *Global Options* set the *Fixed Frame* to `odom`.

Do all the same steps to start the movement described above but now on a desktop machine, in addition to `rqt` steering plugin, also run `rviz`:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_description display_movement.launch
```

Control the robot using the steering plugin and monitor its position in the `rviz` window.

![../media/movement_rviz.png](../media/movement_rviz.png)

This stage is very, very important. You need to ensure that the robot's display in `rviz` does not differ from the robot's actual position. If in reality, for example, your robot drives 1 meter straight and then turns 90 degrees, then in odometry visualization, the robot should go the exact way! If your odometry differs from the robot's actual position, you incorrectly configured the parameters of either the controller or the urdf model. Carefully review all config files.

ВИДЕО! СПЛИТСКРИН ИРЛ+РВИЗ+РУЛЕЖКА RQT.

# Robot Teleoperation

You can control the robot's movement via the `rqt_robot_steering` plugin, but it is not very convenient. It is much easier to control the robot with a joystick.

Let's make the robot's movement teleoperation from a regular Dualshock 4 joystick from the PS4 console. The Dualshock 4 joystick communicates via Bluetooth.

![../media/dualshock_800.jpg](../media/dualshock_800.jpg)

## Setup Drivers

### Setup Raspberry Pi 4 Bluetooth Device

Raspberry Pi 4 already has a Bluetooth module, and you don't need to buy any additional Bluetooth hardware modules. However, the Bluetooth chip communicates with the Raspberry controller via UART, and this UART interface is open for use by default.

We have to sacrifice one hardware UART Raspberry interface and assign the Bluetooth module to it. For Ubuntu Focal (20.04) the Bluetooth activation sequence is as follows:

```bash
sudo apt-get install pi-bluetooth
sudo apt-get install bluetooth bluez blueman
```

Edit the `/boot/firmware/usrcfg.txt` file:

```bash
sudo nano /boot/firmware/usrcfg.txt
```

And add the following line at the end:

```bash
include btcfg.txt
```

Save the file and reboot the Raspberry. Then, check that the Bluetooth device is detected:

```bash
hciconfig -a
```

![../media/teleop_bl_1.png](../media/teleop_bl_1.png)

### Setup Dualshock 4 Driver

Now install the driver for the Dualshock4 joystick on Raspberry. I use an excellent open-source driver [https://github.com/naoki-mizuno/ds4drv](https://github.com/naoki-mizuno/ds4drv). The ROS already has a wrapper package for this driver.

Install the `pip` package installer for Python and the driver:

```bash
sudo apt-get install python3-venv python3-pip
sudo apt-get install python-is-python3
sudo pip3 install ds4drv
```

Pair the PS4 joystick with the Raspberry Pi. For this, take the joystick and simultaneously press the *Sharing* button and the *PS4* button. The joystick LED indicator will start blinking rapidly. 

ВИДЕО! РЕЗКИЕ МИГАНИЯ ДУАЛШОКА 4.

On Raspberry desktop use `blueman` to pair the joystick the first time and create connection. In general, you need a joystick to be defined as a HID device.

![../media/bl_blueman.jpg](../media/bl_blueman.jpg)

If it is neccesary change the Raspbery Pi Bluetooth visibility setting:

![../media/bl_adapter.jpg](../media/bl_adapter.jpg)

When you pair the joystick test the `ds4drv` driver, under root: 

```bash
sudo -s
ds4drv --hidraw
```

![../media/bl_ds4drv.jpg](../media/bl_ds4drv.jpg)

In a new terminal check the new `js` input devices:

![../media/bl_js.jpg](../media/bl_js.jpg)

You can test the joystick buttons with `jstest`:

```bash
sudo apt-get install jstest-gtk
jstest /dev/input/js1
```

### Setup ROS Dualshock Package

In ROS, there is the `[ds4_driver](http://wiki.ros.org/ds4_driver)` package, which is a wrapper for the `ds4drv`. This package was made by the [naoki-mizuno](https://github.com/naoki-mizuno/ds4_driver) community member and is not available in the official ROS Noetic assembly. But, you can build it manually, simply adding it to the `ros` workspace. 

```bash

cd ~/ros/src
git clone https://github.com/naoki-mizuno/ds4_driver.git
cd ~/ros
catkin_make
```

Or you can just clone into the `ros` workspace and build along with abot packages.
Also, install the `[joy](http://wiki.ros.org/joy)` package:

```bash
sudo apt-get install ros-noetic-joy
```

## Abot_teleop Package

Let's create a new package in our `ros` workspace - `abot_teleop`. This package will store all nodes that are somehow connected to the remote control. Set the package dependencies -`[roscpp](http://wiki.ros.org/roscpp)`, `geometry_msgs`, `sensor_msgs`, `joy`.

Conventionally, in the ROS, joystick devices publish messages of the `[sensor_msgs/Joy](http://docs.ros.org/en/api/sensor_msgs/html/msg/Joy.html)` type. The `[ds4_driver](http://wiki.ros.org/ds4_driver)` package that we installed sends messages of this type to the topic `/joy`. This message contains the states of all buttons and joysticks on the device.

I use the Dualshock's left and right joysticks to control the robot's speed. The left joystick's vertical movement is responsible for the linear velocity vector of the robot along the X-axis. The horizontal movement of the right joystick is responsible for the robot's angular velocity around the Z-axis.

We need to write a simple C++ class that responds to changes in joystick buttons states. In the `abot_teleop` package, I create an `src` folder and put the `abot_teleop.hpp` header with the `AbotTeleop` class in it.

What does the `AbotTeleop` class do? This class subscribes to the `/joy` topic and gets data about the states of all Dualshock buttons. Then the positions of the left and right joysticks are multiplied by the limiting coefficients `_linear_speed_scale` and `_angular_speed_scale`. The adjusted positions are translated into velocity vectors and placed in the `geometry_msgs::Twist` type message. The ready message with the robot speed is sent directly to the topic of the differential drive controller - `/mobile_abot/cmd_vel`.

```cpp
#ifndef ABOT_TELEOP_HPP_
#define ABOT_TELEOP_HPP_

#include <ros/ros.h>
#include <geometry_msgs/Twist.h>
#include <sensor_msgs/Joy.h>

#define PS4_AXIS_STICK_LEFT_LEFTWARDS 0
#define PS4_AXIS_STICK_LEFT_UPWARDS 1
#define PS4_AXIS_STICK_RIGHT_LEFTWARDS 2
#define PS4_AXIS_STICK_RIGHT_UPWARDS 3

class AbotTeleop {
public:
    AbotTeleop(ros::NodeHandle private_node);
private:
    ros::NodeHandle _node;
    ros::NodeHandle _private_node;
    ros::Subscriber _joy_sub;
    ros::Publisher _cmd_vel_pub;

    bool _last_zero_twist = true; 
    double _linear_speed_scale;
    double _angular_speed_scale;
    
    void joyCallback(const sensor_msgs::Joy::ConstPtr& joy);
};

AbotTeleop::AbotTeleop(ros::NodeHandle private_node) :
    _private_node(private_node) {

    _private_node.param<double>("linear_speed_scale", _linear_speed_scale, 0.0);
    _private_node.param<double>("angular_speed_scale", _angular_speed_scale, 0.0);
    _cmd_vel_pub = _node.advertise<geometry_msgs::Twist>("/mobile_abot/cmd_vel", 1);
    _joy_sub = _node.subscribe<sensor_msgs::Joy>("joy", 10, &AbotTeleop::joyCallback, this);
    ROS_INFO("Abot teleop node: Start");
}

void AbotTeleop::joyCallback(const sensor_msgs::Joy::ConstPtr& joy) {

    geometry_msgs::Twist twist;

    double twist_linear_x_vel =  _linear_speed_scale * joy->axes[PS4_AXIS_STICK_LEFT_UPWARDS];
    double twist_angular_z_vel = _angular_speed_scale * joy->axes[PS4_AXIS_STICK_RIGHT_LEFTWARDS];

    twist.linear.x = twist_linear_x_vel;
    twist.angular.z = twist_angular_z_vel;

    if (twist_linear_x_vel == 0 && twist_angular_z_vel == 0) {
        if (_last_zero_twist == false) {
            _cmd_vel_pub.publish(twist);
            _last_zero_twist = true;
        } 
    } else {
        _last_zero_twist = false;
        _cmd_vel_pub.publish(twist);
    }
}

#endif // ABOT_TELEOP_HPP_
```

In the `src` folder, create the `abot_teleop.cpp` file that contains the node to work with our class.

```cpp
#include "abot_teleop.hpp"

int main(int argc, char **argv) {
    ros::init(argc, argv, "abot_teleop_node");
    ros::NodeHandle private_node("~");
    AbotTeleop abotTeleop(private_node);
    ros::spin();
}
```

Add the executable to the `CMakelists.txt` file in the `abot_teleop` pakage:

```makefile
add_executable(abot_teleop src/abot_teleop.cpp)
target_link_libraries(abot_teleop ${catkin_LIBRARIES})
```

Finally, build the new nodes:

```bash
cd ~/ros
catkin_make
```

### Teleoperation Launch

Let's create the new launch file to run the `ds4drv` wrapper and the teleoperation node.

In the `abot_teleop` package, create the `launch` folder and put the following `abot_teleop.launch` file into it.

```xml
<launch>
	<arg name="addr" default="" />
	<arg name="use_standard_msgs" default="true" />
	<arg name="autorepeat_rate" default="50" if="$(arg use_standard_msgs)" />
	<node pkg="ds4_driver" type="ds4_driver_node.py" name="ds4_driver" output="screen" >
		<param name="device_addr" value="$(arg addr)" />
		<param name="use_standard_msgs" value="$(arg use_standard_msgs)" />
		<param name="autorepeat_rate" value="$(arg autorepeat_rate)" if="$(arg use_standard_msgs)" />
		<param name="deadzone" value="0.1" />
	</node>
	<node pkg="abot_teleop" type="abot_teleop" name="abot_teleop" >
		<param name="linear_speed_scale" type="double" value="0.04"/> 
		<param name="angular_speed_scale" type="double" value="0.80"/>
	</node>
</launch>
```

The `linear_speed_scale` parameter sets the robot's maximum linear speed to 0,04 m/s, and the `angular_speed_scale` parameter sets the angular speed to 0,8 rad/s. 

Also include the new launcher file in the shared launcher file `abot_description/bringup_movement.launch` that we use for robot's movement:

```xml
<include file="$(find abot_teleop)/launch/abot_teleop.launch" />
```

## Launch the Motion

Everything is ready to control the robot with the joystick. On the Raspberry, in a new terminal, launch the bring up file:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_description bringup.launch
```

To visualize the movement, on the desktop computer run rviz:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_description display_movement.launch
```

Control the robot with the joystick and monitor its movement in the `rviz`.

ВИДЕО! РУЛИМ РОБОТОМ С ДЖОЙСТИКА. СПЛИТ СКРИН ИРЛ+ДЖОЙ+РВИЗ.

# Robot Navigation

Let's deal with navigation. Suppose there is some environment around the robot. To navigate in this environment, the robot must "see" it and localize in it. For this, robots use different sensors. How a robot sees the surrounding environment depends on the sensors it has.

These sensors can be simple or complex, 2D or 3D. These can be cameras, depth cameras, laser/ultrasonic/infrared rangefinders, simple binary contact sensors (bumpers), etc. The more sensors installed at the robot and the better they are synchronized with each other, the more information the robot can get about the world around it. ROS supports a wide variety of sensors. Read more in the [documentation](http://wiki.ros.org/Sensors).

## RPLIDAR A1

For beginners, it is best to start with simple, effective, and popular sensors. The best sensor for beginners is a [LIDAR](https://en.wikipedia.org/wiki/Lidar) with a 360-degree field of view. 

This 2D sensor can scan the entire plane in which it is installed. Why LIDAR? This type of sensor is so effective that a single device can be enough for a robot to perform navigation in a room. I chose the most popular and low-cost [RPLIDAR A1](https://www.slamtec.com/en/Lidar/A1) by SLAMTEC.

![../media/lidar.jpg](../media/lidar.jpg)

This sensor provides a 360-degree scanning field, with a 5.5Hz/10Hz rotation frequency. The range of the RPLIDAR A1 is about 8 meters. This lidar comes as a complete device. You just need to mount it on your robot and connect it to the robot's onboard computer. The easiest way to connect the RPLIDAR is to use the USB port.

The main reason I use this particular sensor is the [ROS RPLIDAR package](http://wiki.ros.org/rplidar) and ROS support from the manufacturer.

### Mount the Sensor

For the lidar mount, I cut out another plexiglass pad and attached RPLIDAR A1 to it. 

ФОТО! Лидар с падом.

The LIDAR rotates, and there should be no other robot parts around to interfere with the scan. Most often, the LIDAR is the highest point of the robot. On different robots, LIDARs are installed different ways and in different places. It is best to install LIDAR closer to the ground. The efficiency of detecting obstacles for LIDARs installed in this way is higher. However, the low-level LIDAR has a reduced viewing angle because of other surrounding robot parts. I decided to install my LIDAR on top of the robot. So, it cannot detect low-height obstacles, but it keeps a circular view.

ФОТО! Лидар с падом на роботе.

### Update the Robot Description

Get used to reflect any real robot changes in the 3D model and URDF description. I added new parts to the 3D model CAD model of the robot.

![../media/6.png](../media/6.png)

For the LIDAR, you also need to create a link in the URDF robot description. 

When adding sensors to the robot description, it is crucial to set the correct proper coordinate systems and axes of the sensor action. For RPLIDAR A1 in ROS, the following reference coordinate system orientation is recommended:

![../media/rplidar_A1_frame.png](../media/rplidar_A1_frame.png)

Create a new coordinate system for the LIDAR sensor:

![../media/ABOT_4.png](../media/ABOT_4.png)

Export the new URDF data. Add a new link and a fixed joint to the element tree; Link to indicate the LIDAR's frame and joint to define the LIDAR scan plane's initial point. I named my link `abot_lidar` and joint `lidar_to_base`.

![../media/4-1-1-1.png](../media/4-1-1-1.png)

Go to the `ros` workspace to the `abot_description` package. Put the new *.STL lidar file to the `meshes` folder. In the `urdf` folder, create a new `xacro` file for describing the sensors and fill it with new URDF export data. I called mine `abot_sensors.xacro`.

```xml
<?xml version="1.0" encoding="utf-8"?>
<robot name="abot"
	xmlns:xacro="http://www.ros.org/wiki/xacro">
	<!-- lidar -->
	<link name="abot_lidar">
		<inertial>
			<origin xyz="0.0118769386096909 -0.000753838771765047 -0.0199066395735294" rpy="0 0 0" />
			<mass value="0.601249620501043" />
			<inertia ixx="0.000163971147126097" ixy="-2.03059193776652E-07" ixz="-3.50083356803378E-06" iyy="0.000195001082010381" iyz="1.20160266671478E-07" izz="0.000341179024466778" />
		</inertial>
		<visual>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_lidar.STL" />
			</geometry>
			<material name="Yellow" />
		</visual>
		<collision>
			<origin xyz="0 0 0" rpy="0 0 0" />
			<geometry>
				<mesh filename="package://abot_description/meshes/abot_lidar.STL" />
			</geometry>
		</collision>
	</link>
	<joint name="lidar_to_base" type="fixed">
		<origin xyz="-0.01 0 0.1494" rpy="0 0 3.14159265358979" />
		<parent link="abot_base" />
		<child link="abot_lidar" />
		<axis xyz="0 0 0" />
	</joint>
</robot>
```

Include the sensors file at the end of the main description file `abot.xacro`:

```xml
<xacro:include filename="$(find abot_description)/urdf/abot_sensors.xacro" />
```

 In the `ros` workspace, launch the `display_model.launch` file and observe description changes in `rviz`.

![../media/rivz_with_lidar.jpg](../media/rivz_with_lidar.jpg)

### USB Device Alias

RPLIDAR connects to the Raspberry via the USB port. Let's create a USB device alias for LIDAR. Using the alias, the OS determines the lidar device, no matter which USB port it is physically plugged.

Connect the LIDAR and see how it is defined in the system:

```bash
lsusb
ls /dev | grep ttyUSB
```

I've got LIDAR defined as `Bus 001 Device 003: ID 10c4:ea60 Silicon Labs CP210x UART Bridge`. Here the `10c4` is the Vendor ID, `ea60` is the Product ID. I use this data to identify the LIDAR.

![../media/usb-1.png](../media/usb-1.png)

Also, you can get more information about the unique attributes of the USB device:

```bash
udevadm info -a -n /dev/ttyUSB0
```

Create a new UDEV rule. Make a new file `99-usb-serial.rules` inside `/etc/udev/rules.d`. Under root.

```bash
sudo nano /etc/udev/rules.d/99-usb-serial.rules
```

Put the following line into the rule.

```bash
SUBSYSTEM=="tty", ATTRS{idVendor}=="10c4", ATTRS{idProduct}=="ea60", SYMLINK+="lidar"
```

According to this rule, any connected device with such `idVendor` and `idProduct` is defined with the `lidar` name. Reload UDEV rules, reconnect RPLIDAR, and make sure that the new alias works:

```bash
sudo udevadm control --reload-rules && udevadm trigger
ls -l /dev/lidar
```

![../media/usb-2.png](../media/usb-2.png)

### PLIDAR ROS Package

To use RPLIDAR A1 in ROS, you do not need to install any additional drivers, just install the ROS `[rplidar_ros](http://wiki.ros.org/rplidar)` package. This package is not yet available in the official ROS Noetic assembly, but you can clone it into your ROS workspace and build it.

```bash
cd ~/ros/src
git clone https://github.com/Slamtec/rplidar_ros.git
cd ~/ros
catkin_make
```

To launch the RPLIDAR, create a new launcher file `abot_lidar.launch`. Since the LIDAR refers to the robot's hardware devices, put the launch file in the `abot_driver/launch` package folder. This file runs the `rplidarNode` node from the `rplidar_ros` package. The RPLIDAR communicates via the UART interface at a default baud rate of 115200. As a path to the interface, specify the USB device alias `/dev/lidar` created earlier. Also here you need to specify the `frame_id` name of the link that describes the LIDAR in URDF. I have this link named `abot_lidar`.

```xml
<launch>
	<node name="rplidarNode" pkg="rplidar_ros"  type="rplidarNode" output="screen">
		<param name="serial_port" type="string" value="/dev/lidar"/>  
		<param name="serial_baudrate" type="int" value="115200"/>
		<param name="frame_id" type="string" value="abot_lidar"/>
		<param name="inverted" type="bool" value="false"/>
		<param name="angle_compensate" type="bool" value="true"/>
		<param name="scan_mode" type="string" value="Boost" />
	</node>
</launch>
```

 Include the file for launching LIDAR into the general `abot_drivers.launch` file for launching all robot drivers:

```xml
<include file="$(find abot_driver)/launch/abot_lidar.launch" />
```

### Visualize the LIDAR Scan

Let's test how the LIDAR works. On the Raspberry side, launch:

```bash
cd ~/ros
sudo -s 
source devel/setup.bash
roslaunch abot_desription bringup.launch
```

Visualize the LIDAR's operation in `rviz`. In the `abot_description` package, create a new launch file to visualize the robot's sensors. I called my `display_sensors.launch`.

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_sensors.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false"/>
</launch>
```

This launch file runs `rviz` with new visualization settings `abot_sensors.rviz`. As a source `rviz` settings, you can use any existing file, for example, `abot_movement.rviz`. At the desktop computer, at the `ros` workspace run:

```bash
roslaunch abot_description display_sensors.launch
```

In the `rviz` settings, add a new visualization for an existing topic. By default, the data from the LIDAR is of the `sensor_msgs/laserscan` type, and it is published to the `/scan` topic. In `rviz` click *Add → Create visualization → By topic* and select the `/scan` topic.

![../media/lidar_rviz.png](../media/lidar_rviz.png)

Take a look at the scan points that appear. Try to control the robot with the joystick and make sure that everything works as it should.

![../media/lidar_rviz_2.png](../media/lidar_rviz_2.png)

ВИДЕО! Сплит скрин. Рвиз+скан+движение+джойстик.

## Navigation Theory

The creation of autonomous mobile robots is a challenging task that requires enormous theoretical and practical knowledge. Here is how I understand it. Autonomous robot navigation is based on three main tasks:

- *[Mapping](https://en.wikipedia.org/wiki/Robotic_mapping)*
- *[Localization](https://en.wikipedia.org/wiki/Robot_navigation)*
- *[Path planning](https://en.wikipedia.org/wiki/Motion_planning)*

The *Mapping* task is to answer the robot's question: "What does the world around me look like?" During *Mapping*, the data from various sensors passes to a robot in a given and understandable representation (map). 

The *Localization* task is to answer the robot's question: "Where am I in the world around me?" During *Localization*, a robot calculates its position relative to the known map. A robot should be able to find itself on the known map wherever it is placed.

The *Path planning* task is to answer the robot's question: "How can I get to a specific point on the map?" A human can set a specific point for a robot to move to, or a robot can set a target point itself. A robot should plan the motion path to the target point and safely and efficiently reach it.

Various combinations of these three components allow a mobile robot to solve different navigation tasks.

![../media/tasks.png](../media/tasks.png)

*SLAM* is [simultaneous localization and mapping](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping). There is a close relationship between *Localization* and *Mapping*. In an unknown environment, mapping and localization cannot be separated. This is because a robot needs to know its current accurate position to make a map, and it needs a good map to know its current position.

The *Active localization* seeks to guide a robot to target points within a map to improve its current position.

The *Exploration* assumes that a robot knows its accurate position and focuses on guiding a robot eﬃciently through the unknown environment to build a map.

The *Integrated approaches* is also called *SPLAM* (simultaneous planning, localization, and mapping). *SPLAM* enables a mobile robot to acquire sensor data by autonomously moving the unknown environment while at the same time building a map.

The task of my robot is good-quality room navigation. First, I'm going to use *SLAM* algorithms to build a map of the room. Then my robot will move autonomously on this map using *Active localization* and *Path planning*.

## Mapping

There are several SLAM algorithms. I'm going to use the [OpenSLAM](https://openslam-org.github.io/) algorithm. ROS has a popular wrapper package for this algorithm - `[gmapping](http://wiki.ros.org/gmapping)`. 

### Gmapping package

For the `[gmapping](http://wiki.ros.org/gmapping)` package to build a map, you need a mobile controlled robot, robot's Odometry, and a LIDAR attached to the robot. I already have all of this. My robot is mobile, I can control the robot from the joystick. I've got simple robot's Odometry at the `/odom` topic. My Odometry comes from the `mobile_abot` differential drive controller. The LIDAR that i have publishs laser scans to the default `/scan` topic.

I create a new package `abot_slam` in the `ros` workspace with dependencies `gmapping` and `sensor_msgs`. In this package, I create three folders: `launch`, `config`, and `maps`. In the `config` folder I store the `gmapping` package settings. In the `launch` folder, I have ROS launch files for SLAM. In the `maps` folder, I keep obtained maps.

Let's create the `gmapping_params.yaml` config file for the `gmapping` settings. Read more about all parameters in the official [ROS documentation for the `gmapping` package](http://wiki.ros.org/gmapping). Most of the settings can be left default. The main thing is to specify the following parameters: `base_frame`, `odom_frame`, `map_frame`, `xmax`, `xmin`, `ymax`, `ymin`, `delta`, `particles`, `map_update_interval`, `maxUrange`, `linearUpdate`, `angularUpdate`, `temporalUpdate`, `resampleThreshold`.

The finished map is an image consisting of white or black squares. A black square indicates an occupied space; a white one indicates a free space. I'm building square map 40 by 40 meters with the origin in the square center and resolution of one `0.02`m. With these parameters, I get the highest map quality:

```yaml
base_frame: base_footprint # The frame attached to the mobile base. 
odom_frame: odom # The frame attached to the odometry system. 
map_frame: map # The frame attached to the map.

map_update_interval: 2.0 # How long (in seconds) between updates to the map. Lowering this number updates the occupancy grid more often, at the expense of greater computational load. 
maxUrange: 5.0 # The maximum usable range of the laser. A beam is cropped to this value. 

linearUpdate: 0.2 # Process a scan each time the robot translates this far 
angularUpdate: 0.2 # Process a scan each time the robot rotates this far 
temporalUpdate: 0.5 # Process a scan if the last scan processed is older than the update time in seconds. A value less than zero will turn time based updates off. 
resampleThreshold: 0.5 # The Neff based resampling threshold 

particles: 100 # Number of particles in the filter (int, default: 30)
minimumScore: 50

xmax: 20.0
xmin: -20.0
ymax: 20.0
ymin: -20.0

delta: 0.02 # Resolution of the map (in metres per occupancy grid block) 

# Keep default
sigma: 0.05 # The sigma used by the greedy endpoint matching (float, default: 0.05) 
kernelSize: 1 # The kernel in which to look for a correspondence (int, default: 1) 
lstep: 0.05 # The optimization step in translation (float, default: 0.05) 
astep: 0.05 # The optimization step in rotation (float, default: 0.05)
iterations: 5 # The number of iterations of the scanmatcher (int, default: 5)

lsigma: 0.075 # The sigma of a beam used for likelihood computation float, default: 0.075) 
ogain: 3.0 # Gain to be used while evaluating the likelihood, for smoothing the resampling effects float, default: 3.0)
lskip: 0 # Number of beams to skip in each scan. Take only every (n+1)th laser ray for computing a match (0 = take all rays) 

srr: 0.1 # Odometry error in translation as a function of translation (rho/rho) (float, default: 0.1) 
srt: 0.2 # Odometry error in translation as a function of rotation (rho/theta) (float, default: 0.2) 
str: 0.1 # Odometry error in rotation as a function of translation (theta/rho) (float, default: 0.1) 
stt: 0.2 # Odometry error in rotation as a function of rotation (theta/theta) (float, default: 0.2) 

llsamplerange: 0.01 # Translational sampling range for the likelihood  (float, default: 0.01) 
llsamplestep: 0.01 # Translational sampling step for the likelihood (float, default: 0.01) 
lasamplerange: 0.005 # Angular sampling range for the likelihood (float, default: 0.005) 
lasamplestep: 0.005 # Angular sampling step for the likelihood (float, default: 0.005)
```

In the `launch` folder, create a new file `abot_slam.launch` to launch SLAM. This file runs the `gmapping` package with the settings specified in the `config`.

```xml
<launch>
	<node pkg="gmapping" type="slam_gmapping" name="abot_slam_gmapping" output="screen">
		<rosparam command="load" file="$(find abot_slam)/config/gmapping_params.yaml" />
	</node>
</launch>
```

Also, you need to create a new visualization file for mapping. As usual, I place visualization files in the `abot_description` package. There I make a new launch file `display_slam.launch`. This file runs the SLAM package and rviz with new settings.

```xml
<launch>
	<arg name="rvizconfig" default="$(find abot_description)/rviz/abot_slam.rviz" />
	<arg name="model" default="$(find abot_description)/urdf/abot.xacro" />
	<param name="robot_description" command="$(find xacro)/xacro --inorder $(arg model)" />
	<node name="rviz" pkg="rviz" type="rviz" args="-d $(arg rvizconfig)" required="false" output="screen"/>
	
	<include file="$(find abot_slam)/launch/abot_slam.launch" />
</launch>
```

The new visualization settings `abot_slam.rviz` differ from the previous in the *Global Options → Fixed Frame* attribute. It should be `map`. In addition the camera is positioned perpendicular to the ground.

### Launch Mapping

Let's start the mapping process. Mapping can be computationally intensive, while my Raspberry is pretty weak. So I run it on my desktop ROS.

Make sure that both the robot and the desktop computer are in the ROS network. Launch the packages placed in the Raspbbery's workspace with the familiar launch file:

```bash
cd ~/ros
sudo -s 
source devel/setup.bash
roslaunch abot_desription bringup.launch
```

On desktop ROS, run the SLAM algorithm and visualization:

```bash
cd ~/ros
source devel/setup.bash
roslaunch abot_desription display_slam.launch
```

![../media/slam_1.png](../media/slam_1.png)

Build a map by controlling the movement of the robot. You can control it using the joystick or the `rqt` steering plugin.

![../media/slam_2.png](../media/slam_2.png)

ВИДЕО! СПЛИТ скрин, контроллим робота с джоя. Строим карту. Ездим по офису.

### Save Map

When the map is ready save it. While SLAM is active, in a new terminal run the `map_saver` utility:

```bash
cd ~/ros/src/abot_slam/maps/
rosrun map_server map_saver -f map1
```

Finished maps are stored as a yaml file and a graphic image in *pgm format. If you want you can edit the map in a graphical editor, for example, to place additional walls or clear excess points.

![../media/map1.png](../media/map1.png)

## ROS Navigation Stack

When the map is ready, you can start navigating it and path planning. For navigation in ROS, I use the conventional [navigation stack](http://wiki.ros.org/navigation?distro=noetic). It contains a lot of cool packages. The stack's essence is that it takes data from Odometry, data from sensors, robot's goal position on the map, and calculates the robot's speeds for the motion controller.

I create a new package and name it `abot_navigation`. There I make two folders `config` and `launch` to store the navigation settings and launch files, respectively.

My robot's navigation is based on two packages from the ROS stack: `[move_base](http://wiki.ros.org/move_base)` and `[acml](http://wiki.ros.org/amcl?distro=noetic)`. The `move_base` node is responsible for planning the path and reaching the specified point on the map. The `acml` is an active localization node that implements an adaptive (or KLD-sampling) [Monte Carlo localization algorithm](https://en.wikipedia.org/wiki/Monte_Carlo_method). I advise you to read the official ROS documentation for these nodes. Try to get an understanding of what these nodes are for and how they work.

At first, configure the `move_base` node. When planning a robot path, the `move_base` works with two types of path planners: `[global_planner](http://wiki.ros.org/global_planner?distro=noetic)` and [`base_local_planner`](http://wiki.ros.org/base_local_planner?distro=noetic). The global planner makes a route to the goal position using a global map. The map can be ready-made or can be built in real-time. The local planner is a kind of add-on to the global planner. The local planner is responsible for driving the robot around obstacles encountered on the global path. Suppose you have a ready-made map and place the robot on it and specify the goal position. The global planner builds you a path to this position avoiding the global obstacles found on the map (for example, the walls). While moving to the goal position, the local planner corrects the path if dynamic obstacles (such as a person) appear.